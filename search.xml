<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/08/22/hello-world/"/>
      <url>/2020/08/22/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p><h3 id="config-page"><a href="#config-page" class="headerlink" title="config page."></a>config page.</h3>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>CAP_principle</title>
      <link href="/2020/07/01/CAP-principle/"/>
      <url>/2020/07/01/CAP-principle/</url>
      
        <content type="html"><![CDATA[<h1 id="CAP-原则"><a href="#CAP-原则" class="headerlink" title="CAP 原则"></a>CAP 原则</h1><p>CAP原则又称CAP定理， 指的是在一个分布式系统中， 一致性（Consistency), 可用性（Availability), 分区容错性（Partition Tolerance). CAP原则指的是， 这三个要素最多只能同时实现两点， 不可能三者兼顾。 </p><p>一致性（C， Consistency) 在分布式系统中的所有数据备份， 在同一时刻是否同样的值，即各个节点上的数据都是一样的。 </p><p>可用性（A， Avalibility) 在集群是一部他节点故障后， 集群整体是否还能响应客户端的读写请求， （对于数据更新具备高可用性）</p><p>分区容忍性（P Partition Tolerance), 以实际效果而言， 分析相当于对通信的时限要求， 系统如果不能在时限内达到数据一致性， 就意味着发生了分区的情况， 必须要当前操作在C和A这间作出选择。 </p><p>CAP原则的精髓就是要么AP， 要么CP， 但是不存在CAP。 如果在某个分布系统中数据无副本， 那么系统必然满足强一致性条件， 因为只有独一数据， 不会出现数据不一致的情况， 些时C和P两要素具备， 但是如果系统发生了网络分区状态或者宕机，必须导致某些数据不可以访问， 此时可用性条件就不能被满足， 即在此情况下获到了CP系统，但是CAP不可同时满足。 </p><h2 id="服务注册中心是CP还是AP？"><a href="#服务注册中心是CP还是AP？" class="headerlink" title="服务注册中心是CP还是AP？"></a>服务注册中心是CP还是AP？</h2><p>服务注册中心是为了服务间调用服务的， 那么绝对不允许因为服务注册中心出现了问题而导致服务间的调用出现问题。 </p><p>如果node1, node2, node3集群节点。保存着可用的服务列表ip1,ip2,ip3,试想如果些时不一致， node1只保存了ip1,ip2, 此时服务读取到了node1的节点， 那么会造成什么影响？</p><p>调用node1的服务， 顶多就是负载均衡时不会有流量打到ip3,然后等node1同步回ip3后，又一致了，  这对服务其实没有什么太的影响。 </p><p>所以， 推出服务注册中心应该是一个AP系统。 </p><p>Zookeeper是个CP系统， 强一致性</p><p>场景1：  当master挂了， 此时， zookeeper集群是需要停止对外服务， 启动内部选举， 所以影响到了服务的可用性。 </p><p>当然就可以说服务本地有缓存可用列表，但是下面这种方式就更无法处理了。 </p><p>场景2： 分区可用， 试想， 有3个机房， 如果其中机房3和机房1，2网络断了， 那么机房3的注册中心就不能注册新的机器了么， 这显然不合理。 </p><p><strong>zookeep是通过TCP的心跳来判断服务是否可用，但是TCP的活性并不代表服务是否可用，但TCP活性可以说明服务是可用的么，答案显然是否定的，如：连接池已经满了，DB挂了等情况</strong></p><h2 id="理想的注册中心需要"><a href="#理想的注册中心需要" class="headerlink" title="理想的注册中心需要"></a>理想的注册中心需要</h2><ul><li>服务的自动注册与发现。最好有新的服务注册上去时还能推送到调用端。 </li><li>能对注册上来的机器方便的进行管理，能手工剔除（发送信号让服务优雅下线）、恢复机器</li><li>服务的健康检查， 能真正的检测到服务是否可用</li><li>可以看到是否有其他调用服务正在订阅注册上来的服务</li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> CAP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CAP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Netty_notepad_001</title>
      <link href="/2020/06/27/Netty-notepad-001/"/>
      <url>/2020/06/27/Netty-notepad-001/</url>
      
        <content type="html"><![CDATA[<h1 id="作者"><a href="#作者" class="headerlink" title="作者"></a>作者</h1><p>  Netty 由 Trustin Lee (韩国， Line公司) 2004年开发</p><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><ul><li>本质： 网络应用程序框架</li><li>实现： 异步、事件驱动</li><li>特征： 高性能、可维护、快速开发</li><li>用途： 开发服务器和客户端</li></ul><h1 id="Netty的现状与趋势"><a href="#Netty的现状与趋势" class="headerlink" title="Netty的现状与趋势"></a>Netty的现状与趋势</h1><p>一些典型项目：</p><ul><li>大数据： Cassandra</li><li>大数据处理: Spark hadoop</li><li><p>Message Queue: RocketMQ</p></li><li><p>检索： Elasticsearch</p></li><li>框架： gRPC Apache Dubbo Spring5</li><li>分布式协调器： Zookeeper</li><li>工具类： async-http-client</li><li><p>其他参考： <a href="https://netty.io/wiki/adopters.html" target="_blank" rel="noopener">https://netty.io/wiki/adopters.html</a></p></li><li><p>趋势</p></li><li>更多流行协议的支持<ul><li>dns</li><li>haproxy</li><li>http</li><li>http2</li><li>memcache</li><li>mqtt</li><li>redis</li><li>smtp</li><li>socks</li><li>stomp</li><li>xml</li></ul></li><li>紧跟JDK新功能能步代</li><li>更多易用、人性化的功能</li><li>IP 地址黑白名单、流量整形等</li><li>应用越来越多<h1 id="什么时经典的三种I-O模式"><a href="#什么时经典的三种I-O模式" class="headerlink" title="什么时经典的三种I/O模式"></a>什么时经典的三种I/O模式</h1>| | | | |<br>|:—:|:—-:|:—-:|:—-:|<br>|排队打饭模式|BIO（阻塞I/O）| JDK1.4之前|阻塞同步|<br>|点单、等待被叫模式|NIO（非阻塞I/O）| JDK1.4（2002年，java.nio包）| 非阻塞同步|<br>|包厢模式| AIO（异步I/O）| JDK1.7（2011年）| 非阻塞异步|</li></ul><h1 id="Netty-如何支持三种Reactor"><a href="#Netty-如何支持三种Reactor" class="headerlink" title="Netty 如何支持三种Reactor"></a>Netty 如何支持三种Reactor</h1><ul><li>什么是Reactor及三种版本 ， BIO Thread-Per-Connection </li><li>如何在Netty中使用Reactor模式  NIO Reactor </li><li>解析Netty对 Reactor模式的支持的常见疑问  AIO  Proactor </li></ul><h1 id="如何在Netty-中使用Reactor-模式"><a href="#如何在Netty-中使用Reactor-模式" class="headerlink" title="如何在Netty 中使用Reactor 模式"></a>如何在Netty 中使用Reactor 模式</h1><ul><li><p>Reactor 单线程模式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">EventLoopGroup eventGroup = <span class="keyword">new</span> NioEventLoopGroup(<span class="number">1</span>);</span><br><span class="line">ServerBootstrap serverBootstrap = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line">serverBootstrap.group(eventGroup);</span><br></pre></td></tr></table></figure></li><li><p>非主从Reactor多线程模式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">EventLoopGroup eventGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">ServerBootstrap serverBootstrap = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line">serverBootstrap.group(eventGroup);</span><br></pre></td></tr></table></figure></li><li><p>主从 Reactor 多线程模式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">EventLoopGroup bossGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line">EventLoopGroup workerGroup = <span class="keyword">new</span> NioEventLoopGroup();</span><br><span class="line"></span><br><span class="line">ServerBootstrap serverBootstrap = <span class="keyword">new</span> ServerBootstrap();</span><br><span class="line">serverBootstrap.group(boosGroup, workerGroup);</span><br></pre></td></tr></table></figure></li></ul><h2 id="为什么TCP应用中会出现粘包和半包现象？"><a href="#为什么TCP应用中会出现粘包和半包现象？" class="headerlink" title="为什么TCP应用中会出现粘包和半包现象？"></a>为什么TCP应用中会出现粘包和半包现象？</h2><p>出现粘包现象的主要原因：</p><ul><li>发送方每次写入数据 &lt; &lt; 套接字缓冲区大小</li><li>接收方读取套接字缓冲区数据不够及时<br>以上二个原因可能会导致TCP接收到的数据出现粘包现象； </li></ul><p>出现半包现象的主要原因：</p><ul><li>发送方写入的数据 &gt; &gt; 套接字缓冲区大小 </li><li>发送的数据大于协议的MTU（Maximun Transmission Unit, 最大传输单元）, 必须拆包处理</li><li>IPV4 mtu 68, 64KiB</li><li>IPV6 mtu (1280, 64KiB) but up to 4GiB with optional</li><li>Ethernet 1500</li></ul><p>出现上述问题，原因： <strong>TCP是流式协议，消息无边界</strong><br>提醒： UDP像邮寄的包裹， 虽然一次运输多个， 但每个包裹都有“界限”， 一个一个签收， 所以无粘包， 半包问题。 </p><h2 id="解决问题的根本手段：-找出消息的边界："><a href="#解决问题的根本手段：-找出消息的边界：" class="headerlink" title="解决问题的根本手段： 找出消息的边界："></a>解决问题的根本手段： 找出消息的边界：</h2><p><img src="https://www.ant-loiter.com/img/tcp_package.png" alt=""></p><h2 id="封装成帧"><a href="#封装成帧" class="headerlink" title="封装成帧"></a>封装成帧</h2><ul><li>固定长度 FixedLengthFrameDecoder   easy</li><li>分割符 DelimiterBaseFrameDecoder   easy</li><li>固定长度字段存内容的长度信息 LengthFieldBaseFrameDecoder   LengthFieldPrepender </li></ul><h2 id="Netty-为什么需要“二次”-编解码？"><a href="#Netty-为什么需要“二次”-编解码？" class="headerlink" title="Netty 为什么需要“二次” 编解码？"></a>Netty 为什么需要“二次” 编解码？</h2><ul><li>一次解码器： ByteToMessageDecoder <ul><li>io.netty.buffer.ByteBuf (原始数据流) -&gt;  io.netty.buffer.ByteBuf （用户数据）</li></ul></li><li>二次解码器： MessageToMessageDecoder<t><ul><li>io.netty.buffer.ByteBuf(用户数据) -&gt; java Object </li></ul></t></li></ul><h2 id="常用-“-二次-”-编解码方式"><a href="#常用-“-二次-”-编解码方式" class="headerlink" title="常用 “ 二次 ” 编解码方式"></a>常用 “ 二次 ” 编解码方式</h2><p>java 序列化 &lt;  Marshaling &lt; XML &lt; JSON &lt; MessagePack &lt; Google Protobuf &lt; …</p><ul><li><p>Protobuf 是一个灵活的， 高效的用于序列化的数据协议； </p></li><li><p>相比较XML 和 JSON 格式， Protobuf 更小， 更快， 更便捷。 </p></li><li><p>Protobuf是跨语言的， 并具自带了一个编译器（Protoc)， 只需要用它进行编译， 可以自动生成Java, python, C++等代码， 不需要再写其他代码。 </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Netty NetWork NetWork Protocol </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Netty NetWork NetWork Protocol </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL8.0.20_Master_Slave_replicationConfig</title>
      <link href="/2020/06/19/MySQL8-0-20-Master-Slave-replicationConfig/"/>
      <url>/2020/06/19/MySQL8-0-20-Master-Slave-replicationConfig/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL8-0-20-Master-Slave-Config"><a href="#MySQL8-0-20-Master-Slave-Config" class="headerlink" title="MySQL8.0.20 Master Slave Config"></a>MySQL8.0.20 Master Slave Config</h1><h2 id="master-service"><a href="#master-service" class="headerlink" title="master service"></a>master service</h2><p>open my.cnf config :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">server-id = 1</span><br><span class="line">binlog_expire_logs_seconds=259200</span><br><span class="line">binlog-format=MIXED</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line"></span><br><span class="line"># mysql8 startup failed </span><br><span class="line">default-time-zone=&apos;+8:00&apos;</span><br></pre></td></tr></table></figure></p><h2 id="slave-service"><a href="#slave-service" class="headerlink" title="slave service"></a>slave service</h2><p>open my.cnf config :<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server-id = 2</span><br><span class="line">binlog-format=MIXED</span><br><span class="line">log-bin=mysql-bin</span><br><span class="line">binlog_expire_logs_seconds=259200</span><br><span class="line">log-slave-updates=1</span><br></pre></td></tr></table></figure></p><h2 id="look-master-service-binlog-flag"><a href="#look-master-service-binlog-flag" class="headerlink" title="look master service binlog flag"></a>look master service binlog flag</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show master status;</span><br></pre></td></tr></table></figure><p>get binlog filename and binlog position </p><p><code>`</code></p><h1 id="create-repl-user"><a href="#create-repl-user" class="headerlink" title="create repl user"></a>create repl user</h1><p>create user ‘repl‘@’ip’ identified by ‘password’;<br>grant replication slave on <em>.</em> to ‘repl‘@’ip’;</p><p>not use this SQL:<br>grant replication slave on <em>.</em> to ‘repl‘@’IP’ identified by ‘password’;</p><h2 id="slave-service-1"><a href="#slave-service-1" class="headerlink" title="slave service"></a>slave service</h2><p>change master to<br>master_host=’ip’,<br>master_port=port,<br>master_user=’repl’,<br>master_password=’password’,<br>master_log_file=’master find binlog filename’,<br>master_log_pos=postition;</p><p>up command master_log_file &amp; master_log_pos values find by master server; </p><p>stop slave ;<br>start slave;<br>reset slave;</p>]]></content>
      
      
      <categories>
          
          <category> Master Slave Backup Restore </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Master Slave Backup Restore </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SpringFormwork001</title>
      <link href="/2020/06/18/SpringFormwork001/"/>
      <url>/2020/06/18/SpringFormwork001/</url>
      
        <content type="html"><![CDATA[<h1 id="Spring-模块"><a href="#Spring-模块" class="headerlink" title="Spring 模块"></a>Spring 模块</h1><p>spring FrameWork的模块化与java 9的模块化有所不同； </p><h1 id="Spring-模块化设计（Modular）"><a href="#Spring-模块化设计（Modular）" class="headerlink" title="Spring 模块化设计（Modular）"></a>Spring 模块化设计（Modular）</h1><table><thead><tr><th style="text-align:center">序号</th><th style="text-align:center">模块名</th><th style="text-align:center">描述说明</th><th style="text-align:center">序号</th><th style="text-align:center">模块名</th><th style="text-align:center">描述说明</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">spring-aop</td><td style="text-align:center"></td><td style="text-align:center">2</td><td style="text-align:center">spring-jms</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">spring-aspects</td><td style="text-align:center"></td><td style="text-align:center">4</td><td style="text-align:center">spring-messaging</td><td style="text-align:center">统一消息的实现如jms，kafka等MQ</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">spring-context-indexer</td><td style="text-align:center"></td><td style="text-align:center">6</td><td style="text-align:center">spring-orm</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">spring-context-support</td><td style="text-align:center"></td><td style="text-align:center">8</td><td style="text-align:center">spring-oxm</td><td style="text-align:center">xml的序列化反序列化的模块</td></tr><tr><td style="text-align:center">9</td><td style="text-align:center">spring-context</td><td style="text-align:center">与spring-beans合成实现了IOC的功能,通地这core模块支持</td><td style="text-align:center">10</td><td style="text-align:center">spring-text</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">11</td><td style="text-align:center">spring-core</td><td style="text-align:center"></td><td style="text-align:center">12</td><td style="text-align:center">spring-tx</td><td style="text-align:center">spring的事物抽象</td></tr><tr><td style="text-align:center">13</td><td style="text-align:center">spring-expression</td><td style="text-align:center"></td><td style="text-align:center">14</td><td style="text-align:center">spring-web</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">15</td><td style="text-align:center">spring-instrument</td><td style="text-align:center"></td><td style="text-align:center">16</td><td style="text-align:center">spring-webflux</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">17</td><td style="text-align:center">spring-jcl</td><td style="text-align:center">新模块从spring5开始支持的是spring引入的一个新型的日志框架spring以前就是通过comment-loging来支持的</td><td style="text-align:center">18</td><td style="text-align:center">spring-webmvc</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">19</td><td style="text-align:center">spring-jdbc</td><td style="text-align:center"></td><td style="text-align:center">20</td><td style="text-align:center">spring-websocket</td></tr></tbody></table><p>change master to master_host=’192.168.1.212’,master_user=’repl1’,master_password=‘Test@123’,master_log_file=’mysql-bin.000002’,master_log_pos=443;</p><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><ul><li>jsp 官方网址： <a href="https://jcp.org/" target="_blank" rel="noopener">https://jcp.org/</a></li><li>小马哥JSR收藏： <a href="https://github.com/mercyblitz/jsr" target="_blank" rel="noopener">https://github.com/mercyblitz/jsr</a></li><li>Spring官方文档根路径： <a href="https://docs.spring.io/spring/docs" target="_blank" rel="noopener">https://docs.spring.io/spring/docs</a><br><a href="https://docs.spring.io/spring-boot/docs" target="_blank" rel="noopener">https://docs.spring.io/spring-boot/docs</a></li></ul><h2 id="Spring编程模型"><a href="#Spring编程模型" class="headerlink" title="Spring编程模型"></a>Spring编程模型</h2><ul><li>面向对象编程</li><li>面向切面编程</li><li>面向元编程</li><li>函数驱动</li><li>模块驱动</li></ul><h2 id="IOC-容器的职责"><a href="#IOC-容器的职责" class="headerlink" title="IOC 容器的职责"></a>IOC 容器的职责</h2><ul><li>通用职责</li><li>依赖处理<ul><li>依赖查找</li><li>依赖注入</li></ul></li><li>生命周期管理<ul><li>容器</li><li>托管的资源（Java Beans或其他资源）</li></ul></li><li>配置<ul><li>容器</li><li>外部化配置</li><li>托管的资源（Java Beans 或 其他资源）</li></ul></li></ul><h2 id="IOC容器的实现"><a href="#IOC容器的实现" class="headerlink" title="IOC容器的实现"></a>IOC容器的实现</h2><ul><li>主要实现</li><li>Java SE<ul><li>Java Beans</li><li>Java ServiceLoader SPI</li><li>JNDI （Java Naming and Directory Interface）</li></ul></li><li>Java EE<ul><li>EJB （Enterprise Java Beans）</li><li>Servlet</li></ul></li><li>开源<ul><li>Apache Avalon （<a href="http://avalon.apache.org/closed.html" target="_blank" rel="noopener">http://avalon.apache.org/closed.html</a>)</li><li>PicoContainer (<a href="http://picocontainer.com/" target="_blank" rel="noopener">http://picocontainer.com/</a>)</li><li>Google Guice (<a href="https://github.com/google/guice" target="_blank" rel="noopener">https://github.com/google/guice</a>)</li><li>Spring Framework (<a href="https://spring.io/projects/spring-framework" target="_blank" rel="noopener">https://spring.io/projects/spring-framework</a>)  * </li></ul></li></ul><h2 id="依赖查找-VS-依赖注入"><a href="#依赖查找-VS-依赖注入" class="headerlink" title="依赖查找 VS 依赖注入"></a>依赖查找 VS 依赖注入</h2><table><thead><tr><th style="text-align:center">类型</th><th style="text-align:center">依赖处理</th><th style="text-align:center">实现便利性</th><th style="text-align:center">代码侵入性</th><th style="text-align:center">API依赖性</th><th style="text-align:center">可读性</th></tr></thead><tbody><tr><td style="text-align:center">依赖查找</td><td style="text-align:center">主动获取</td><td style="text-align:center">查对管繁琐</td><td style="text-align:center">侵入业务逻辑</td><td style="text-align:center">依赖容器API</td><td style="text-align:center">良好</td></tr><tr><td style="text-align:center">依赖注入</td><td style="text-align:center">被动提供</td><td style="text-align:center">相对便利</td><td style="text-align:center">低侵入性</td><td style="text-align:center">不依赖容器API</td><td style="text-align:center">一般</td></tr></tbody></table><h2 id="沙雕面试题-—-什么时IoC？"><a href="#沙雕面试题-—-什么时IoC？" class="headerlink" title="沙雕面试题  — 什么时IoC？"></a>沙雕面试题  — 什么时IoC？</h2><p> – 简单地说， IoC 是反转控制， 类似于好菜坞原则， 主要是依赖查找和依赖注入实现。</p><h2 id="996-面试题–-依赖查询和依赖注入的区别？"><a href="#996-面试题–-依赖查询和依赖注入的区别？" class="headerlink" title="996 面试题– 依赖查询和依赖注入的区别？"></a>996 面试题– 依赖查询和依赖注入的区别？</h2><p>  — 依赖查找是主动或手机依赖查询方式， 通常需要依赖容器或标准API实现，如依赖名称， 资源等方式获得对象信息，servlet API， EJB API， JNDI API； 而依赖注入则是手动或自动依赖绑定的方式， 无需依赖特定的容器和API。 </p><h2 id="劝退面试题-–-Spring-作为IoC-容器有什么优势？？"><a href="#劝退面试题-–-Spring-作为IoC-容器有什么优势？？" class="headerlink" title="劝退面试题 – Spring 作为IoC 容器有什么优势？？"></a>劝退面试题 – Spring 作为IoC 容器有什么优势？？</h2><p>  – 典型的IoC 管理， 依赖查询的依赖注入<br>  AOP抽象<br>  事务抽象<br>  事机机制<br>  SPI扩展<br>  强大的第三方整合<br>  易测试性<br>  更好的面向对象</p><h2 id="Spring-IoC-依赖查找"><a href="#Spring-IoC-依赖查找" class="headerlink" title="Spring IoC 依赖查找"></a>Spring IoC 依赖查找</h2><ul><li>根据Bean 名称查询<ul><li>实时查找</li><li>延迟查找</li></ul></li><li>根据Bean 类型查找<ul><li>单个Bean 对象</li><li>集合 Bean 对象</li></ul></li><li>根据Bean 名称 + 类型查找</li><li>根据Java 注解查找<ul><li>单个 Bean 对象</li><li>集合 Bean 对象</li></ul></li></ul><h2 id="Bean-的来源"><a href="#Bean-的来源" class="headerlink" title="Bean 的来源"></a>Bean 的来源</h2><ul><li>自建的Bean， 并通过配置产生Bean实例</li><li>依赖的Bean， 容器自己自动注入</li><li>非Bean ， 内部容器所构建的Bean</li></ul><h2 id="Spring-IoC-配置元信息"><a href="#Spring-IoC-配置元信息" class="headerlink" title="Spring IoC 配置元信息"></a>Spring IoC 配置元信息</h2><ul><li>Bean 定义配置<ul><li>基于XML 文件</li><li>基于Properties文件</li><li>基于Java 注解</li><li>基于Java API（专题讨论）</li></ul></li><li>IoC 容器配置<ul><li>基于XML文件</li><li>基于Java注解</li><li>基于Java API（专题讨论）</li></ul></li><li>外部化属性配置<ul><li>基于Java注解</li></ul></li></ul><h2 id="BeanFactory-与-ApplicationContext-倒底哪个是IoC的主要特征体理？"><a href="#BeanFactory-与-ApplicationContext-倒底哪个是IoC的主要特征体理？" class="headerlink" title="BeanFactory 与 ApplicationContext 倒底哪个是IoC的主要特征体理？"></a>BeanFactory 与 ApplicationContext 倒底哪个是IoC的主要特征体理？</h2><ul><li>ApplicationContext 不仅是BeanFactory的超类， 而且还是支持很多Spring 其它特性如：<ul><li>Events</li><li>i18n</li><li>Annotations</li><li>AOP</li><li>Resources</li><li>Configuration Metadata</li><li>Environment 抽象（Environment Abstraction)<br>在ApplicationContext中可以获取到原生功能的BeanFactory; </li></ul></li></ul><p><strong>技巧：<em>shift + fn + f6 可以重构变量名</em></strong></p><h2 id="ApplicationContext-上下文对象的关键方法："><a href="#ApplicationContext-上下文对象的关键方法：" class="headerlink" title="ApplicationContext 上下文对象的关键方法："></a>ApplicationContext 上下文对象的关键方法：</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 启动应用上下文</span></span><br><span class="line">applicationContext.refresh();</span><br><span class="line"><span class="comment">// 这一步， 完成上下文的处理， 同时初始化了很多非bean对象， 如支持事件， 支持广播， 支持国际化， 支持注解等； </span></span><br><span class="line">perareBeanFactory(beanFactory);</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">catch</span>(Exception e)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">applicationContext.close();</span><br></pre></td></tr></table></figure><h3 id="什么时Spring-IoC-容器？"><a href="#什么时Spring-IoC-容器？" class="headerlink" title="什么时Spring IoC 容器？"></a>什么时Spring IoC 容器？</h3><p>Spring Framework implementation of the Inversion(反转) of Control(IoC)principle.<br>IoC is also known as dependency injection（注入）(DI). It is a process where by objects define their dependencies(that is , the other objects they work with) only through constructor arguments, arguments to a factory method, or properties that are set on the object instance after it is constructed or returned from a factory method. The container then injects those dependencies when it creates the bean.</p><p>依赖查找， 其实在早期的javaEE实现了。 </p><h3 id="BeanFactory-与-FactoryBean"><a href="#BeanFactory-与-FactoryBean" class="headerlink" title="BeanFactory 与 FactoryBean ?"></a>BeanFactory 与 FactoryBean ?</h3><p>BeanFactory 是IoC的底层容器。<br>FactoryBean 是创建Bean的一种方式， 帮助实现复杂的初始化逻辑。 </p><h3 id="Spring-IoC容器启动时做了哪些准备？"><a href="#Spring-IoC容器启动时做了哪些准备？" class="headerlink" title="Spring IoC容器启动时做了哪些准备？"></a>Spring IoC容器启动时做了哪些准备？</h3><p>IoC 配置元信息读取和解析、IoC容器生命周期、Spring事件发布、国际化等； </p><h3 id="实例化-Spring-Bean"><a href="#实例化-Spring-Bean" class="headerlink" title="实例化 Spring Bean"></a>实例化 Spring Bean</h3><ul><li><p>Bean 实例化（Instantiation)</p><ul><li>常规方式<ul><li>通过构造器（配置元信息： XML、 Java注解和Java API）</li><li>通过静态工厂方法（ 配置元信息： XML 和 Java API）</li><li>通过Bean 工厂方法（配置元信息， XML 和 Java API）</li><li>通过 FactoryBean (配置元信息： XML 、 java 注解 和 Java API)</li></ul></li><li>特殊方式<ul><li>通过ServiceLoaderFactoryBean （配置元信息： XML、 java注解和Java API）</li><li>通过AutowireCapaleBeanFactory#ceateBean（java.lang.Class,int , boolean)</li><li>通过BeanDefinitaionRegistry#registerBeanDefinition(String, BeanDefinition) </li></ul></li></ul></li></ul><h3 id="Spring-Bean延迟初始化"><a href="#Spring-Bean延迟初始化" class="headerlink" title="Spring Bean延迟初始化"></a>Spring Bean延迟初始化</h3><ul><li><p>Bean 延迟初始化（lazy Initialization)</p><ul><li>XML 配置： &lt;bean lazy-init=”true”…/&gt;</li><li>java 注解： @Lazy(true)<br>Java注解是个静态化的东西， 一旦定义就不会修改。 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Lazy</span>(value = <span class="keyword">false</span>)</span><br><span class="line"><span class="comment">// 以上注解建议不打</span></span><br></pre></td></tr></table></figure></li></ul></li><li><p>非延迟初始化在spring应用上下文启动完成后， 被初始化 </p></li><li>延迟初始化，其实就是按需进行初始化。</li><li>在applicationContext中refresh()方法源码中， 有一个方法<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Instantiate all remaing (non-lazy-init) singletons</span></span><br><span class="line">finishBeanFactoryInitialization(beanFactory);  </span><br><span class="line"><span class="comment">// 这个方法执行完后， 就会初始化所有非延迟初始化的bean </span></span><br><span class="line"></span><br><span class="line">在应用上下文初始化前后进行输出。</span><br></pre></td></tr></table></figure></li></ul><h3 id="Spring-Bean-销毁"><a href="#Spring-Bean-销毁" class="headerlink" title="Spring Bean 销毁"></a>Spring Bean 销毁</h3><ul><li>Bean 销毁（Destroy)<ul><li>@PreDestroy 标注方法</li><li>实现DisposableBean 接口的 destory() 方法</li><li>自定义销毁方法<ul><li>XML 配置： <bean destroy="destroy" ..=""></bean></li><li>Java注解： @Bean(destory = “destory”)</li><li>Java API: AastractBeanDefinition#setDestroyMethodName(String)</li></ul></li></ul></li></ul><h3 id="Spring-Bean-垃圾回收"><a href="#Spring-Bean-垃圾回收" class="headerlink" title="Spring Bean 垃圾回收"></a>Spring Bean 垃圾回收</h3><ul><li>Bean 垃圾回收（GC）<ul><li>关闭Spring 容器（应用上下文）</li><li>执行GC</li><li>Spring Bean 覆盖finalize() 方法被回调 </li></ul></li></ul><h3 id="依赖查找的今世前生"><a href="#依赖查找的今世前生" class="headerlink" title="依赖查找的今世前生"></a>依赖查找的今世前生</h3><ul><li>单一类型依赖查找<ul><li>JNDI - javax。naming。Context#lookup（javax.naming.Name)</li><li>JavaBeans - java.beans.beancontext.BeanContext</li></ul></li><li>集合类型依赖查找<ul><li>java.beans.beancontext.BeanContext</li></ul></li><li>层次性依赖查找<ul><li>java.beans.beancontext.BeanContext</li></ul></li></ul><p>*<em>第45集完全没有听懂</em></p><p><strong>Spring是不支持点对点的广播</strong></p><h2 id="ObjectFactory-与-BeanFactory-的区别？"><a href="#ObjectFactory-与-BeanFactory-的区别？" class="headerlink" title="ObjectFactory 与 BeanFactory 的区别？"></a>ObjectFactory 与 BeanFactory 的区别？</h2><ul><li>ObjectFactory 与 BeanFactory 均提供依赖查找的能力。<br>不过 ObjectFactory 仅关注一个或一种类型的Bean依赖查找， 并且自身不具备依赖查找的能力， 能力则由BeanFactory输出。</li></ul><p>BeanFactory则提供了单一类型、集合类型以及层次性等多种依赖查找方式； </p><h2 id="BeanFactory-getBean操作是否线程安全？"><a href="#BeanFactory-getBean操作是否线程安全？" class="headerlink" title="BeanFactory.getBean操作是否线程安全？"></a>BeanFactory.getBean操作是否线程安全？</h2><p>BeanFactory.getBean方法的执行是线程安全的， 操作过程中会增加互斥锁； 在jdk6 出现偏向锁后， 一定程度上减少了锁的竞争，提升了加锁的效率 ； </p><h2 id="字段注入"><a href="#字段注入" class="headerlink" title="字段注入"></a>字段注入</h2><ul><li>实现方法<ul><li>手动模式<ul><li>Java注解配置元信息<ul><li>@Autowired  会忽略掉static 静态字段。 实际是只能注入实例字段或叫对象字段。 不能注入类的静态字段， 会自动忽略掉所有static字段。 </li><li>@Resource</li><li>@Inject (可选)</li></ul></li></ul></li></ul></li></ul><h2 id="接口回调注入"><a href="#接口回调注入" class="headerlink" title="接口回调注入"></a>接口回调注入</h2><ul><li>Aware 系列接口回调<ul><li>自动模式<br>|内建接口| 说明 |<br>|:—:|:—|<br>|BeanFactoryAware|获取IoC容器 - BeanFactory |<br>|ApplicationContextAware|获取Spring 应用上下文-ApplicationContext对象|<br>|EnvironmentAware| 获取Environment对象|<br>|ResourceLoaderAware|获取资源加载器对象- ResoueceLoader|<br>|BeanClassLoaderAware|获取加载当前Bean Class 的 ClassLoader|<br>|BeanNameAware|获取当前Bean的名称| </li></ul></li></ul><h2 id="依赖注入类型选择"><a href="#依赖注入类型选择" class="headerlink" title="依赖注入类型选择"></a>依赖注入类型选择</h2><ul><li>注入造型<ul><li>低依赖： 构造器注入  byType*  byName  官方推荐</li><li>多依赖： Setter方法注入  有个不足， 就是注入时先后顺序依赖于用户操作先后顺序，如果有注入的字段或属性有顺序要求， 这个方法注入可能会有些问题。  </li><li>便利性： 字段注入 </li><li>声明类： 方法注入 </li></ul></li></ul><h2 id="基础类型注入"><a href="#基础类型注入" class="headerlink" title="基础类型注入"></a>基础类型注入</h2><ul><li>基础类型<ul><li>原生类型（Primitive）： boolean、byte 、 char 、 short、int、float、long、double</li><li>标量类型（Scalar)： Number、Character、Boolean、 Enum、Locale、Charset、Currency、Properties、UUID</li><li>常规类型(General): Object、String、TimeZone、Calendar、Optional</li><li>Spring类型： Resource、InputSource、Formatter</li></ul></li></ul><h2 id="集合类型注入"><a href="#集合类型注入" class="headerlink" title="集合类型注入"></a>集合类型注入</h2><ul><li><p>集合类型</p><ul><li><p>数组类型（Array）： 原生类型、标量类型、 常规类型、Spring类型</p></li><li><p>集合类型（Collection）</p><ul><li>Collection： List、Set、(Sortedset、NavigableSet、EnumSet)</li><li>Map: Properties</li></ul></li></ul></li></ul><h2 id="限定注入"><a href="#限定注入" class="headerlink" title="限定注入"></a>限定注入</h2><ul><li>使用注解 @Qualifier 限定<ul><li>通过Bean 名称限定</li><li>通过分组限定</li></ul></li><li>基于注解 @Qualifier 扩展限定<ul><li>自定义注解 - 如 Spring Cloud @LoadBalanced </li></ul></li></ul><h2 id="延迟依赖注入"><a href="#延迟依赖注入" class="headerlink" title="延迟依赖注入"></a>延迟依赖注入</h2><ul><li>使用 API ObjectFactory 延迟注入<ul><li>单一类型</li><li>集合类型</li></ul></li><li>使用API Objectprovider 延迟注入 （推荐）， 其实就是扩展了ObjectFactory的类<ul><li>单一类型</li><li>集合类型</li></ul></li></ul><h2 id="依赖处理过程"><a href="#依赖处理过程" class="headerlink" title="依赖处理过程"></a>依赖处理过程</h2><ul><li>基础知识<ul><li>入口 - DefaultListableBeanFactory # resolveDependency</li><li>依赖描述符： DependencyDescriptor</li><li>自定绑定候选处理器 - AutowireCandidateResolver </li></ul></li></ul><h2 id="Autowired-注入"><a href="#Autowired-注入" class="headerlink" title="@Autowired 注入"></a>@Autowired 注入</h2><ul><li>@Autowired 注入过程<ul><li>元信息解析</li><li>依赖查找</li><li>依赖注入（ 字段、 方法） </li></ul></li><li>核心类 AutowiredAnnotationBeanPostProcessor<ul><li>postProcessMergedBeanDefinition</li><li>postProcessProperties</li></ul></li></ul><h2 id="Inject-注入"><a href="#Inject-注入" class="headerlink" title="@Inject 注入"></a>@Inject 注入</h2><ul><li><p>@Inject 注入过程</p><ul><li>如果JSR-330 存在于ClassPath 中， 复用AutowiredAnnotationBeanPostProcessor 实现。 </li><li>可以处理 @Autowired @Value @Inject</li><li>AutowiredAnnotationBeanPostProcessor 进行了 @Autowired 和 @Inject 的注解处理。 处理逻辑基本一致。</li></ul></li><li><p>CommonAnnotationBeanPostProcessor </p><ul><li>注入注解<ul><li>javax.xml.ws.WebServiceRef</li><li>javax.ejb.EJB</li><li>javax.annotation.Resource</li></ul></li><li>生命周期注解<ul><li>javax.annotation.PostConstruct</li><li>javax.annotation.PreDestroy</li></ul></li></ul></li></ul><h2 id="如何自定义依赖注入"><a href="#如何自定义依赖注入" class="headerlink" title="如何自定义依赖注入"></a>如何自定义依赖注入</h2><ul><li><p>基于AutowiredAnnotationBeanPostProcessor 实现</p></li><li><p>自定义实现</p><ul><li>生命周期处理<ul><li>InstanticationAwareBeanPostProcessor</li><li>MergedBeanDefinitionPostProcessor</li></ul></li><li>元数据<ul><li>InjectedElement</li><li>InjectionMetadata</li></ul></li></ul></li></ul><h3 id="有多少种依赖注入的方式？"><a href="#有多少种依赖注入的方式？" class="headerlink" title="有多少种依赖注入的方式？"></a>有多少种依赖注入的方式？</h3><ul><li>构造器注入 ， 少依赖， 强制依赖的情况下</li><li>Setter 注入， 多依赖， 弱依赖</li><li>字段注入   开发比较便利</li><li>方法注入   @Bean 方便声明， </li><li>接口回调注入   比较特殊的注入方法， 一般可以做一些别的事情， 如生命周期式的。 </li></ul><h3 id="你偏好构造器注入还是Setter注入？"><a href="#你偏好构造器注入还是Setter注入？" class="headerlink" title="你偏好构造器注入还是Setter注入？"></a>你偏好构造器注入还是Setter注入？</h3><p>  两种依赖注入的方式均可使用， 如果是必须依赖的话， 那么推荐使用构造器注入， Setter注入用于可选依赖。<br>  少参数， 建议首先构造器注入， </p><h3 id="Spring-依赖注入的来源有哪些？"><a href="#Spring-依赖注入的来源有哪些？" class="headerlink" title="Spring 依赖注入的来源有哪些？"></a>Spring 依赖注入的来源有哪些？</h3><ul><li>依赖注入是用 ResolverDependency </li><li>依赖查找是用 BeanFactory.getBean() </li></ul>]]></content>
      
      
      <categories>
          
          <category> Spring Framework SpringBoot SpringCloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Framework SpringBoot SpringCloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>distributed_ku_table</title>
      <link href="/2020/06/16/distributed-ku-table/"/>
      <url>/2020/06/16/distributed-ku-table/</url>
      
        <content type="html"><![CDATA[<p><strong>每一个优秀的程序员和架构师都应该掌握分库分表</strong></p><p>移动互联网时代， 海量的用户每天产生海量的数据，比如：</p><ul><li>用户表</li><li>订单表</li><li>交易流水表</li></ul><p>事实上MySQL单表可以存储10亿级数据， 只是这时候性能比较差， 业务公认MySQL单表容量在1KW以下是最佳状态， 因为这时它的BTree索引树高在3-5之间。 </p><p>即然一张表无法搞定， 那么就要想办法将数据放到多个地方， 目前比较普遍的方案有3个：</p><ul><li>表分区</li><li>分库分表</li><li>NoSQL/NewSQL, NoSQL代表MongoDB， ES； NewSQL代表TiDB</li></ul><p>RDBMS 系统有以下几个NoSQL和NewSQL无法比的</p><ul><li>RDBMS 生态完善</li><li>RDBMS 绝对稳定</li><li>RDBMS 事务特性ACID</li></ul><h2 id="分区"><a href="#分区" class="headerlink" title="分区"></a>分区</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">分区表是由多个相关底层表实现， 这些底层表也是由句柄对象表示， 所以我们也可以直接访问各个分区， 存储引擎管理分区的各个底层表和管理普通表一样（所有底层表都必须使用相同的存储引擎），分区表的索引只是在各有个底层表上各自加上一个相周的索引， 从存储引擎的角度来看， 底层表和一个普通表没有任何不同， 存储引擎也无须知道这是一个普通表还是一个分区表的一部分。</span><br></pre></td></tr></table></figure><p>这种方案有一个很大的问题就是还是只能在一个MySQL实例中， 所以IO是个很严重的问题。 但是如果上层缓存做的强大， 也可以接受。 </p><p>表分区无法使用外键， 不支持全文索引。 我认为这都不算什么缺点， 现在的项目如果还是大量使用外键和数据库全文索引， 也真是不应该。 有太多的技术可以实现的更好，数据库本身的全文索引本身就是一个普通功能。 </p><p>一般 来讲， 如果使用分区表， 业务应该要具备以下两个特点：</p><ul><li>数据不是海量（分区数有限， 存储能力有限）</li><li>并发能力要求不高</li></ul><h2 id="分库分表"><a href="#分库分表" class="headerlink" title="分库分表"></a>分库分表</h2><p>中间件：</p><ul><li>阿里的TDDL， DRDS 和 cobar</li><li>开源社区sharding-jdbc（3.x已经更名为sharding-sphere）</li><li>民间组织的MyCAT</li><li>360的Atlas</li><li>美团的zebra</li></ul><p>分库分表， 主要分二大类型：</p><ul><li>Client 模式； </li><li>Proxy 模式； </li></ul><p>Client模式代表有阿里的TDDL， 开源社区的sharding-jdbc（sharding-sphere3.x已经支持proxy模式了），架构如下：<br><img src="https://mmbiz.qpic.cn/mmbiz_jpg/Naw09lVL3GSRvyfFeLZbiagKUQEibmWiaLsn5ZBiboZumFUkVTgjGxfOjFrPko2c2uic98UAxX8icMg0FicqCTxykQsSw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>Proxy模式代表有阿里的cobar ， 民间组织的MyCAT，架构如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/Naw09lVL3GSRvyfFeLZbiagKUQEibmWiaLsf7qaknTDolvUyq5wQuapgDJojUnr89Uv7tnAJdhS3QUnUbPMNMXNmQ/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt=""></p><p>但是，无论是CLIENt模式， 还是PROXY模式， 几个核心的步骤是一样的： SQL解析、重写、路由、执行，结果归并。 </p>]]></content>
      
      
      <categories>
          
          <category> 分库分表 实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 实战 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis-distributed-Lock</title>
      <link href="/2020/06/16/Redis-distributed-Lock/"/>
      <url>/2020/06/16/Redis-distributed-Lock/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-Distributed-Lock-实现"><a href="#Redis-Distributed-Lock-实现" class="headerlink" title="Redis Distributed Lock 实现"></a>Redis Distributed Lock 实现</h1><h2 id="分布式概览"><a href="#分布式概览" class="headerlink" title="分布式概览"></a>分布式概览</h2><p>在多线程环境下， 为了保证一个代码在同一时间只能由一个多线程， java中我们一般可以使用synchronized 语法和ReetrantLock去保证， 这实际上是本地锁的方式。 但是现在都是流行分布式的加构， 在分布式的环境下， 如何保证不同节点的线程同步执行？？</p><p>实际上， 对于分布式场景， 可以使用分布式锁， 它是用来控制分布式系统之间互斥访问共享资源的一种方式。 </p><p>比如说在一个分布式系统中， 多台机器上部署了多个服务， 当客户端一个用户发起一个数据插请求时， 如果没有分布式锁机制保证， 那么这多台机器上的多个服务可能进行并发插入操作， 导致数据重复插入， 对于某些不允许有多余数据的业务来说， 这就是会造成问题。 而分布式锁机制就是为了解决类似这类问题。 保证多个服务之间互斥的访问共享资源， 如果一个服务抢占了分布式锁， 共他服务 没有获取到锁， 就不进行后续操作， 如下图所示：<br><img src="https://www.ant-loiter.com/img/distributed-lock.png" alt="Distributed Lock"></p><h2 id="分布式锁的特点"><a href="#分布式锁的特点" class="headerlink" title="分布式锁的特点"></a>分布式锁的特点</h2><p>分布式锁一般有如下的特点：</p><ul><li>互斥性， 同一时刻只能一个线程特有锁</li><li>可重入性： 同一节点上的同一个线程如果获取了锁之后能够再次获取锁； </li><li>锁超时： 和J.U.C中的锁一样支持锁超时， 防止死锁</li><li>高性能和高可用： 加锁和解锁需要高效， 同时也需要保证高可用， 防止分布式锁失效； </li><li>具备阻塞和非阻塞性， 能够及时从阻塞状态中被唤醒</li></ul><h2 id="分布式锁的实现方式"><a href="#分布式锁的实现方式" class="headerlink" title="分布式锁的实现方式"></a>分布式锁的实现方式</h2><p>一般有以下几种方式：</p><ul><li><p>基于数据库</p></li><li><p>基于Redis</p></li><li><p>基于zookeeper</p></li></ul><h2 id="Redis分布式锁实现"><a href="#Redis分布式锁实现" class="headerlink" title="Redis分布式锁实现"></a>Redis分布式锁实现</h2><ul><li>利用setnx + expire命令（不严谨）</li></ul><p>Redis的SetNX命令， setnx key value, 将key设置为value, 当键不存在时， 才能成功， 若键成功， 什么也不做， 成功返回1， 失败返回0. SETNX实际上就是SET IF NOT Exists的缩写。 </p><p>因为分布式锁还需要有超时机制， 所以需要利用expire命令来设置超时时间， 否则可能会出现死锁。 代码段如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(String key, String request, <span class="keyword">int</span> timeout)</span> </span>&#123;</span><br><span class="line">  Long result = jedis.setnx(key, request);</span><br><span class="line">  <span class="comment">// result == 1时， 设置成功， 否则设置失败</span></span><br><span class="line">  <span class="keyword">if</span>(result == <span class="number">1l</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> jedis.expire(key, timeout) == <span class="number">1l</span>;</span><br><span class="line">  &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>实际情况，上面的二步操作setnx 和 expire 是不具备原子性的。 有可能会出现expire执行不成功的情况， 如果也会出现死锁。 </p><p>有一种改善方案就是使用lua脚本来保证其原子性（包含setnx 和 expire 两条指令）</p><ul><li>使用Lua脚本（包含setnx和expire两条指令）</li></ul><p>代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock_with_lua</span><span class="params">(String key, String UniqueId, <span class="keyword">int</span> seconds)</span> </span>&#123;</span><br><span class="line">  String lua_scripts = <span class="string">"if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then"</span> + <span class="string">"redis.call('expire', KEYS[1], ARGV[2]) return 1 else returen 0 end"</span>;</span><br><span class="line"></span><br><span class="line">  List&lt;String&gt; keys = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">  List&lt;String&gt; values = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">  keys.add(key);</span><br><span class="line">  values.add(UniqueId);</span><br><span class="line">  values.add(String.valueOf(seconds));</span><br><span class="line">  Object result = jedis.eval(lua_scripts, keys, values);</span><br><span class="line">  <span class="comment">// 判断是否成功</span></span><br><span class="line">  <span class="keyword">return</span> result.equals(<span class="number">1l</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li>使用set key value [EX seconds][PX milliseconds][NX|XX] 命令</li></ul><p>在redis 2.6.12 开始， 为set 命令增加一系列选项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set key value[EX seconds][PX milliseconds][NX|XX]</span><br></pre></td></tr></table></figure><ul><li>EX seconds : 设定过期时间 ， 单位为秒</li><li>PX milliseconds: 设定过期时间 ，单位为毫秒</li><li>NX: 仅当key不存在时设置值</li><li>XX：仅当key存在时设置值<br>set 命令的nx选项， 就等于setnx 命令， 如下；<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock_with_set</span><span class="params">(String key, String UniueId, <span class="keyword">int</span> seconds)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="string">"OK"</span>.equals(jedis.set(key, UniueId, <span class="string">"NX"</span>, <span class="string">"EX"</span>, seconds));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>value必须具有唯一性， 我们可以用UUID来做， 设置随机字符串来保证唯一性， 至于为什么要保证唯一性？ 假如value不是随机字符串， 而是一个固定值， 那么就可能存在下面的问题。</p><ul><li>客户1 获取了锁成功； </li><li>客户1在某个操作阻塞了较长时间</li><li>设置的key过期了， 锁自动释放了</li><li>客户2 获取到了对应同一个资源的锁</li><li>客户1从阻塞中恢复过来， 因为value值一样， 所以执行释放操作会释放掉客户端2持有的锁， 这样就会造成问题。 </li></ul><h3 id="释放锁的实现"><a href="#释放锁的实现" class="headerlink" title="释放锁的实现"></a>释放锁的实现</h3><p>释放锁时需要验证value值， 也就是说我们在获取锁的时候需要设置一个value， 不能直接用del key这种粗暴的方式， 因为直接del key任何客户端都可以进行解锁了， 所以解锁时，需要判断锁的值是否与自己拿的value一致。 代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">releaseLock_lua</span><span class="params">(String key, String value)</span> </span>&#123;</span><br><span class="line">  String lueScripts = <span class="string">"if redis.call('get', KEYS[1]) == ARGV[1] then "</span> + <span class="string">"return redis.call('del', KEYS[1]) else return 0 end;</span></span><br><span class="line"><span class="string">  return jedis.eval(luaScripts, Collections.singLetonList(key), Collections.singletonList(value)).equest(1l);</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p>使用lua脚本方式， 尽是保证其原子性。 </p><h1 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h1><p><strong>set key value [EX seconds][PX milliseconds][NX|XX]在redis的主备环境下也有可能出现问题，如果数据写入到master上还没有还得及同步到slave节点，master服务宕掉，slave节点成为了master这样就会出现锁丢失，针对这种情况，在Redis集群下还有其他方案</strong></p><ul><li><p>RedLock算法 及 Redisson 实现 </p><p>可以查看开源项目<br><a href="https://github.com/BrendaHub/spring-cloud-loiter-demos.git" target="_blank" rel="noopener">redis distributed lock</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis Distributed Lock Cache </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis Distributed Lock Cache </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JavaEnterprise_Architect_001</title>
      <link href="/2020/06/14/JavaEnterprise-Architect-001/"/>
      <url>/2020/06/14/JavaEnterprise-Architect-001/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式事务这深入理解？"><a href="#分布式事务这深入理解？" class="headerlink" title="分布式事务这深入理解？"></a>分布式事务这深入理解？</h1><p><em>2PC、3PC及TCC协议</em></p><h2 id="什么是分布式事务"><a href="#什么是分布式事务" class="headerlink" title="什么是分布式事务"></a>什么是分布式事务</h2><p>其实分布式事务从实质上看与数据库事务的概念是一致的， 既然是事务也就需要满足事务的基本特征（ACID）， 只是分布式事务相对于本地事务而言其表现形式有很大的不同， 如， 一个jvm进程中如果需要同时操作数据库的多条记录， 而这些操作需要在一个事务中，那么我们可以通过数据库的事务机制（一般的数据库锁）来实现。 </p><p>而随着这个jvm进程（应用）被拆分成了微服务架构， 原本一个本地逻辑执行单元被拆分到了多个独立的微服务中， 这些微服务又分别操作不同的数据库和表， 服务之间通过网络调用。 </p><p>如，服务A收到笔购物下单请求后， 需要调用服务B去支付， 支付 成功则处理购物订单为待发货状态， 否则就需要将购物订单处理为失败状态。</p><p>分布式事务实现方式有很多种， 最且有代表性的是由Oracle Tuxdeo系统提出的XA分布式事务协议， XA协议包括两阶段提交（2PC）和三阶段提交（3PC）两种理实， 接下来我们分别来介绍这两种实现方工的原理。 </p><h3 id="两阶段提交（2PC）"><a href="#两阶段提交（2PC）" class="headerlink" title="两阶段提交（2PC）"></a>两阶段提交（2PC）</h3><p>两阶段提交又称为2PC（two-phase commit protocol）， 2PC是一个非常经典的强一致、中心化的原子提交协议。 这里所说的中心化是指协议中有两类节点：一个是中心化的协调者节点（coordinator)和N<br>个参与者节点（Partcipant）。 </p><h4 id="第一阶段：-请求、表决阶段"><a href="#第一阶段：-请求、表决阶段" class="headerlink" title="第一阶段： 请求、表决阶段"></a>第一阶段： 请求、表决阶段</h4><p>Starter(分布式事务发起者) -&gt; （1、发起请求调用）-&gt; Coordinator 协调者 init </p><p>-&gt; Partcipant (参与者A) -&gt; 开启本地事务操作数据库</p><p>-&gt; Partcipant (参与者B) -&gt; 开启本地事务操作数据库</p><p>就是分布式事务的发起方在向分布式事务协调者（Coordinator）发送请求时， Coordinator首先会分别向参与者（Partcipant）节点A、参与这节点（Partcipant)节点B分别发送事务预处理请求，称之为Prepare, 有些资料也叫“Vote Request” 。 </p><p>说的直白点就是问一下这些参与节点”这件事情你们能不能处理成功了“ ， 此时参与者节点一般来说都会打开本地数据库事务， 然后开始执行数据本地事务， 但在执行完成后并不会立马提交数据库本地事务， 而先向Coordinator报告说，我这边可以处理了、我这边不能处理。 </p><p>如果所有的参与者与这个点向协调者作了”vote Commit“的反馈的话， 那么此时流程就会进入第二个阶段了。 </p><h4 id="第二个阶段，-提交-执行阶段"><a href="#第二个阶段，-提交-执行阶段" class="headerlink" title="第二个阶段， 提交/执行阶段"></a>第二个阶段， 提交/执行阶段</h4><p>根据各参与者反馈的结果， 协 调者会确定是提交还是回滚操作； </p><p>基于二阶段提交会存在一些问题： </p><ul><li><p>性能问题。 从流程上我们可以看得出， 其最大缺点就是在于穹的执行过程中间， 节点都处于阻塞状态。 各个操作数据库的节点都点用的数据库资源， 只有当所有节点准备完毕， 事务协调者才会通知进行全局提交， 参与者进行本地事务提交后才会释放资源。 这样的过程会比较漫长，对性参影响比较大。 </p></li><li><p>协调者单点故障问题， 事务协调者是整个XA模型的核心， 一旦事务协调者挂掉， 会导致参与者收不到提交或回滚的通知， 从而导致参与者节点绐xtlu处理事务无法完成的中间状态。 </p></li><li><p>丢失消息导致的数据不一致问题， 在这二个阶段， 如果发生局部网络问题， 一部分事务参考者收一了提交消息， 别一部分事务参与者没收到提交消息， 那么就会导致节点间数据的不一致问题。 </p></li></ul><h2 id="三阶段提交（3PC）"><a href="#三阶段提交（3PC）" class="headerlink" title="三阶段提交（3PC）"></a>三阶段提交（3PC）</h2><h2 id="补偿事务（TCC）"><a href="#补偿事务（TCC）" class="headerlink" title="补偿事务（TCC）"></a>补偿事务（TCC）</h2><p>TCC（Try-Confirm-Cancel） 又称补偿事务。 其核心思想是： ”针对每一个操作都要注册一个与其对应的确认和补偿（撤销操作）“ 它分为三个操作；</p><ul><li><p>Try阶段： 主要是对业务系统做检测与资源预留</p></li><li><p>Confirm阶段： 确认执行业务操作</p></li><li><p>Cancel阶段： 取消执行业务操作； </p></li></ul><h2 id="Redis实际，使用场景"><a href="#Redis实际，使用场景" class="headerlink" title="Redis实际，使用场景"></a>Redis实际，使用场景</h2><ul><li><p>Cache Aside </p></li><li><p>Read/Write Through</p></li></ul><p>对应的流程图为：<br><img src="https://www.ant-loiter.com/img/redis-cache-strage.png" alt="Redis Cache strategy"></p><p>实战：</p><ul><li><p>数据加版本号， 写库时自动增一。 更新缓存时， 只允许高版本覆盖低版本的数据。 </p></li><li><p>对于Cache Aside 和 Read/Write Through而带来的数据不一致问题， 工作中是这样解决：</p><ul><li>a 写线程； b 读线程； </li><li>b 线程， 读缓存 -&gt; 未命中 -&gt; 上写锁 -&gt; 从db读数据到缓存 -&gt; 释放锁； </li><li>a 线程， 上写锁 -&gt; 写DB -&gt; 删除缓存/ 改缓存 -&gt; 释放锁；<br>这样来保证a，b线程并发读写缓存带来的脏数据问题。 </li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Java Enterprise Architest Info </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java Enterprise Architest Info </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JavaEnterprise_Architect</title>
      <link href="/2020/06/12/JavaEnterprise-Architect/"/>
      <url>/2020/06/12/JavaEnterprise-Architect/</url>
      
        <content type="html"><![CDATA[<h2 id="不同场景数据存储分析"><a href="#不同场景数据存储分析" class="headerlink" title="不同场景数据存储分析"></a>不同场景数据存储分析</h2><h3 id="购物车"><a href="#购物车" class="headerlink" title="购物车"></a>购物车</h3><p>  购物车的数据，分二个场景：<br>    场景一： 匿名购物车<br>    场景二： 实名购物车<br>  场景一的情况， 建议是要把数据存在客户端。 那客户端可以存储数据的空间可以是以下三个：<br>    1、 Cookie<br>    2、 Session<br>    3、 LocalStorage<br>  其中Session是不太合适的， 原因是Session的保留时间短， 而且Session的数据实际上还是保存在服务端的。<br>  Cookie 和 LocalStorage 最关键的区别是， 客户端和服务端的每次交互， 都会自动带着Cookie数据的。 这样服务端可以读写客户端Cookie中的数据， 而LocalStorage里的数据， 只能由客户端来访问。 所以使用Cookie来存储， 实现起来比较简单， 加减合并购物车的过程中， 由于服务端可以读写Cookie， 这样全部逻辑都可以在服务端实现。 并且客户端和服务端请求在次数也相对少一些。 但是Cookie在客户端空间只有4K， 有时可能空间不够用。 所有有时选择LocalStorage反而又更合适。 </p><p>  一般购物车保存的数据格式都是一样的， 如下JSON表示：<br>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">// 购物车数据格式</span><br><span class="line">  &#123;</span><br><span class="line">      <span class="attr">"cart"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">              <span class="attr">"SKUID"</span>: <span class="number">8888</span>,</span><br><span class="line">              <span class="attr">"timestamp"</span>: <span class="number">1578721136</span>,</span><br><span class="line">              <span class="attr">"count"</span>: <span class="number">1</span>,</span><br><span class="line">              <span class="attr">"selected"</span>: <span class="literal">true</span></span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">              <span class="attr">"SKUID"</span>: <span class="number">6666</span>,</span><br><span class="line">              <span class="attr">"timestamp"</span>: <span class="number">1578721138</span>,</span><br><span class="line">              <span class="attr">"count"</span>: <span class="number">2</span>,</span><br><span class="line">              <span class="attr">"selected"</span>: <span class="literal">false</span></span><br><span class="line">          &#125;</span><br><span class="line">      ]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p>  用户登录态的购物车存储，应该怎么处理呢？ </p><p>  实名态的用户购物车，就必须要存储在服务端了。 常规的思路是， 设计一张购物车的表， 把数据存在MySQL中， 这个表的结构周样可以参照刚讲的实体模型来设计 ： </p><p>  也可以用Redis来保存购物车数据， 以用户ID作为Key， 用一个Redis的HASH作来Value来保存购物车中的商品， 比如；<br>  <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">// Redis Hash Info</span><br><span class="line">  &#123;</span><br><span class="line">      <span class="attr">"KEY"</span>: <span class="number">6666</span>,</span><br><span class="line">      <span class="attr">"VALUE"</span>: [</span><br><span class="line">          &#123;</span><br><span class="line">              <span class="attr">"FIELD"</span>: <span class="number">8888</span>,</span><br><span class="line">              <span class="attr">"FIELD_VALUE"</span>: &#123;</span><br><span class="line">                  <span class="attr">"timestamp"</span>: <span class="number">1578721136</span>,</span><br><span class="line">                  <span class="attr">"count"</span>: <span class="number">1</span>,</span><br><span class="line">                  <span class="attr">"selected"</span>: <span class="literal">true</span></span><br><span class="line">              &#125;</span><br><span class="line">          &#125;,</span><br><span class="line">          &#123;</span><br><span class="line">              <span class="attr">"FIELD"</span>: <span class="number">6666</span>,</span><br><span class="line">              <span class="attr">"FIELD_VALUE"</span>: &#123;</span><br><span class="line">                  <span class="attr">"timestamp"</span>: <span class="number">1578721138</span>,</span><br><span class="line">                  <span class="attr">"count"</span>: <span class="number">2</span>,</span><br><span class="line">                  <span class="attr">"selected"</span>: <span class="literal">false</span></span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">      ]</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p><p>  存储的地儿， 一般会有二种选择： 1、 Redis ; 2、 MySQL ; </p><p>  原则： <strong>读多写少用缓存Redis; 写多读少用MQ</strong></p><h2 id="使用数据库事务来保证数据一致性"><a href="#使用数据库事务来保证数据一致性" class="headerlink" title="使用数据库事务来保证数据一致性"></a>使用数据库事务来保证数据一致性</h2><p>  一般在设计对外提供的服务接口时， 不能提供单独更新余额或者流水功能， 只提供交易功能。 我们需要在实现交易功能的时候， 同时记录流水并修改余额， 并且要尽可能保证， 在任何情况下， 记录流水和修改余额这两个操作， 要么都成功， 要么都失败。 不能有任何一笔交易出现。 记录了流水但余额没更新， 或者更新了余额保是没有记录流水。 </p><p>  事物特性： 原子性Atomic; 一致性Consistency; 隔离性Lsolation; 持久性Durability; ACID</p><p>  对账户系统和其他大多数交易系统来说， 事务的原子性和持久性是必须要保证的， 否则就失去了使用事务的意义， 而一致性和隔离性其实可以做适当牺牲， 不换取性能。 所以MySQL提供了四种事物隔离级别， </p><table><thead><tr><th style="text-align:center">隔离级别</th><th style="text-align:center">脏读</th><th style="text-align:center">不可重复读</th><th style="text-align:center">幻读</th></tr></thead><tbody><tr><td style="text-align:center">读未提交</td><td style="text-align:center">Y</td><td style="text-align:center">Y</td><td style="text-align:center">Y</td></tr><tr><td style="text-align:center">读已提交</td><td style="text-align:center">N</td><td style="text-align:center">Y</td><td style="text-align:center">Y</td></tr><tr><td style="text-align:center">可重复读</td><td style="text-align:center">N</td><td style="text-align:center">N</td><td style="text-align:center">Y</td></tr><tr><td style="text-align:center">串行执行</td><td style="text-align:center">N</td><td style="text-align:center">N</td><td style="text-align:center">N</td></tr></tbody></table><p>   主要的隔离级别有二个， 一个是RC 和 RR 这二种；<br>   RC： 表示读已提交； 这个隔离级别是可能会存在重复读的情况；<br>   RR： 表示不可重复读， 这个隔离级别是会隔离重复读的情况；<br>   MySQL是默认事物隔离级别是 RR； Oracle默认的事物隔离级别为 RC</p><p> 幻读， 就是在操作时感觉是出现了幻觉一样。 场景， 数据库正在处理一个RC或RR的事物操作场景中， 现在有一个线程需要往数据库中插入一条记录； 在插入之前查询是没有与要插入ID冲突的记录， 但是在真正插入时，便 报ID冲突。 这种情况就是幻读现像； </p><p> 方案： 兼顾并发、性能和数据一致性的交易实现， 这个实现在隔离级别为RC和RR时， 都是安全的。 </p><p> 1、 我们给账户余额表增加一个log_id属性， 记录最后一笔交易的流水号；<br> 2、 首先开启事物， 查询并记录当前账户的余额和最后和笔交易的流水号；<br> 3、然后写入流水记录。<br> 4、再更新账户余额， 需要在更新语句中where条件中限定， 只有流水号等于之前查询出来的流水号时才更新。<br> 5、 然后检查更新的返回值， 如果更新成功就提交事物， 否则回滚事务；<br> <img src="https://www.ant-loiter.com/img/RCRR.png" alt="时序图表示"></p><p> 需要注意的时， 确认更新成功不是以catch为准， 而是要确认成功更新的记录数。 以下是交易SQL：<br> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"> mysql&gt; begin;</span><br><span class="line"> Query OK, 0 rows affected (0.00 sec)</span><br><span class="line"> mysql&gt;  -- 查询当前账户的余额和最后一笔交易的流水号。</span><br><span class="line"> mysql&gt; select balance, log_id from account_balance where user_id = 0;+---------+--------+</span><br><span class="line"> | balance | log_id |</span><br><span class="line"> +<span class="comment">---------+--------+</span></span><br><span class="line"> |     100 |      3 |</span><br><span class="line"> +<span class="comment">---------+--------+</span></span><br><span class="line"> 1 row in <span class="keyword">set</span> (<span class="number">0.00</span> sec)</span><br><span class="line"> mysql&gt;  <span class="comment">-- 插入流水记录。</span></span><br><span class="line"> mysql&gt; <span class="keyword">insert</span> <span class="keyword">into</span> account_log <span class="keyword">values</span>    </span><br><span class="line">      -&gt; (<span class="literal">NULL</span>, <span class="number">100</span>, <span class="keyword">NOW</span>(), <span class="number">1</span>, <span class="number">1001</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">      Query OK, 1 row affected (0.01 sec)</span><br><span class="line">mysql&gt;  -- 更新余额，注意where条件中，限定了只有流水号等于之前查询出的流水号3时才更新。</span><br><span class="line">mysql&gt; update account_balance    </span><br><span class="line">-&gt; set balance = balance + 100, log_id = LAST_INSERT_ID(), timestamp = NOW()    </span><br><span class="line">-&gt; where user_id = 0 and log_id = 3;</span><br><span class="line">Query OK, 1 row affected (0.00 sec)</span><br><span class="line">Rows matched: 1  Changed: 1  Warnings: 0</span><br><span class="line">mysql&gt;  -- 这里需要检查更新结果，只有更新余额成功（Changed: 1）才提交事务，否则回滚事务。</span><br><span class="line">mysql&gt; commit;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br></pre></td></tr></table></figure></p><p>流水和余额两个表的DDL，如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`account_log`</span> (</span><br><span class="line">  <span class="string">`log_id`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> AUTO_INCREMENT <span class="keyword">COMMENT</span> <span class="string">'流水号'</span>,</span><br><span class="line">  <span class="string">`amount`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'交易金额'</span>,</span><br><span class="line">  <span class="string">`timestamp`</span> datetime <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'时间戳'</span>,</span><br><span class="line">  <span class="string">`from_system`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'转出系统编码'</span>,</span><br><span class="line">  <span class="string">`from_system_transaction_number`</span> <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'转出系统的交易号'</span>,</span><br><span class="line">  <span class="string">`from_account`</span> <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'转出账户'</span>,</span><br><span class="line">  <span class="string">`to_system`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'转入系统编码'</span>,</span><br><span class="line">  <span class="string">`to_system_transaction_number`</span> <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'转入系统的交易号'</span>,</span><br><span class="line">  <span class="string">`to_account`</span> <span class="built_in">int</span> <span class="keyword">DEFAULT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'转入账户'</span>,</span><br><span class="line">  <span class="string">`transaction_type`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'交易类型编码'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`log_id`</span>)</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`account_balance`</span> (</span><br><span class="line">  <span class="string">`user_id`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'用户ID'</span>,</span><br><span class="line">  <span class="string">`balance`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'余额'</span>,</span><br><span class="line">  <span class="string">`timestamp`</span> datetime <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'时间戳'</span>,</span><br><span class="line">  <span class="string">`log_id`</span> <span class="built_in">int</span> <span class="keyword">NOT</span> <span class="literal">NULL</span> <span class="keyword">COMMENT</span> <span class="string">'最后一笔交易的流水号'</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`user_id`</span>)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></p><h3 id="结论："><a href="#结论：" class="headerlink" title="结论："></a>结论：</h3><p>账户系统用于记录每个用户的余额， 为了保证数据的可追溯性，还需要记录账户流水。 流水记录只能新增， 任何情况下都不允许修改和删除， 每次交易的时候需要把流水和余额放在同一个事务中一起更新； </p><p>事务具备原子性（A）， 一致性（C）， 隔离性（I）， 持久性（D）四种基本特性， 也就是ACID， 它可以保证在一个事务中执行的数据更新， 要么都成功， 要么都失败。 并且在事务执行过程中， 中间状态的数据对其他事务是不可见的。 </p><p>ACID是一种理想情况， 特别是要完美地实现CI，会导致数据库性能严重下降， 所以MySQL提供的四种可选的隔离级别， 牺牲一定的隔离性和一致性， 用于换取高性能。 这四种隔离级别中， 只有RC 和 RR 这两个隔离级别是常用的。 它们中唯一区别是在进行的事务中， 其他事务对数据的更新是否可见。 </p>]]></content>
      
      
      <categories>
          
          <category> Java Enterprise Architest Info </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java Enterprise Architest Info </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mybatis-plus-notepad</title>
      <link href="/2020/05/23/mybatis-plus-notepad/"/>
      <url>/2020/05/23/mybatis-plus-notepad/</url>
      
        <content type="html"><![CDATA[<h1 id="MyBatis-Plus（简称-MP）是一个-MyBatis-的增强工具，在-MyBatis-的基础上只做增强不做改变，为简化开发、提高效率而生。"><a href="#MyBatis-Plus（简称-MP）是一个-MyBatis-的增强工具，在-MyBatis-的基础上只做增强不做改变，为简化开发、提高效率而生。" class="headerlink" title="MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。"></a>MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。</h1><h1 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h1><ul><li>无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑</li><li>损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作</li><li>强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求</li><li>支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错</li><li>支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题</li><li>支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作</li><li>支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ）</li><li>内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用</li><li>内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询</li><li>分页插件支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer 等多种数据库</li><li>内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询</li><li>内置全局拦截插件：提供全表 delete 、 update 操作智能分析阻断，也可自定义拦截规则，预防误操作</li></ul><h1 id="支持数据库"><a href="#支持数据库" class="headerlink" title="支持数据库"></a>支持数据库</h1><ul><li><p>mysql 、 mariadb 、 oracle 、 db2 、 h2 、 hsql 、 sqlite 、 postgresql 、 sqlserver</p></li><li><p>达梦数据库 、 虚谷数据库 、 人大金仓数据库</p></li></ul><h1 id="框架结构"><a href="#框架结构" class="headerlink" title="框架结构"></a>框架结构</h1><p><a href="https://mybatis.plus/img/mybatis-plus-framework.jpg" target="_blank" rel="noopener">架构图</a></p><h1 id="mp分页"><a href="#mp分页" class="headerlink" title="mp分页"></a>mp分页</h1><ul><li><p>在spring boot项目中注册分页插件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Spring boot方式</span></span><br><span class="line"><span class="meta">@EnableTransactionManagement</span></span><br><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@MapperScan</span>(<span class="string">"com.baomidou.cloud.service.*.mapper*"</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MybatisPlusConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> PaginationInterceptor <span class="title">paginationInterceptor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        PaginationInterceptor paginationInterceptor = <span class="keyword">new</span> PaginationInterceptor();</span><br><span class="line">        <span class="comment">// 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求  默认false</span></span><br><span class="line">        <span class="comment">// paginationInterceptor.setOverflow(false);</span></span><br><span class="line">        <span class="comment">// 设置最大单页限制数量，默认 500 条，-1 不受限制</span></span><br><span class="line">        <span class="comment">// paginationInterceptor.setLimit(500);</span></span><br><span class="line">        <span class="comment">// 开启 count 的 join 优化,只针对部分 left join</span></span><br><span class="line">        paginationInterceptor.setCountSqlParser(<span class="keyword">new</span> JsqlParserCountOptimize(<span class="keyword">true</span>));</span><br><span class="line">        <span class="keyword">return</span> paginationInterceptor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>接下来就可以使用mapper里的page相关方法如：</p><ul><li>selectPage</li><li>selectMapspage</li><li>就是返回的泛型结构不太相同</li></ul></li><li>同时也可以自定义支持page的查询方法； </li></ul><h1 id="逻辑删除"><a href="#逻辑删除" class="headerlink" title="逻辑删除"></a>逻辑删除</h1><ul><li>可以在yml里全局配置逻辑删除标识</li><li>在实例上通过注解指定标记逻辑删除的字段</li><li>在mapper自带的方法里就可以进行逻辑删除了， 正常做删除就是逻辑删除</li><li>配置逻辑删除后， 自带的方法查询都会自动过滤逻辑删除的记录； 但是，但是，但是自定义的查询方法是不会自动过滤逻辑删除记录，需要自行处理； 处理方法有：<ul><li>在wrapper里添加条件，建议采用lambda Wrapper； </li><li>可以在mapper的方法的sql里添加条件； </li></ul></li></ul><h1 id="自动填充功能；"><a href="#自动填充功能；" class="headerlink" title="自动填充功能；"></a>自动填充功能；</h1><ul><li><p>需要confiation自动填充插件，如下： </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf</span>4j</span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMetaObjectHandler</span> <span class="keyword">implements</span> <span class="title">MetaObjectHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insertFill</span><span class="params">(MetaObject metaObject)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">"start insert fill ...."</span>);</span><br><span class="line">        <span class="keyword">this</span>.strictInsertFill(metaObject, <span class="string">"createTime"</span>, LocalDateTime.class, LocalDateTime.now()); <span class="comment">// 起始版本 3.3.0(推荐使用)</span></span><br><span class="line">        <span class="keyword">this</span>.fillStrategy(metaObject, <span class="string">"createTime"</span>, LocalDateTime.now()); <span class="comment">// 也可以使用(3.3.0 该方法有bug请升级到之后的版本如`3.3.1.8-SNAPSHOT`)</span></span><br><span class="line">        <span class="comment">/* 上面选其一使用,下面的已过时(注意 strictInsertFill 有多个方法,详细查看源码) */</span></span><br><span class="line">        <span class="comment">//this.setFieldValByName("operator", "Jerry", metaObject);</span></span><br><span class="line">        <span class="comment">//this.setInsertFieldValByName("operator", "Jerry", metaObject);</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateFill</span><span class="params">(MetaObject metaObject)</span> </span>&#123;</span><br><span class="line">        log.info(<span class="string">"start update fill ...."</span>);</span><br><span class="line">        <span class="keyword">this</span>.strictUpdateFill(metaObject, <span class="string">"updateTime"</span>, LocalDateTime.class, LocalDateTime.now()); <span class="comment">// 起始版本 3.3.0(推荐使用)</span></span><br><span class="line">        <span class="keyword">this</span>.fillStrategy(metaObject, <span class="string">"updateTime"</span>, LocalDateTime.now()); <span class="comment">// 也可以使用(3.3.0 该方法有bug请升级到之后的版本如`3.3.1.8-SNAPSHOT`)</span></span><br><span class="line">        <span class="comment">/* 上面选其一使用,下面的已过时(注意 strictUpdateFill 有多个方法,详细查看源码) */</span></span><br><span class="line">        <span class="comment">//this.setFieldValByName("operator", "Tom", metaObject);</span></span><br><span class="line">        <span class="comment">//this.setUpdateFieldValByName("operator", "Tom", metaObject);</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>需要在实例是属性上通过注解指定自动填充策略，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 注意！这里需要标记为填充字段</span></span><br><span class="line"><span class="meta">@TableField</span>(.. fill = FieldFill.INSERT)</span><br><span class="line"><span class="keyword">private</span> String fillField;</span><br></pre></td></tr></table></figure></li><li><p>但是实际中自动填充还支持递进关系， 可以支持临时设置的值覆盖原有的逻辑，但需要在MyMetaObjectHandler类里进行逻辑配置； </p></li><li><p>还可以在MyMetaObjectHandler配置这个字段是否存在而动态的进行自动填充策略； </p></li></ul><h1 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h1><p><em>一般查询多写入少乐观锁；写入读少悲观锁</em></p>]]></content>
      
      
      <categories>
          
          <category> mybatis mybatis-plus orm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mybatis mybatis-plus orm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SkyWalking</title>
      <link href="/2020/05/18/SkyWalking/"/>
      <url>/2020/05/18/SkyWalking/</url>
      
        <content type="html"><![CDATA[<p><a href="https://hacpai.com/article/1554982301423" target="_blank" rel="noopener">https://hacpai.com/article/1554982301423</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> SkyWalking linkln Lookup </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis-deploy</title>
      <link href="/2020/05/12/Redis-deploy/"/>
      <url>/2020/05/12/Redis-deploy/</url>
      
        <content type="html"><![CDATA[<h2 id="Deploy-standalone-Redis-Server"><a href="#Deploy-standalone-Redis-Server" class="headerlink" title="Deploy standalone Redis Server"></a>Deploy standalone Redis Server</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ wget http://download.redis.io/releases/redis-6.0.1.tar.gz</span><br><span class="line">$ tar xzf redis-6.0.1.tar.gz</span><br><span class="line">$ cd redis-6.0.1</span><br><span class="line">$ make</span><br></pre></td></tr></table></figure><p>以下是从官网拷贝，如果在centos7 64bit中安装会不成功， make不通过。 可能原因主是gcc版本不对，gcc版本要5.3 + ，centos7默认源的gcc版本为4.8.5. 升级gcc：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$  yum -y install gcc  // 先安装，如果已经安装略过</span><br><span class="line">$  gcc -v 查看当前版本</span><br><span class="line">$  yum -y install centos-release-scl</span><br><span class="line">$  yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ deltoolset-9-binutils</span><br><span class="line">$  scl enable devtoolset-9 bash   </span><br><span class="line">$  gcc -v  完成升有，此时升级到了9.x.x版本</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">*以上操作scl命令启用只是临时生效，退出shell或重新打开一个shell就会恢复原系统gcc版本*</span><br></pre></td></tr></table></figure></p><p> echo “source /opt/rh/devtoolset-9/enable” &gt;&gt; /etc/profile<br> 执行完后， 即可每次都会生效成gcc 9.X版本； </p><p> 接下来就可以make redis了，<br> 小技巧： make -jn (n建议是&lt;= cpu cos 数量)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">启动：</span><br></pre></td></tr></table></figure></p><p>// 修改配置<br>vim ./redis.conf<br>    daemonize  on   支持后台运行<br>    bind 0.0.0.0<br>    logfile  “xxxxx.log”<br>    dbfilename “dump-xxx.rdb”<br>    rdbcompression yes</p><p>redis-server ./redis.conf  (这里指定的配置文件需要根据实际情况指定)</p><p>lsof -i:6379  检查是否启动成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">到些完成了， standalone 模式的启动； </span><br><span class="line"></span><br><span class="line">## Deploy Redis master/slave 模式</span><br><span class="line"></span><br><span class="line">*一个master节点二个slave节点*</span><br></pre></td></tr></table></figure><p> config master<br>      bind 0.0.0.0<br>      port 6379<br>      logfile “…”<br>      dbfilename “…”<br>      daemonize on<br>      rdbcompression yes<br> config slave 1<br>      bind 0.0.0.0<br>      port 6380<br>      logfile “…”<br>      dbfilename “…”<br>      daemonize on<br>      rdbcompression yes<br>      slaveof master 6379<br> config alave 2<br>      bind 0.0.0.0<br>      port 6381<br>      logfile “…”<br>      dbfilename “…”<br>      daemonize on<br>      rdbcompression yes<br>      slaveof master 6379<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">配置完成后， 就可以分别启动。</span><br></pre></td></tr></table></figure></p><p>  redis-server master.conf<br>  redis-server slave1.conf<br>  redis-server slave2.conf<br><code>`</code></p><h4 id="master-主数据持久化机制"><a href="#master-主数据持久化机制" class="headerlink" title="master 主数据持久化机制"></a>master 主数据持久化机制</h4><ul><li><p>RDB</p><p>save 900 1<br>save 300  10<br>save 60    1000</p></li><li><p>AOF</p><p>appendfsync  always<br>appendfsync  everysec<br>appendfsync  no</p></li></ul><h2 id="Deploy-Redis-Sentinel"><a href="#Deploy-Redis-Sentinel" class="headerlink" title="Deploy Redis Sentinel"></a>Deploy Redis Sentinel</h2><ul><li>Redis Sentinel 规划</li></ul><table><thead><tr><th style="text-align:center">IP</th><th style="text-align:center">端口号</th><th style="text-align:center">角色</th></tr></thead><tbody><tr><td style="text-align:center">201</td><td style="text-align:center">7000</td><td style="text-align:center">Redis Master</td></tr><tr><td style="text-align:center">202</td><td style="text-align:center">7000</td><td style="text-align:center">Redis Master</td></tr><tr><td style="text-align:center">203</td><td style="text-align:center">7000</td><td style="text-align:center">Redis Master</td></tr><tr><td style="text-align:center">201</td><td style="text-align:center">27000</td><td style="text-align:center">sentinel</td></tr><tr><td style="text-align:center">202</td><td style="text-align:center">27000</td><td style="text-align:center">sentinel</td></tr><tr><td style="text-align:center">203</td><td style="text-align:center">27000</td><td style="text-align:center">sentinel</td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> redis master/slave sentinel cluster </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis master/slave sentinel cluster </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RocketMQ_Binder</title>
      <link href="/2020/05/08/RocketMQ-Binder/"/>
      <url>/2020/05/08/RocketMQ-Binder/</url>
      
        <content type="html"><![CDATA[<p>SCS (Spring cloud stream)</p><h2 id="RocketMQ-Binder-的使用"><a href="#RocketMQ-Binder-的使用" class="headerlink" title="RocketMQ Binder 的使用"></a>RocketMQ Binder 的使用</h2><ul><li><p>添加依赖</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">&lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;$&#123;latest.version&#125;&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li><li><p>版本对应关系：<br>|Spring Cloud Version|Spring Cloud Alibaba Version|<br>|:—–:|:—–:|<br>|Spring Cloud Greenwich|2.1.0.RELEASE|<br>|Spring Cloud Finchley|2.0.0.RELEASE|<br>|Spring Cloud Edgware|1.5.0.RELEASE|</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> RocketMQ Alibaba MQ Message </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ Alibaba MQ Message </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>volatile</title>
      <link href="/2020/05/08/volatile/"/>
      <url>/2020/05/08/volatile/</url>
      
        <content type="html"><![CDATA[<h1 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h1><p>volatile让变量每次在使用的时候， 都从主存中取，而不是从各个线程的“工作内存”。<br>volatile变量具有synchronized的<em>可见性</em>和<em>有序性</em>， 但是不具备<em>原子特性</em>， 所以volatile变量并不保存并发的正确性； </p><p>在Java内存模型中， 有main memory， 每一个线程也有自已的memory(例如寄存器)。为了性能， 一个线程会在自己的memory中保持要访问的变量副本。 这样就会出现同一个变量在某个瞬间，在一个线程的memory中的值可能与另外一个线程memory中的值，或者main memory中的值不一致的情况， 一个变量声明为volatile，就意味着这个变量是随时会被其他线程修改的， 因此不能将它cache在线程的memory中。 </p><p>假如多个线程同时执行i++， volatile只能保证他们操作的i是同一块内存， 但依然可能出现写入脏数据的情况。 </p><p>volatile是非阻塞的。 </p><h1 id="volatile关键字的作用"><a href="#volatile关键字的作用" class="headerlink" title="volatile关键字的作用"></a>volatile关键字的作用</h1><ul><li>保证可见性（参看下面的“volatile的实现原理”）</li><li>禁止指令重排</li></ul><p>这里来看看第二个作用： 禁止指令重排。</p><p>重排序是指编译器和处理器为了优化程序性能而对指令序列进行排序的一种手段， 现代CPU中指令的执行次序不一定按排序执行， 没有相关性的指令可以打乱次序执行， 以充分种用cpu的指令流水线， 提高执行速度。 但是重排序也需要遵守一定规划： </p><ul><li>重排序操作不会对存在数据依赖关系的操作进行重排序。如： a=1;b=a;这个指令序列，由于第二个操作依赖于第一个操作， 所以在编译时和下理器运行时这两个操作不会被重排序。 </li><li>重排序是为了优化性能， 但是不管怎么重排序， 单线程下程序的执行结果不能被改变。</li></ul><p>若用volatile修饰共享变量，在编译时， 会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 </p><p>内存屏障是在代码中使用一些特殊指令， 如ARM中的dmb、dsb和isb指令， x86中的sfence、ifence和mfence指令。CPU遇到这些特殊指令后， 要等待前面的指令执行完成才执行后面的指令。 这些指令的作用就好像一道屏障把前后指令隔离开了， 防止cpu把前后两段指令颠倒执行。 （什么时内存屏障）</p><h1 id="正确使用volatile变量的条件"><a href="#正确使用volatile变量的条件" class="headerlink" title="正确使用volatile变量的条件"></a>正确使用volatile变量的条件</h1><p>要使用volatile变量提供理想的线程安全， 必须同时满足下面两个条件：</p><ul><li>对变量的写操作不依赖于当前值。</li><li>该变量没有包含在具有其他变量的不变式中</li></ul><p>第一个条件的限制使 volatile 变量不能用作线程安全计数器。虽然增量操作（x++）看上去类似一个单独操作，实际上它是一个由读取－修改－写入操作序列组成的组合操作，必须以原子方式执行，而 volatile 不能提供必须的原子特性。实现正确的操作需要使 x 的值在操作期间保持不变，而 volatile 变量无法实现这点。（然而，如果将值调整为只从单个线程写入，那么可以忽略第一个条件。）</p>]]></content>
      
      
      <categories>
          
          <category> volatile java synchronized </category>
          
      </categories>
      
      
        <tags>
            
            <tag> volatile java synchronized </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>md5shasum</title>
      <link href="/2020/05/04/md5shasum/"/>
      <url>/2020/05/04/md5shasum/</url>
      
        <content type="html"><![CDATA[<h1 id="MD5验证"><a href="#MD5验证" class="headerlink" title="MD5验证"></a>MD5验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># md5 WebStorm-2019.2.4.dmg</span><br><span class="line">输出结果：</span><br><span class="line">MD5 (WebStorm-2019.2.4.dmg) = eaf1fb249706216e2ea162d947ee07ca</span><br></pre></td></tr></table></figure><h1 id="OpenSSL的MD5验证"><a href="#OpenSSL的MD5验证" class="headerlink" title="OpenSSL的MD5验证"></a>OpenSSL的MD5验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ openssl md5 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">MD5(WebStorm-2019.2.4.dmg)= eaf1fb249706216e2ea162d947ee07ca</span><br></pre></td></tr></table></figure><h1 id="SHA1验证"><a href="#SHA1验证" class="headerlink" title="SHA1验证"></a>SHA1验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ shasum -a 1 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">0a1df0eaf6a4fffd5800a460fc3a34d38f640ce4  WebStorm-2019.2.4.dmg</span><br></pre></td></tr></table></figure><h1 id="OpenSSL的SHA1验证"><a href="#OpenSSL的SHA1验证" class="headerlink" title="OpenSSL的SHA1验证"></a>OpenSSL的SHA1验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ openssl sha1 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">SHA1(WebStorm-2019.2.4.dmg)= 0a1df0eaf6a4fffd5800a460fc3a34d38f640ce4</span><br></pre></td></tr></table></figure><h1 id="SHA256验证"><a href="#SHA256验证" class="headerlink" title="SHA256验证"></a>SHA256验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ shasum -a 256 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">d2cae6370f2272c1c625774fa2552f670ea0e43af78c6b025df90c6ec73e0816  WebStorm-2019.2.4.dmg</span><br></pre></td></tr></table></figure><h1 id="OpenSSL的SHA256验证"><a href="#OpenSSL的SHA256验证" class="headerlink" title="OpenSSL的SHA256验证"></a>OpenSSL的SHA256验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ openssl sha256 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">SHA256(WebStorm-2019.2.4.dmg)= d2cae6370f2272c1c625774fa2552f670ea0e43af78c6b025df90c6ec73e0816</span><br></pre></td></tr></table></figure><h1 id="SHA512验证"><a href="#SHA512验证" class="headerlink" title="SHA512验证"></a>SHA512验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ shasum -a 512 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">6c5b7d7bec920c7f231d1dad3b4c1c85f4b0fa40ecbc47f0af78813f5c0201887c50d664e5494497411e1180d00396c2a744510a06765b87662302c9d3743e94  WebStorm-2019.2.4.dmg</span><br></pre></td></tr></table></figure><h1 id="OpenSSL的SHA512验证"><a href="#OpenSSL的SHA512验证" class="headerlink" title="OpenSSL的SHA512验证"></a>OpenSSL的SHA512验证</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ openssl sha512 WebStorm-2019.2.4.dmg </span><br><span class="line">输出结果：</span><br><span class="line">SHA512(WebStorm-2019.2.4.dmg)= 6c5b7d7bec920c7f231d1dad3b4c1c85f4b0fa40ecbc47f0af78813f5c0201887c50d664e5494497411e1180d00396c2a744510a06765b87662302c9d3743e94</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> md5 sha checksum signature </category>
          
      </categories>
      
      
        <tags>
            
            <tag> md5 sha checksum signature </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Disruptor</title>
      <link href="/2020/01/05/Disruptor/"/>
      <url>/2020/01/05/Disruptor/</url>
      
        <content type="html"><![CDATA[<h2 id="在-Disruptor中，-实现Hello-World需要如下几步骤："><a href="#在-Disruptor中，-实现Hello-World需要如下几步骤：" class="headerlink" title="在 Disruptor中， 实现Hello World需要如下几步骤："></a>在 Disruptor中， 实现Hello World需要如下几步骤：</h2><ul><li>建立一个Event类； </li><li>建立一个工厂Event类， 用于创建Event类实例对象</li><li>需要有一个监听事件类， 用于处理数据（Event类）</li><li>需要进行没度代码编写， 实例化Disruptor实例， 配置一系列参数， 然后我们对Disruptor实例绑定监听事件类， 接受并处理数据。 </li><li>在Disruptor中， 真正存储数据的核心叫做RingBuffer， 通过Disruptor实例拿到它， 然后把数据生产出来， 把数据加入到RingBuffer的实例对象中，即可。 </li></ul>]]></content>
      
      
      <categories>
          
          <category> disruptor 高并发 多线程 无锁 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> disruptor 高并发 多线程 无锁 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive_Data_Skew</title>
      <link href="/2019/07/21/Hive-Data-Skew/"/>
      <url>/2019/07/21/Hive-Data-Skew/</url>
      
        <content type="html"><![CDATA[<h2 id="倾斜原因：-map端缓慢，-输入数据文件多，-大小不均匀"><a href="#倾斜原因：-map端缓慢，-输入数据文件多，-大小不均匀" class="headerlink" title="倾斜原因： map端缓慢， 输入数据文件多， 大小不均匀"></a>倾斜原因： map端缓慢， 输入数据文件多， 大小不均匀</h2><ul><li><p>当出现的文件过多， 需要合并小文件， 可以通过</p><blockquote><p>set hive.merge.mapfiles=true 来解决， 将小文件进行合并；<br>set hive.map.aggr=true map端部分聚合， 相当于combiner 可以减少压力（默认 true)<br>set hive.groupby.skewindata=true 默认false</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">有数据倾斜的时候进行负载均衡，当选项设定为 true，生成的查询计划会有两个 MR Job。第一个 MR Job 中，Map 的输出结果集合会随机分布到 Reduce 中，每个 Reduce 做部分聚合操作，并输出结果，这样处理的结果是相同的 Group By Key 有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的；第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作。</span><br></pre></td></tr></table></figure></blockquote><blockquote><p>还可以通过配置map task 和reduce task进行调优 set mapred.map.tasks=number; set mapred.reduce.tasks=number;</p></blockquote></li><li><p>当映衬到一个大表和一个小表join时； </p><blockquote><p>小表在join的左侧， 大表在右侧，或使用mapjoin将小表加载到内存中。然后再与比较大的表进行join操作；如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select /* + MAPJOIN(a)*/ a.c1, b.c1,b.c2 from a join b where a.c1 = b.c1;</span><br></pre></td></tr></table></figure></blockquote></li><li><p>遇到需要进行join的但是关联字段有数据为null, 如表一的id需要和表二的id进行关联，null值的reduce会落在同一个节点上的问题； </p><blockquote><p>解决方法1： 子查询中过滤掉null值， id为空的不参于关联；<br>解决方法2： 用case when给空值分配随机的key值，（字符串+rand())，为了不让所有的null分配在同一个节点上； </p></blockquote></li><li><p>不同数据类型关联产生数据倾斜</p><blockquote><p>场景：一张表s8的日志，每个商品一条记录，要和商品表关联。但关联却碰到倾斜的问题。s8的日志中有字符串商品id,也有数字的商品id,类型是string的，但商品中的数字id是bigint的。猜测问题的原因是把s8的商品id转成数字id做hash来分配reduce，所以字符串id的s8日志，都到一个reduce上了，解决的方法验证了这个猜测。</p></blockquote><blockquote><p>解决方法： 把数字类型转换成字符串类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select * from s8_log a </span><br><span class="line">Left outer join r_auction_auctions b </span><br><span class="line">On a.auction_id = cast(b.auction_id as string)</span><br></pre></td></tr></table></figure></blockquote></li><li><p>当Hive 的HQL中包含count(distinct)时</p><blockquote><p>如果数据量非常大， 执行 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select a, count(distinct b) from t group by a;</span><br></pre></td></tr></table></figure></blockquote><p>时，会出现数据倾斜；</p><blockquote><p>解决方法： 使用 sum….group by 优化HQL，如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">select a, sum(1) from (</span><br><span class="line">  select a, b from t group by a, b</span><br><span class="line">) group by a;</span><br></pre></td></tr></table></figure></blockquote></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> hadoop hive dataSkew </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BigData_Spark_001</title>
      <link href="/2019/06/13/BigData-Spark-001/"/>
      <url>/2019/06/13/BigData-Spark-001/</url>
      
        <content type="html"><![CDATA[<p>当下主流的计算方式有如下几种：</p><ul><li>批量处理， MapReduce、Hive、 Big</li><li>流式计算， storm</li><li>内存式的交互计算， presto， Impala</li></ul><h2 id="高效（比MapReduce快10-100倍）"><a href="#高效（比MapReduce快10-100倍）" class="headerlink" title="高效（比MapReduce快10-100倍）"></a>高效（比MapReduce快10-100倍）</h2><ul><li><p>内存计算引擎， 提供Cache机制来支持需要反复迭代计算或者多次数据共享， 减少数据读取IO开销 </p></li><li><p>DAG引擎， 减少多次计算之间中间结果写到HDFS的开销</p></li><li>使用多线程池模型来减少task启动开销， shuffle过程中避免不必要的sort操作以及减少磁盘IO操作（原先批量处理的shuffle过程主要完成的是sort + partition操作）</li></ul><h3 id="Spark核心概念—RDD"><a href="#Spark核心概念—RDD" class="headerlink" title="Spark核心概念—RDD"></a>Spark核心概念—RDD</h3><p>Resilient Distributed Datasets 弹性分布式数据集</p><ul><li>分布式存储在集群的各个节点上（每一部分称为一个Partition)</li><li>可以选择不同的存储方式（磁盘或内存）</li><li>可以由一个RDD生成另外一个RDD（转换操作）</li><li>数据丢失后可以自动恢复</li></ul><h3 id="RDD基本操作（operator）"><a href="#RDD基本操作（operator）" class="headerlink" title="RDD基本操作（operator）"></a>RDD基本操作（operator）</h3><ul><li><p>Transformation (转换)<br>通过已有的RDD产生新的RDD<br>举例， map, filter, groupBy, reduceBy</p></li><li><p>Action(动作)<br>通过RDD计算得到一个或者一组值 ；<br>举例： count、 reduce、 saveAsTextFile</p></li><li><p>初始RDD的生成<br>可通过scala集合或者Hadoop数据集构造； </p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> BigData Spark MapReduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hive_FIle_format_eg</title>
      <link href="/2019/06/08/Hive-FIle-format-eg/"/>
      <url>/2019/06/08/Hive-FIle-format-eg/</url>
      
        <content type="html"><![CDATA[<p>概述</p><p>只要是配置了正确的文件类型和压缩类型(比如Textfile+Gzip、SequenceFile+Snappy等)，Hive都可以按预期读取并解析数据，提供SQL功能。</p><p>SequenceFile本身的结构已经设计了内容进行压缩。所以对于SequenceFile文件的压缩，并不是先生成SequenceFile文件，再对文件进行压缩。而是生成SequenceFile文件时，对其中的内容字段进行压缩。最终压缩后，对外仍体现为一个SequenceFile。</p><p>RCFile、ORCFile、Parquet、Avro对于压缩的处理方式与SequenceFile相同。</p><p>文件格式</p><p>Textfile<br>SequenceFile<br>RCFile<br>ORCFile<br>Parquet<br>Avro<br>压缩算法的编解码器</p><p>TEXTFILE</p><p>–创建一个表，格式为文本文件：<br>CREATE EXTERNAL TABLE student_text (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–导入数据到此表中,将启动MR任务<br>INSERT OVERWRITE TABLE student_text SELECT * FROM student;<br>可查看到生成的数据文件的格式为非压缩的文本文件：</p><p>hdfs dfs -cat /user/hive/warehouse/student_text/000000_0 </p><p>1001810081,cheyo<br>1001810082,pku<br>1001810083,rocky<br>1001810084,stephen<br>2002820081,sql<br>2002820082,hello<br>2002820083,hijj<br>3001810081,hhhhhhh<br>3001810082,abbbbbb </p><h1 id="文本文件-DEFLATE压缩"><a href="#文本文件-DEFLATE压缩" class="headerlink" title="文本文件,DEFLATE压缩"></a>文本文件,DEFLATE压缩</h1><p>–创建一个表，格式为文件文件：<br>CREATE TABLE student_text_def (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–设置压缩类型为Gzip压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec;<br>–导入数据：<br>INSERT OVERWRITE TABLE student_text_def SELECT <em> FROM student;<br>–查看数据<br>SELECT </em> FROM student_text_def;<br>查看数据文件,可看到数据文件为多个.deflate文件。</p><p>hdfs dfs -ls /user/hive/warehouse/student_text_def/<br>-rw-r–r–   2015-09-16 12:48 /user/hive/warehouse/student_text_def/000000_0.deflate<br>-rw-r–r–   2015-09-16 12:48 /user/hive/warehouse/student_text_def/000001_0.deflate<br>-rw-r–r–   2015-09-16 12:48 /user/hive/warehouse/student_text_def/000002_0.deflate </p><h1 id="文本文件-Gzip压缩"><a href="#文本文件-Gzip压缩" class="headerlink" title="文本文件,Gzip压缩"></a>文本文件,Gzip压缩</h1><p>–创建一个表，格式为文件文件：<br>CREATE TABLE student_text_gzip (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–设置压缩类型为Gzip压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;<br>–导入数据：<br>INSERT OVERWRITE TABLE student_text_gzip SELECT <em> FROM student;<br>–查看数据<br>SELECT </em> FROM student_text_gzip;<br>查看数据文件,可看到数据文件为多个.gz文件。解开.gz文件，可以看到明文文本：</p><p>hdfs dfs -ls /user/hive/warehouse/student_text_gzip/<br>-rw-r–r–  2015-09-15 10:03 /user/hive/warehouse/student_text_gzip/000000_0.gz<br>-rw-r–r–  2015-09-15 10:03 /user/hive/warehouse/student_text_gzip/000001_0.gz<br>-rw-r–r–  2015-09-15 10:03 /user/hive/warehouse/student_text_gzip/000002_0.gz<br>文本文件,Bzip2压缩</p><p>====================================<br>–创建一个表，格式为文件文件：<br>CREATE TABLE student_text_bzip2 (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–设置压缩类型为Bzip2压缩：<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.BZip2Codec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_text_bzip2 SELECT <em> FROM student;<br>–查看数据：<br>SELECT </em> FROM student_text_bzip2;<br>查看数据文件,可看到数据文件为多个.bz2文件。解开.bz2文件，可以看到明文文本：</p><p>hdfs dfs -ls /user/hive/warehouse/student_text_bzip2<br>-rw-r–r–  2015-09-15 10:09 /user/hive/warehouse/student_text_bzip2/000000_0.bz2<br>-rw-r–r–  2015-09-15 10:09 /user/hive/warehouse/student_text_bzip2/000001_0.bz2<br>-rw-r–r–  2015-09-15 10:09 /user/hive/warehouse/student_text_bzip2/000002_0.bz2<br>文本文件,lzo压缩</p><p>====================================<br>–创建表<br>CREATE TABLE student_text_lzo (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–设置为LZO压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=com.hadoop.compression.lzo.LzopCodec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_text_lzo SELECT <em> FROM student;<br>–查询数据<br>SELECT </em> FROM student_text_lzo;<br>查看数据文件,可看到数据文件为多个.lzo压缩。解开.lzo文件，可以看到明文文本。</p><p>未实测,需要安装lzop库</p><p>文本文件,lz4压缩</p><p>–创建表<br>CREATE TABLE student_text_lz4 (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–设置为LZ4压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.Lz4Codec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_text_lz4 SELECT * FROM student;<br>查看数据文件,可看到数据文件为多个.lz4压缩。使用cat查看.lz4文件，可以看到是压缩后的文本。</p><p>hdfs dfs -ls /user/hive/warehouse/student_text_lz4<br>-rw-r–r– 2015-09-16 12:06 /user/hive/warehouse/student_text_lz4/000000_0.lz4<br>-rw-r–r– 2015-09-16 12:06 /user/hive/warehouse/student_text_lz4/000001_0.lz4<br>-rw-r–r– 2015-09-16 12:06 /user/hive/warehouse/student_text_lz4/000002_0.lz4<br>文本文件,Snappy压缩</p><p>====================================<br>–创建表<br>CREATE TABLE student_text_snappy (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS TEXTFILE;<br>–设置压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.compress.map.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression=org.apache.hadoop.io.compress.SnappyCodec;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;<br>SET io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_text_snappy SELECT <em> FROM student;<br>–查询数据<br>SELECT </em> FROM student_text_snappy;<br>查看数据文件,可看到数据文件为多个.snappy压缩文件。使用cat查看.snappy文件，可以看到是压缩后的文本:</p><p>hdfs dfs -ls /user/hive/warehouse/student_text_snappy<br>Found 3 items<br>-rw-r–r–   2015-09-15 16:42 /user/hive/warehouse/student_text_snappy/000000_0.snappy<br>-rw-r–r–   2015-09-15 16:42 /user/hive/warehouse/student_text_snappy/000001_0.snappy<br>-rw-r–r–   2015-09-15 16:42 /user/hive/warehouse/student_text_snappy/000002_0.snappy<br>SEQUENCEFILE</p><p>Sequence文件,DEFLATE压缩</p><p>====================================<br>–创建一个表，格式为文件文件：<br>CREATE TABLE student_seq_def (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS SEQUENCEFILE;<br>–设置压缩类型为Gzip压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.DefaultCodec;<br>–导入数据：<br>INSERT OVERWRITE TABLE student_seq_def SELECT <em> FROM student;<br>–查看数据<br>SELECT </em> FROM student_seq_def;<br>查看数据文件,是一个密文的文件.</p><p>hdfs dfs -ls /user/hive/warehouse/student_seq_def/<br>-rw-r–r–  /user/hive/warehouse/student_seq_def/000000_0 </p><p>====================================<br>Sequence文件,Gzip压缩</p><p>–创建一个表，格式为文件文件：<br>CREATE TABLE student_seq_gzip (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS SEQUENCEFILE;<br>–设置压缩类型为Gzip压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;<br>–导入数据：<br>INSERT OVERWRITE TABLE student_seq_gzip SELECT <em> FROM student;<br>–查看数据<br>SELECT </em> FROM student_seq_gzip;<br>查看数据文件,是一个密文的文件，无法通过gzip解压：</p><p>hdfs dfs -ls /user/hive/warehouse/student_seq_gzip/<br>-rw-r–r–  /user/hive/warehouse/student_seq_gzip/000000_0<br>RCFILE</p><p>====================================<br>RCFILE,Gzip压缩</p><p>CREATE TABLE student_rcfile_gzip (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS RCFILE; </p><p>–设置压缩类型为Gzip压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.GzipCodec;<br>–导入数据：<br>INSERT OVERWRITE TABLE student_rcfile_gzip SELECT id,name FROM student;<br>–查看数据<br>SELECT * FROM student_rcfile_gzip; </p><p>ORCFile</p><p>====================================<br>ORCFile有自己的参数设置压缩格式，一般不使用上述Hive参数设置压缩参数。</p><p>ORCFile,ZLIB压缩</p><p>–创建表<br>CREATE TABLE student_orcfile_zlib (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS ORCFILE TBLPROPERTIES (“orc.compress”=”ZLIB”); </p><p>–导入数据<br>INSERT OVERWRITE TABLE student_orcfile_zlib SELECT id,name FROM student;<br>–查询数据<br>SELECT * FROM student_orcfile_zlib; </p><p>ORCFILE,Snappy压缩</p><p>====================================<br>–创建表<br>CREATE TABLE student_orcfile_snappy2 (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS ORCFILE TBLPROPERTIES (“orc.compress”=”SNAPPY”); </p><p>–导入数据<br>INSERT OVERWRITE TABLE student_orcfile_snappy2 SELECT id,name FROM student;<br>–查询数据<br>SELECT * FROM student_orcfile_snappy2;<br>一般不使用下述方式。下述方式压缩后，结果与上述同类型压缩(SNAPPY)不同。具体原因待进一步研究。</p><p>–创建表<br>CREATE TABLE student_orcfile_snappy (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS ORCFILE;<br>–设置压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.compress.map.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression=org.apache.hadoop.io.compress.SnappyCodec;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;<br>SET io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_orcfile_snappy SELECT id,name FROM student;<br>–查询数据<br>SELECT * FROM student_orcfile_snappy;<br>Parquet</p><p>====================================<br>Parquet,Snappy压缩</p><p>–创建表<br>CREATE TABLE student_parquet_snappy (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS PARQUET;<br>–设置压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.compress.map.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression=org.apache.hadoop.io.compress.SnappyCodec;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;<br>SET io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_parquet_snappy SELECT id,name FROM student;<br>–查询数据<br>SELECT * FROM student_parquet_snappy;<br>Avro</p><p>====================================<br>Avro,Snappy压缩</p><p>–创建表<br>CREATE TABLE student_avro_snappy (id STRING, name STRING)<br>ROW FORMAT DELIMITED<br>    FIELDS TERMINATED BY ‘,’<br>    LINES TERMINATED BY ‘\n’<br>STORED AS AVRO;<br>–设置压缩<br>SET hive.exec.compress.output=true;<br>SET mapred.compress.map.output=true;<br>SET mapred.output.compress=true;<br>SET mapred.output.compression=org.apache.hadoop.io.compress.SnappyCodec;<br>SET mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;<br>SET io.compression.codecs=org.apache.hadoop.io.compress.SnappyCodec;<br>–导入数据<br>INSERT OVERWRITE TABLE student_avro_snappy SELECT id,name FROM student;<br>–查询数据<br>SELECT * FROM student_avro_snappy; </p>]]></content>
      
      
      
        <tags>
            
            <tag> hive textfile seqFile RCFile ORCFile Parquet </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch_7.X</title>
      <link href="/2019/06/04/ElasticSearch-7-X/"/>
      <url>/2019/06/04/ElasticSearch-7-X/</url>
      
        <content type="html"><![CDATA[<p>可以满足多用户，多场景；<br>全文检索、安全分析、聚合、地理位置； </p><p>下载： ElasticSearch + Kirblan + X-pack</p><p>es 下载后解决也可以启动：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/elasticsearch</span><br></pre></td></tr></table></figure></p><p>即可启动， 默认端口为9200</p><p>安装x-pack<br>进入到elasticsearch目录下，<br>cd ./bin/elasticsearch-plugin install file://本地目录地址； </p><p>即可； </p><p>生成安全密码命令：</p><p>./bin/x-pack/setup-passwords<br>有二个方式， 自动生成密码， 交互式生成密码； </p><p>在ElasticSearch整合kibana时， 需要配置kibana.<br>vim ./kibana/conf/。。。。<br>配置es的服务地址和登录es的用户名和密码； </p><p>启动kibana<br>./bin/kibana</p><p>get 查询类的接口<br>post 创建索引<br>put 修改索引下的文档内容<br>delete 删除索引下的文档内容<br>post _bulk 第一个是schema 第二个是body</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">精确的查找条件格式：</span><br><span class="line">_search</span><br><span class="line">&#123;</span><br><span class="line">  query:&#123;</span><br><span class="line">    match:&#123;</span><br><span class="line">      city:&quot;adf&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">bool条件查询格式：</span><br><span class="line">&#123;</span><br><span class="line">  query:&#123;</span><br><span class="line">    bool:&#123;</span><br><span class="line">      must:[&#123;</span><br><span class="line">        match:&#123;</span><br><span class="line">          city:&quot;adsfadsf&quot;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,&#123;</span><br><span class="line">        match:&#123;</span><br><span class="line">          age:23</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">不找某个条件的格式：</span><br><span class="line">_search</span><br><span class="line">&#123;query:&#123;</span><br><span class="line">  bool:&#123;</span><br><span class="line">    must_not:[]</span><br><span class="line">    &#123;</span><br><span class="line">      match:&#123;</span><br><span class="line">        city:&quot;beijing&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> elasticSearch </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BigData_Presto_003</title>
      <link href="/2019/06/02/BigData-Presto-003/"/>
      <url>/2019/06/02/BigData-Presto-003/</url>
      
        <content type="html"><![CDATA[<p>Facebook</p><p>分布式的查询引擎， 不存储数据； 只负责计算； </p><p>MPP  Massively parallel processing </p><p>扩展式Connector组件， 数据规模GB–PB级； </p><p>跨数据库的join计算； 常用数据的connector的组件； </p><p>要求服务器内存较大， 完全基于内存， 256G 512G </p><p>完全基于内存的并行计算<br>MPP架构， 管道式执行：会在第一时间把所有节点都启动起来。 会把计算结果直接发给， 流水线作业；<br>向量化计算；<br>多线程化处理， cpu核数 * 4<br>动态编译执行计划；  if或switch是cpu不擅长执行的； cpu会预判执行； C++中LLVM， 10倍以上的优化效果；<br>优化的ORC和Parquet Reader<br>类<strong>BlinkDB</strong>的近似查询 （查询中存在长尾特效）</p><p>￥￥ 现在的CPU可以在同一时钟执行多个执行； For循环也向量化矛盾；<br>$$  hive还会大量使用， 一般不会用它来做数据查询， 用来做数据管理和存储； </p><p>presto适合：</p><p>PB级海量数据复杂分析<br>交互式SQL查询<br>ANSI SQL （notHQL）<br>f支持跨数据源查询</p><p>不适合做多个大表的join操作； </p><p>￥￥￥ 列式存储的时候只读一命中数据，<br>￥￥￥ join是需要做内存存储； </p><p>Presto完全可以独立部署； 也是一种master、slave架构<br>Coordinator, worker Discovery Service </p><p>cordinator: 是一个入口；  </p><p>周日华， jvm内核剖析； </p><p>AST 所有的SQL都可以进行AST的抽像； join on， 谓词上推；<br>presto已经采用了AST优化了SQL的查询逻辑； </p><p>mapreduce 和 presto 有不同的使用场景；<br>presto, 512G<br>presto在分片时会更细， 默认为1000条记录； </p><p>query.max-run-time  default:100d</p><p>启动：<br>/home/bigdata/software/presto-server-0.166/bin/launcher start<br>停止：<br>/home/bigdata/software/presto-server-0.166/bin/launcher stop</p><p>启动客户端<br>presto –server hadoopnode:8081 –catalog hive –schema db1</p><p>附<br>事物的隔离级别<br>读末提交（read-uncommitted)  脏读 是   不可重复读  是   幻读  是<br>不可重复读   （read-committed)  脏读 否  不可重复读  是   幻读 是<br>（mysql默认隔离级别）可重复读（repeatable-read)  脏读 否   不可重复读  否   幻读 是<br>串行化（serializable)  脏读  否   不可重复读  否   幻读 否   最严格； </p><p>ETL(Extract - Transform - Load) 指 ， 数据提起-转化-加载</p>]]></content>
      
      
      
        <tags>
            
            <tag> presto </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BigData_Hive2_002</title>
      <link href="/2019/06/01/BigData-Hive2-002/"/>
      <url>/2019/06/01/BigData-Hive2-002/</url>
      
        <content type="html"><![CDATA[<p>hbase 列簇； cell 包含， rowkey， colunmfamily…</p><p>hbase是存小文件， hdfs不擅长存小文件， 解决了</p><p>hbase不支持SQL ， 是采用命令式的。 put, get, scan , delete…..<br>在hbase之个可以用phiexo采用SQL来查询hbase的数据； </p><p>hbase创建表时只需要指定表名， 名簇名， </p><p>hbase只能存bytes数组； </p><p>hive中创建一个external表时 ， 如果在删除时， 只会删除其元数据， 不会直接删除数据文件； </p><p>kafka是有at most once , at least once , exlaty once ;  保证了数据不丢失； </p><p>hbase在配置nosync后， 吞吐性能会有10倍以上的提升；<br>hbase中zookeeper的作用： 1、master的leader选举； 2、存储region元数据； 3、负载均衡； </p><p>hive 支持交互式查询， hive on llAP， cdo,基于代价的查询优化算法； </p><p>UDF user define funciton</p><p>spark 是一种lazy runner</p><p>Hive是由hive cli metaStore yarn hdfs </p><p>hive cli可以配置多个不同的执行引擎。 可以是MapReduce 和 Spark<br>metastore在管理数据仓库有重要的作用； show create table tablename , 所有的信息都会存在metastore中。 </p><p>set hive.execution.engine = tez  </p><p>这是采用了teZ 替换了 MapReduce; </p><p>多个MR之间的依赖，会存在很大的性能问题。 中间过程要写的开销，在10年左中就开始了一个孵化项目就TEZ， 有向无环图 ， 可以进行组合处理。 就是把多个job组成一个有向无环图， 这样可以做到把中间结果存在本地。 keep seesion尽量可以复用connect;启动一个task需要搬运资源； </p><p>学习， Analyze(table statistios) ， sampling （how to user） 分析；  metadate是加快查询效率； 不同文件格式对于执行结果的影响； </p><p>如果没有配置metastore时， hive会自行启一个local的dery的数据 临时的； </p><p>explain 二个计划， </p><p>map-side join (broadcast join), 会有很好的行并性；<br>提升性能， 可以显示的replication调大。 如果map task很多的时候。 short-cricor短路图</p><p>reduce-side join (shaff join) </p><p>MR阶段优化， Reduce阶段<br>在mak task阶段优化： 1、添加一个局部的reduce task , ； 2、开启压缩； 前提是数据量很大； </p><p>作业并发度设置：</p><p>hive.exec.parallel = true<br>hive.exec.parallel.thread.number = 8 ; (default 8 )</p><p>hive on tez </p><p>hive需要考虑table的设计；<br>OLAP 工具，  可以配置</p><p>Hive 的DEBUG信息：<br>hive -hiveconf hive.root.logger=DEBUG,console</p><p>hive是一个分析型的数据， OLAP  </p><p>OLTP在阿里要求crud在1-2ms之间返回； 变态级的要求； </p><p>hive on mapreduce 慢，但很稳定； </p><p>OLTP + OLAP =》 HLAP sqlserver为代表； </p><p>mapreduce streaming 只要语言支持标准的输入输出就可以； </p><p>ETL 数据的输换， 加载； </p><p>hive是在读的时候检查schema， mysql是在写的时候检查schema</p><p>ORCFIle 行列式存储； 是把大表先按行式切片， 然后再把里面的数据进行列式存储，压缩 ； </p><p>hive会根据不同的sql逻辑来选 择性的启动MR任务； </p><p>hive命令是胖客户端，这时候不需要启动hiveServer2， beeline是一个轻客户端， 这时必须要有hiveserver2客启端； </p><h5 id="hive查资料笔记"><a href="#hive查资料笔记" class="headerlink" title="hive查资料笔记"></a>hive查资料笔记</h5><p>hive的元数据存储有三个方式：内嵌式存储derby、本地元存储、远程元存储； </p><p>连接hive有以下几种方式：</p><p>hive的分区主要目的是</p><p>ast(abstract syntax tree 抽象语法树)</p>]]></content>
      
      
      
        <tags>
            
            <tag> hive bigdata </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BigData_HBase_001</title>
      <link href="/2019/05/28/BigData-HBase-001/"/>
      <url>/2019/05/28/BigData-HBase-001/</url>
      
        <content type="html"><![CDATA[<h2 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h2><ul><li>是Google Chubby的开源实现</li><li>解决分布式集群中应用系统的一致性问题</li><li>类似于文件系统的目录节点树方式的数据存储</li><li>Hadoop中使用zookeeper的系统有：<ul><li>Yarn</li><li>HDFS</li><li>HBase</li><li>Kafka</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> HBase zookeeper BigData </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BigData_Service_config_start</title>
      <link href="/2019/05/27/BigData-Service-config-start/"/>
      <url>/2019/05/27/BigData-Service-config-start/</url>
      
        <content type="html"><![CDATA[<p>Google 在大数据的三驾马车是：BigTable\MapReduce\GFS</p><h3 id="启动MySQL"><a href="#启动MySQL" class="headerlink" title="启动MySQL"></a>启动MySQL</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">service mysqld status</span><br><span class="line">service mysqld start</span><br><span class="line">service mysqld stop</span><br><span class="line">service mysqld restart</span><br></pre></td></tr></table></figure><h3 id="config-yarn-and-hdfs"><a href="#config-yarn-and-hdfs" class="headerlink" title="config yarn and hdfs"></a>config yarn and hdfs</h3><h4 id="hdfs-config-namenode-amp-datanode"><a href="#hdfs-config-namenode-amp-datanode" class="headerlink" title="hdfs config(namenode &amp; datanode)"></a>hdfs config(namenode &amp; datanode)</h4><p>hdfs配置文件存放在Hadoop安装目录下的etc/hadoop下， 主要与core-site.xml和hdfs-site.xml两个文件相关。 </p><ul><li><p>第一次运行hadoop时， 请格式化namenode， 在namenode机器上运行：<br>bin/hadoop namenode -format</p></li><li><p>启动namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure></li><li><p>在所有的datanode机器上依次运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></li></ul><p>验证服务是否启动成功：</p><ul><li>jps 命令查看</li><li>输入<a href="http://hostname:50070" target="_blank" rel="noopener">http://hostname:50070</a>, 其中master是namenode启动节点的hostname或IP； </li></ul><h4 id="启动配置yarn-需要提前启动hdfs"><a href="#启动配置yarn-需要提前启动hdfs" class="headerlink" title="启动配置yarn(需要提前启动hdfs)"></a>启动配置yarn(需要提前启动hdfs)</h4><ul><li>配置etc/hadoop/core-site.xml</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fs.defaultFS = hdfs://hostname:9000</span><br><span class="line">hadoop.tmp.dir = /home/bigdata/hadoopdata</span><br><span class="line">hadoop.proxyuser.本机用户名.hosts = *</span><br><span class="line">hadoop.proxyuser.本机用户名.groups = *</span><br></pre></td></tr></table></figure><ul><li><p>配置etc/hadoop/yarn-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">yarn.nodemanager.aux-services = mapreduce_shuffle</span><br><span class="line">yarn.resourcemanager.address = hostname:18040</span><br><span class="line">yarn.resourcemanager.scheduler.address = hostname:18030</span><br><span class="line">yarn.resourcemanager.resource-tracker.address = hostname:18025</span><br><span class="line">yarn.resourcemanager.admin.address = hostname:18141</span><br><span class="line">yarn.resourcemanager.webapp.address = hostname:18088</span><br><span class="line">yarn.resourcemanager.scheduler.class = org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</span><br><span class="line">yarn.log-aggregation-enable = true  日志聚合配置开关</span><br><span class="line">yarn.nodemanager.pmem-check-enabled = false   配置nodemanager不对物理内存进行检查</span><br><span class="line">yarn.nodemanager.vmem-check-enabled = false  配置nodemanager不对虚拟内存进行检查</span><br></pre></td></tr></table></figure></li><li><p>配置etc/hadoop/mapred-site.xml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mapreduce.framework.name = yarn</span><br><span class="line">mapreduce.jobhistory.done-dir = /usr/history/done</span><br><span class="line">mapreduce.jobhistory.intermediate-done-dir = /usr/history/done_intermediate</span><br><span class="line">mapreduce.jobhistory.address = hostname:10020</span><br><span class="line">mapreduce.jobhistory.webapp.address = hostname:19888</span><br></pre></td></tr></table></figure></li><li><p>配置capacity-scheduler.xml </p></li></ul><h3 id="启动yarn-前提是需要将HDFS启动"><a href="#启动yarn-前提是需要将HDFS启动" class="headerlink" title="启动yarn (前提是需要将HDFS启动)"></a>启动yarn (前提是需要将HDFS启动)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><p>验证启动： <a href="http://hostname:18088" target="_blank" rel="noopener">http://hostname:18088</a></p><h3 id="启historyserver"><a href="#启historyserver" class="headerlink" title="启historyserver"></a>启historyserver</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure><p>验证启动： <a href="http://hostname:19888" target="_blank" rel="noopener">http://hostname:19888</a> </p><h3 id="启hbase"><a href="#启hbase" class="headerlink" title="启hbase"></a>启hbase</h3><ul><li><p>hbase 需要依赖zookeeper<br>配置zookeeper 的配置文件zoo.cfg</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial </span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10</span><br><span class="line"># The number of ticks that can pass between </span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line"># do not use /tmp for storage, /tmp here is just </span><br><span class="line"># example sakes.</span><br><span class="line">dataDir=/home/bigdata/software/zookeeper-3.4.9/zookeeper_data</span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">autopurge.snapRetainCount=5</span><br><span class="line"># Purge task interval in hours</span><br><span class="line">autopurge.purgeInterval=1</span><br></pre></td></tr></table></figure></li><li><p>./bin/zkServer.sh start 启动zookeeper</p></li><li>QuorunPeerMain  zookeeper进程； </li></ul><h4 id="配置conf-hbase-env-sh"><a href="#配置conf-hbase-env-sh" class="headerlink" title="配置conf/hbase-env.sh"></a>配置conf/hbase-env.sh</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/jdk1.8.0_102/</span><br><span class="line">export HBASE_MANAGES_ZK=false  是否采用内制的zookeeper</span><br></pre></td></tr></table></figure><h4 id="配置conf-hbase-site-xml"><a href="#配置conf-hbase-site-xml" class="headerlink" title="配置conf/hbase-site.xml"></a>配置conf/hbase-site.xml</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt;</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">   &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;bigdata&lt;/value&gt;  为hostname</span><br><span class="line">   &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h4 id="配置conf-regionservers-指定regionserver的主机名；"><a href="#配置conf-regionservers-指定regionserver的主机名；" class="headerlink" title="配置conf/regionservers 指定regionserver的主机名；"></a>配置conf/regionservers 指定regionserver的主机名；</h4><p>需要启动HDFS</p><h4 id="启动HBase"><a href="#启动HBase" class="headerlink" title="启动HBase"></a>启动HBase</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/start-hbase.sh</span><br></pre></td></tr></table></figure><p>验证： <a href="http://hostname:16010/master-status" target="_blank" rel="noopener">http://hostname:16010/master-status</a></p><h3 id="配置启动hive"><a href="#配置启动hive" class="headerlink" title="配置启动hive"></a>配置启动hive</h3><ul><li>在本机安装MySQL服务， hive会刚相关的元数据存储到MySQL中；<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install mysql-server</span><br><span class="line">sudo yum install mysql-connector-java</span><br></pre></td></tr></table></figure></li></ul><p>关联MySQL的java 连接Driver<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/share/java/mysql-connector-java.jar /home/bigdata/hive-2.1.1-bin/lib/mysql-connector-java.jar</span><br></pre></td></tr></table></figure></p><p>启动MySQL<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo service mysqld start</span><br><span class="line">mysql默认没有密码， 连接</span><br><span class="line">mysql -uroot 回车进入</span><br><span class="line">use mysql 切换数据库</span><br><span class="line">update user set password = password(&apos;newpass&apos;) where user = &apos;root&apos;;</span><br><span class="line">flush privileges;</span><br><span class="line">grant all privileges on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;newpass&apos; with grant option;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></p><ul><li>安装hive，下载安装包apache-hive-2.1.1-bin.tar.gz, 解压后配置hive-site.xml<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">hive.metastore.uris = thrift://hostname:9083</span><br><span class="line">hive.server2.thrift.port = 10000</span><br><span class="line">javax.jdo.option.ConnectionURL = jdbc:mysql://hostname/metastore?createDatabaseIfNotExist=true</span><br><span class="line">javax.jdo.option.ConnectionDriverName = com.mysql.jdbc.Driver</span><br><span class="line">javax.jdo.option.ConnectionUserName = root</span><br><span class="line">javax.jdo.option.ConnectionPassword = newpass</span><br><span class="line">hive.metastore.schema.verification = false</span><br><span class="line">hive.metastore.warehouse.dir = /warehouse</span><br><span class="line">fs.defaultFS = hdfs://hostname:9000</span><br><span class="line">datanucleus.autoCreateSchema = true</span><br><span class="line">datanucleus.autoStartMechanism = SchemaTable</span><br><span class="line">datanucleus.schema.autoCreateTables = true</span><br><span class="line">beeline.hs2.connection.user = bigdata  随便配置，连接登录时用</span><br><span class="line">beeline.hs2.connection.password = bigdate   同上</span><br></pre></td></tr></table></figure></li></ul><h5 id="如果是第一次启动hive，-需要执行行初台命令"><a href="#如果是第一次启动hive，-需要执行行初台命令" class="headerlink" title="如果是第一次启动hive， 需要执行行初台命令"></a>如果是第一次启动hive， 需要执行行初台命令</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">schematool -dbType  mysql -initSchema</span><br><span class="line">注： 仅在第一次启hive时运行，以后不需要；</span><br></pre></td></tr></table></figure><h5 id="启动metastore"><a href="#启动metastore" class="headerlink" title="启动metastore"></a>启动metastore</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup hive --service metastore &gt;&gt; /home/hive/metastore.log 2&gt;&amp;1 &amp;</span><br><span class="line">noup hive --service hiveserver2 &gt;&gt; home/hive/hiveserver.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>查看</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -aux | grep hive</span><br></pre></td></tr></table></figure><p>如果能看到二个进程： HiveServer2  和 HiveMetaStore </p><p>采用hive连接   直接输入hive命令即可<br>采用beeline连接， 这个是会先连接到hiveserver2上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">beeline 回车</span><br><span class="line"></span><br><span class="line">!connect jdbc:hive2://localhost:10000/default</span><br><span class="line">即可测试连接服务；</span><br></pre></td></tr></table></figure><p>Hive服务启动后， 在beeline里做查询时，针地不同的字段有不同的查询语法：<br>单字段，与常规SQL一样，表名.字段名， 表名可以省略<br>数组字段，  数组名[index] 从0开始， 数组还有size函数<br>MAP字段，  Map名[key] 就可以<br>Struct字段 ， struct名.内部key名。 </p><p>学到了， sum, cast, case where … then .. else …end; 的查询函数； </p><p>cast(字段值 as 类型（string, int, float…))<br>case 字段值  when ‘sss’ then ‘xxx’ else ‘xxx’ end; </p><h3 id="hive的partition的知识笔记"><a href="#hive的partition的知识笔记" class="headerlink" title="hive的partition的知识笔记"></a>hive的partition的知识笔记</h3><p><strong>在创建表分区时，分区字段不能和表中的字段重复</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">异常信息如下：</span><br><span class="line">表示在编写创建表SQL时， 少写By， 语法错误</span><br><span class="line">Error: Error while compiling statement: FAILED: ParseException line 10:28 missing BY at &apos;&apos;-&apos;&apos; near &apos;&lt;EOF&gt;&apos; (state=42000,code=40000)</span><br><span class="line"></span><br><span class="line">表示在创建表的partition时， 采用了表的字段当做partition字段</span><br><span class="line">FAILED: SemanticException [Error 10035]: Column repeated in partitioning columns (state=42000,code=10035)</span><br><span class="line"></span><br><span class="line">正确的创建表的SQL如下：</span><br><span class="line">create table if not exists t2(</span><br><span class="line">  id int,</span><br><span class="line">  name string,</span><br><span class="line">  hobby array&lt;string&gt;,</span><br><span class="line">  add map&lt;string,string&gt;</span><br><span class="line">)</span><br><span class="line">partitioned by (pt_d string)</span><br><span class="line">row format delimited</span><br><span class="line">fields telminated by &apos;,&apos;</span><br><span class="line">collection items terminated by &apos;-&apos;</span><br><span class="line">map keys terminated by &apos;:&apos;</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">对应的原始数如下：</span><br><span class="line"></span><br><span class="line">1,xiaoming,book-TV-code,beijing:chaoyang-shagnhai:pudong</span><br><span class="line">2,lilei,book-code,nanjing:jiangning-taiwan:taibei</span><br><span class="line">3,lihua,music-book,heilongjiang:haerbin</span><br><span class="line"></span><br><span class="line">一个表可以创建多个分构；</span><br><span class="line"></span><br><span class="line">可以通过以下操作为表创建一个新的分区，并load进入数据到新的分区里， 其实就相当于表分区一样； </span><br><span class="line"></span><br><span class="line">load data local inpath &apos;/home/hadoopuser/hive/data/hivedata/t1.data&apos; overwrite into table t1 partition(pt_d = &apos;000000&apos;);</span><br><span class="line"></span><br><span class="line">select * from t1; 查看数据</span><br><span class="line"></span><br><span class="line">show partitions t1; 查看表t1中的分区情况； </span><br><span class="line"></span><br><span class="line">如果在多分区的情况下， 会是每一个分区或组合分区都有一个与之对应的数据文件。</span><br></pre></td></tr></table></figure></p><h4 id="创建一个分区的外部表"><a href="#创建一个分区的外部表" class="headerlink" title="创建一个分区的外部表"></a>创建一个分区的外部表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create external table testljb(id int) partitioned by (age int);</span><br></pre></td></tr></table></figure><ul><li><p>实例说明 一次增加一个分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table testljb add partition(age = 2);</span><br></pre></td></tr></table></figure></li><li><p>一次添加多个分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">alter table testljb add partition(age = 3) partition(age = 4);</span><br><span class="line">注意与下面的区别</span><br><span class="line">alter table testljb add partition(age = 3 , age = 4);</span><br><span class="line">正确的写法如下</span><br><span class="line">alter table testljb add partition(age = 3, sex = &apos;male&apos;);</span><br></pre></td></tr></table></figure></li><li><p>删除分区</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter table testljb drop partition(age = 1);</span><br><span class="line"></span><br><span class="line">注意，组合分区是树状的， 删除第一层的分区， 会删除下面所有的分区内容）</span><br></pre></td></tr></table></figure></li><li><p>修复分区， 重新同步hdfs的分区信息</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">msck repair table testljb;</span><br><span class="line">这样如果用上面的命令删除了一个表分区 ， 在hdfs里的数据还没有进行compant之前还是可以恢复到；</span><br></pre></td></tr></table></figure><ul><li>显示分区信息<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show partitions tablename;</span><br></pre></td></tr></table></figure></li></ul><p>定义的外部表external不会在hdfs上有记录； </p><h3 id="配置安装presto"><a href="#配置安装presto" class="headerlink" title="配置安装presto"></a>配置安装presto</h3><ul><li><p>启动 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/launcher start/restart/stop</span><br></pre></td></tr></table></figure></li><li><p>客户端连接操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">presto --server bigdata:8081 --catalog hive --schema default</span><br></pre></td></tr></table></figure></li></ul><h3 id="配置安装spark"><a href="#配置安装spark" class="headerlink" title="配置安装spark"></a>配置安装spark</h3><p>前提： spark依赖HDFS、YARN;</p><ul><li>启动YARN ， spark的RDD可以运行在yarn之上， （ReourceManager， NodeManager)，所以需要启动yarn服务； </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sbin/stop-yarn.sh</span><br><span class="line">sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><ul><li>启动hadoop的historyserver服务， 每一个Excetor在和Driver进程在执行过程中会产生 stdout\stderr的日志文件， 由spark产生的日志文件会由这个服务收集； <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">WEBUI, 访问：</span><br><span class="line">http://hadoopnode:19888</span><br></pre></td></tr></table></figure></li></ul><h4 id="配置Spark"><a href="#配置Spark" class="headerlink" title="配置Spark"></a>配置Spark</h4><ul><li><p>告诉spark，hadoop的环境</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">配置spark-env.sh</span><br><span class="line">export HADOOP_CONF_DIR=/home/bigdata/hadoop-2.7.3/etc/hadoop</span><br><span class="line">配置到spark的配置目录即可；</span><br></pre></td></tr></table></figure></li><li><p>配置spark-default.conf, </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> bigdata hadoop yarn kafka hdfs flum sqoop hbase zookeeper hive </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bigdata hadoop yarn kafka hdfs flum sqoop hbase zookeeper hive </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>BigData_4_day</title>
      <link href="/2019/05/26/BigData-4-day/"/>
      <url>/2019/05/26/BigData-4-day/</url>
      
        <content type="html"><![CDATA[<h2 id="问卷解答"><a href="#问卷解答" class="headerlink" title="问卷解答"></a>问卷解答</h2><p>1、 实际工作中， kafka的每一个partition是需要配置三个副本。 </p><p>2、CDC  捕获的数据增量，  Capture data change；  sqoop是全量的数据转换； </p><p>3、 MySQL   sqoop - hdfs</p><p>4、 master mysql -&gt;  slave mysql 之间数据可以配置sink  ， sqoop 将数据采到hdfs中， 可以先停到masker与slave的sink；</p><h3 id="学习分式计划批处理引擎MapReduce"><a href="#学习分式计划批处理引擎MapReduce" class="headerlink" title="学习分式计划批处理引擎MapReduce"></a>学习分式计划批处理引擎MapReduce</h3><p>高吞吐， 低延迟</p><p>MapReduce, 不擅长</p><ul><li>实时计算</li><li>流式计算， 输入的数据集是静态的， 不能是动态化的， 自身的设计特点决定了数据源必须是静态的。 </li><li>DAG计算， 多个应用程序的依赖关系， 后一个应用程序的输入为前一个的输出。 有向无环图； </li></ul><p>Map Task</p><p>Each(key, value) in input: map(key, value)</p><p>Reduce Task</p><p>Each(key, List<value>) in input : reduce(key, List<value>)</value></value></p><h3 id="解决什么问题？"><a href="#解决什么问题？" class="headerlink" title="解决什么问题？"></a>解决什么问题？</h3><ul><li>将大的任务拆解为小的任务<br>Application Manager</li><li>并行调度和执行这些小的任务</li><li>将各个小任务的结果汇聚</li></ul><p>解决大量小的文件进行Map Task时，可能会有很多的资源开销； Combinal input </p><p><strong>每一个MapTask,只能处理一个文件的input,spliting</strong><br><strong>在调整成Hadoop CombineFileInputFormat后可以从逻辑上处理多个文件的Map Task input split = mapTask</strong></p><p>MapTask在启动的时候， client会计算 input spliting 来确定， 提交的时候就确定了MapTask的数量； maptask之间是没有依赖关系。 reducetask之间是有依赖关系。<br>hadoop为了提高效率， 在调度上作了优化。 hadoop里有一个参数，可以配置什么时候启动ReduceTask，可以通过一个参数来控制； MapTask与ReduceTask之间的工作是可以协调配置达到合理执行； </p><p><strong>MR， 高容错， 高吞吐</strong></p><p>ReduceTask 在处理过程中会先写缓存临时数据， 最后再commit过程， 这个是由outputFormat来完成的。 提高容错； 是否可以压缩， 文件的组织方式如何； 有很多重载的outputFormat; </p><p>MR 下的 ApplicationMaster容错性<br>一量AM运行失败， 由YARN的ResourceManager负责重新启动， 默认是2次。 一旦超过重启次数， 则作为运行失败； </p><p>最新的MR里可以配置可以容忍有TASK失败的容忍的。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 姜老师 第四天 MapReduce </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Consul-note-001</title>
      <link href="/2019/05/12/Consul-note-001/"/>
      <url>/2019/05/12/Consul-note-001/</url>
      
        <content type="html"><![CDATA[<h2 id="Consul-介绍"><a href="#Consul-介绍" class="headerlink" title="Consul 介绍"></a>Consul 介绍</h2><p>Consul是Hashicorp分司推出的开源工具； 用于实现分布式系统的服务发现与配置。 它与其它分布式服务注册与发现的案，Consul的方案更“一站式”， 内置了服务注册与发现框架、分布式一致性协议（raft）实现、健康检查、Key/Value存储、多数据中心方案， 不再需要依赖其它工具（比如Zookeeper等）。 使用起来比较简单。 Consul使用Go语言编写是采用Golang，具有天然可移植性； 安装包仅包含一个可执行的方件， 方便部署， 与Docker等轻量级容器可无缝配合； </p><h3 id="Consul的优势"><a href="#Consul的优势" class="headerlink" title="Consul的优势"></a>Consul的优势</h3><ul><li>使用Raft算法来保证一致性， 比复杂的Paxos算法更直接， 相比较而言， zookeeper采用的是Paxos，而etcd使用的是Raft。 </li><li>支持多数据中心， 内外网的服务采用不同的端口进行监听。 多数据中心可以避免单数据中心的单点故障， 而其部署则需要考虑网络延迟， 分片等情况。zookeeper和etcd均不提供多数据中心的功能支持； </li><li>支持健康检查。etcd不提供此功能； </li><li>支持http和dns协议接口。 zookeeper的集成较为复杂， 用etcd只支持http协议； </li><li>官方提供web服务界面， etcd无此功能； </li><li>综合比较， Consul作为服务注册和配置管理的新星， 值得关注和学习； </li></ul><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ul><li>服务发现</li><li>健康检查</li><li>Key/Value存储</li><li>多数据中心</li></ul><h3 id="Consul角色"><a href="#Consul角色" class="headerlink" title="Consul角色"></a>Consul角色</h3><ul><li>client客户端 无状态，将HTTP或DNS接口请求转发给局域网内的服务端集群； </li><li>server服务端，保存配置信息， 高可用集群，在局域网内与本地客户端通读，通过广域网与其它数据中心通讯。 每个数据中心的server数量推荐为3个或是5个。 </li></ul><p>Consul客户端、服务端还支持跨中心的使用，更加提高了它的高可用性。 </p><h3 id="Consul业务流程"><a href="#Consul业务流程" class="headerlink" title="Consul业务流程"></a>Consul业务流程</h3><p>1、 当Producer启动的时候， 会向Consul发送一个post请求， 告诉Consol自已的ip和port；即向Consul注册服务信息； </p><p>2、 Consul接收到Producer的注册后， 每隔10s（默认）会向Producer发送一个健康检查的请求， 检验Producer是否健康； 向Consul注册的所有服务，还会负责完成其健康检查； </p><p>3、 当Consumer发送Get方式请求/api/address到Producer时，会先从Consul中拿到一个存储服务IP和Port的临时表，从表中可以拿到Producer服务的IP和Port后再发送Get方式请求/api/address到Producer</p><p>4、 该临时表每隔10s会更新， 只包含有通过了健康检查的Producer服务； </p><p>Spring Cloud Consul项目是针对Consul的服务治理实现。 Consul是一个分布式高可用的系统， 它包含多个组件 ，但是作来一个整体， 在微服务架构中为我们的基础设施提供服务发现和服务配置工具； </p><p>Consul是采用Raft协议保证的服务的强一致性， 然而牺牲了服务的可用性， 当然是在某个临界时候；<br>Eureka保证的服务的高可用性， 和最终的一致性（不是强致性）本身就是一个servlet程序， 跑在servlet容器中， Consul则是go编写而成； </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">附： </span><br><span class="line">Kuberneter的Masker node有三个核心组件</span><br><span class="line">Sheducal\ Api Server\ conller manager </span><br><span class="line">和存储etcd</span><br><span class="line"></span><br><span class="line">正确的写法</span><br><span class="line">1、 schedule</span><br><span class="line">2、 APIServer</span><br><span class="line">3、 ControllerManager</span><br><span class="line">4、 Etcd</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 服务注册 Consul Eureka confi SpringCloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 服务注册 Consul Eureka confi spring cloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>product_manager_PM001</title>
      <link href="/2019/05/07/product-manager-PM001/"/>
      <url>/2019/05/07/product-manager-PM001/</url>
      
        <content type="html"><![CDATA[<h2 id="学习每三课记录："><a href="#学习每三课记录：" class="headerlink" title="学习每三课记录："></a>学习每三课记录：</h2><p>其实我们后天学习的东西，都是理性， 理性是把人往回拉的力量。 但是驱动一个人的，其实是他的内在感受、他的情绪、他的是底层操作系统 。 </p><p>知识的调用是是需要时间和思考的， 然而情绪却是一瞬间的体验； </p><p>因为用户不能像专业的产品经理那样， 分层次说出他的体验， 也能展现的就是用户情绪； 所以一开始我们就要学会读懂用户的情绪； </p><p>满足、愉悦、不爽  </p><p>天才的1万小时的理论 </p><p>所有，你吸收谁的营养，你就会变成谁；<br>你靠 什么满足你， 你就会成为它的样子</p><h2 id="学习第四课记录："><a href="#学习第四课记录：" class="headerlink" title="学习第四课记录："></a>学习第四课记录：</h2><p>愤怒、恐惧</p><p>愤怒： 就是感觉到自己的边界被侵犯； </p><p>其实某种意义上讲， 愤怒是一种恐惧； </p><p>所以恐惧会困住一个人的手脚； </p><p>愉悦和满足感可以让一个人在一个地方投入1万小时， 从而使这个人成为天才； </p><p>其实恐惧也是另一种动力； </p><p>做产品有二个方向：<br>要么做一个让人愉悦到爆爽的产品；<br>要么做一个可以帮助人抵御恐惧的产品； </p><p><strong>每个人的痛点都是他的恐惧， 恐惧是痛点</strong></p><p>总结， 如何找到产品接入点或者怎么改变自己的人生：</p><p>直面恐惧</p><h2 id="第五课-产品要顺应用户的潜意识"><a href="#第五课-产品要顺应用户的潜意识" class="headerlink" title="第五课 产品要顺应用户的潜意识"></a>第五课 产品要顺应用户的潜意识</h2><p>因为人会基于自身所处的角色， 所在的场景和个人的认知判断， 选择性地说一些他觉得正的话，但是， 我认为在这个场景中所谓“正确的话“， 并不代表这个用户真实的选择。<br>所以， 如果我不是在公开的角色中， 或特定的场景下， 我回家自己看影片、选个产品，还是会按照自己的真实想法来的。 </p><p><strong>所以不要被言辞迷惑， 而要想办法看到用户真实的选择。</strong></p><p>一个好的产品经理需要做到：</p><ul><li><p>体会各种人的情绪和潜意识 ； </p></li><li><p>不被一个人基于角色化交流而说出的言辞近迷惑；</p></li><li><p>看到人基于潜意识流露的真实选择； </p></li></ul><p>一个好的产品经理， 则是根本不让用户启动防御心理； </p><p>思考：  一个产品如果引发用户启动意识，让用户思考。 某种意义上就是在推开用户；  、</p><p>因为： 意识即防御； </p><p>一个产品要做到的就是迎合用户潜意识下的选择。 </p><p>包装的经验，最核心的一条就是要有—-规模感； </p><p>催眠  — 原本的词是” 绕过防御 “  </p><p>主观愿望过强的产品经理， 非常容易犯想当然的错误。 </p><p>如果要做一个拥有大用户量的产品经理， 你会看到的是” 人欲即天理“ ， 要尊重人欲。 所谓的用户调研， 就是要清空自己， 接纳别人的世界观； </p><h2 id="第六课，-角色化的预期"><a href="#第六课，-角色化的预期" class="headerlink" title="第六课， 角色化的预期"></a>第六课， 角色化的预期</h2><p>人其实只有在压力非常大的情况下， 才会去扮演角色。 除非你能给他在压力非常到位， 否则就不要对他做角色化的预期 ； </p><p>人是因为训练和压力才成为触角的， 而集体就是角色的聚集； </p><p>如果你想做一个好的产品经理， 那么首先要学习的就是通过”去角色化“来研究真实用户， 而不是用一堆”应该“来臆测用户的行为。 </p><p>角色化生存就是我们真实的生存处境， 但是只有去角色化地认识、沟通、交互、你能够得到真正的感情； </p>]]></content>
      
      
      
        <tags>
            
            <tag> PM liangning 得到 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java_Note001</title>
      <link href="/2019/05/05/Java-Note001/"/>
      <url>/2019/05/05/Java-Note001/</url>
      
        <content type="html"><![CDATA[<p>知识： </p><p>在java内存模型中每一个线程运行时都有一个线程栈， 线程栈保存和线程运行时的变量信息。 当线程访问某一个对象时， 首先通过对象的引用找到对应在推内存变量的值， 然后真内存变量的具体值load到线程本地内存中。 建立一个变量的副本， 之后线程就不再和对象在堆内存变量的值有任何关系。 而是直接修改副本变量的值 ， 在修改完之后的某一个时刻（一般是线程退出之前）， 自动把线程变量副本的值回写到对象在堆中变量，这样在堆中的对象值就产生变化了。 </p><p>若想将count的操作变为原子级别， 可以使用关键字synchronized，即可将类Counter修改为：</p><p>Jdk的垃圾收集器：</p><p>1 、 串行垃圾收集器（Serial Garbage Collector)<br>说明： 它为单线程环境设计， 只使用一个单独的线程进行垃圾回收， 是client级别默认的GC方式； </p><p>使用： 通过JVM参数 -XX:+UseSerialGC可以使用串行垃圾回收器； </p><p>2、 并行垃圾收集器（Parallel Garbage Collector)<br>说明： 它是JVM是默认垃圾回收器， 使用多线程进行垃圾回收。<br>使用： 可用：-XX:+UseParallelGC来强制指定， 用-XX:ParallelGCThreads=4来指定线程数； </p><p>3、 G1垃圾收集器（G1 Garbage Collector）</p><p>说明： G1收集器是当今收集器技术发展最前沿的成果， 它是一款面向服务端应的收集器， 它能充分利用多CPU、多核环境。 因此它是一款并行与并发收集器。并且它能建立可预测的停顿时间模型 ， 适合堆空间较大的内存垃圾回收操作； </p><p>使用： 通过JVM参数-XX:+UseG1GC使用G1垃圾回收器。 </p><p>4、 ZGC 垃圾收集器</p><ul><li><p>所有阶段几乎都是并发执行的； </p></li><li><p>像G1一样划分Region， 但更加灵活； </p></li><li><p>和G1一样会做Compacting   压缩</p></li><li><p>单代</p></li></ul><p>工作过程：<br>1、 Pause Mark Start  - 初始停顿标记 Roots</p><p>停顿JVM标记ROOT对象， 1，2，4三个被标为live； </p><p>2、 Concurrent Mark  -  并发标记</p><p>并发的递归标记其他对象， 为live</p><p>3、 Relocate 移动对象； </p><p>4、 Remap -  修正指针； </p><h3 id="String类为什么是final的；"><a href="#String类为什么是final的；" class="headerlink" title="String类为什么是final的；"></a>String类为什么是final的；</h3><p>final类在创建对象后对应的堆内存就创建好不不能再修改； 建议不要反复操作String对象， 这样可能会创建出很多个String对象， 导致内存短时间的损失； 同时影响性能；<br>所以正确的使用String类，可能一定程序简化操作和提升效率； </p><p>如Integer这样基本对象也是定义成final类型的； </p><p>final可以修饰属性、方法和类</p><p>属性，不可变， 不能修改值 ；<br>方法，不可被重写<br>类， 不可被继承， 也就是不会有子类； </p><ul><li>由于String类不能被继承， 所以就不会没修改， 这就避免了因为继承引起的安全隐患； </li><li>String类在程序中出现的频率比较高， 如果为了避免安全隐患， 在它每次出一的都用final来修饰也是一种提升效率的； </li></ul><h3 id="HashMap的源码、实现原理、底层结构"><a href="#HashMap的源码、实现原理、底层结构" class="headerlink" title="HashMap的源码、实现原理、底层结构"></a>HashMap的源码、实现原理、底层结构</h3><ul><li>HashMap的底层主要是基于数组和链表来实现的， 通过计算key的hash码来决定value的存放位置， 这样可以保证查询效率； hashmap是通链表的方式来解决hash冲突的；</li><li>数组默认大小为16， 元素挂载的h%len产生对应数组的索引位置， 这样很有可能生成的index是相同的， 这样元素就会存放在这个位置，这时针对这个数组位置就会形成一条链用来存放数据，如查数据的这个桶很大时&gt;16就会存成红黑树， 不再是数组了。 </li></ul><h3 id="反射中，Class-forName和classloader的区别"><a href="#反射中，Class-forName和classloader的区别" class="headerlink" title="反射中，Class.forName和classloader的区别"></a>反射中，Class.forName和classloader的区别</h3><p>概念：<br>jvm加载一个类的几个步骤：</p><p>加载class文件 -&gt;<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">链接</span><br><span class="line">验证class有效性 -&gt; 准备 -&gt; 解析</span><br></pre></td></tr></table></figure></p><p>初始化 -&gt; 使用 -&gt; 卸载</p><p>Class.forName(className)方法，内部实际调用的方法是  Class.forName(className,true,classloader);</p><p>第2个boolean参数表示类是否需要初始化，  Class.forName(className)默认是需要初始化。</p><p>一旦初始化，就会触发目标对象的 static块代码执行，static参数也也会被再次初始化。</p><p>ClassLoader.loadClass(className)方法，内部实际调用的方法是  ClassLoader.loadClass(className,false);</p><p>第2个 boolean参数，表示目标对象是否进行链接，false表示不进行链接，由上面介绍可以，</p><p>不进行链接意味着不进行包括初始化等一些列步骤，那么静态块和静态对象就不会得到执行</p><h3 id="Java关于并发的四个维度的技术栈"><a href="#Java关于并发的四个维度的技术栈" class="headerlink" title="Java关于并发的四个维度的技术栈"></a>Java关于并发的四个维度的技术栈</h3><ul><li>并发工具<br>提供了比synchronized更加高级的各种周结构： 包括CountDownLatch、 CyclicBarrier、Semaphore等，可以实现更加丰富的多线程操作； </li><li>并发容器<br>提供各种线程安全的容器：常见的有ConcurrentHashMap、有序ConcurrentSkipListMap,实现线程安全的动态数组CopyOnWriteArrayList等；</li><li>并发框架Executor<br>可以创建各种不同类型的线程池， 调度任务运行等，绝大部分情况下， 不再需要自已从头实现线程池和任务调度器； </li><li>并发队列<br>各种BlockingQueue的实现：常用的ArrayBlockingQueue、SynchorousQueue或针对特定场景的PriorityBlockQueue;</li></ul>]]></content>
      
      
      <categories>
          
          <category> java study note </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java study note </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Mac-n-nodejs</title>
      <link href="/2019/04/28/Mac-n-nodejs/"/>
      <url>/2019/04/28/Mac-n-nodejs/</url>
      
        <content type="html"><![CDATA[<p>Mac环境下可以通过nvm来管理Node版本， 操作如下：</p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>n是Node的一个模块， 所以安装非常方便， 而且是Express框架的作者写的</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>既然是Node模块， 直接通过npm安装全局。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g n</span><br></pre></td></tr></table></figure><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="查看帮助"><a href="#查看帮助" class="headerlink" title="查看帮助"></a>查看帮助</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n help</span><br></pre></td></tr></table></figure><p>列出所有Node版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n ls</span><br></pre></td></tr></table></figure></p><p>安装某个版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n xx.xx.xx (xx.xx.xx为要安装的版本号)</span><br></pre></td></tr></table></figure></p><p>安装最新版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n lastest</span><br></pre></td></tr></table></figure></p><p>安装最新稳定版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n stable</span><br></pre></td></tr></table></figure></p><p>选取已安装的版本使用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n</span><br></pre></td></tr></table></figure></p><p>然后上下键选择并回车确认。<br>删除某个版本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n rm xx.xx.x</span><br></pre></td></tr></table></figure></p><p>制定版本来运行脚本<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">n use xx.xxx.xx a.js</span><br></pre></td></tr></table></figure></p><p>OK ， prefect!!!</p>]]></content>
      
      
      <categories>
          
          <category> node n mac managerversion </category>
          
      </categories>
      
      
        <tags>
            
            <tag> node n mac managerversion </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Java-JDK-NewFeatures</title>
      <link href="/2019/04/28/Java-JDK-NewFeatures/"/>
      <url>/2019/04/28/Java-JDK-NewFeatures/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> java jdk openjdk oracle </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java jdk openjdk oracle </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Docker_MySQL</title>
      <link href="/2019/04/24/Docker-MySQL/"/>
      <url>/2019/04/24/Docker-MySQL/</url>
      
        <content type="html"><![CDATA[<h2 id="拉取mysql"><a href="#拉取mysql" class="headerlink" title="拉取mysql"></a>拉取mysql</h2><p>docker pull mysql</p><h2 id="运行，启动mysql实例"><a href="#运行，启动mysql实例" class="headerlink" title="运行，启动mysql实例"></a>运行，启动mysql实例</h2><p>docker run –name mingxie-mysql -p 32xxx:3306 -e MYSQL_ROOT_PASSWORD=1234 -d mysql:latest</p><p>–name 后面是docker容器名<br>-p 32xxx:3306 这里需要注意 32xxx 是你连接mysql的时候的port<br>-e MYSQL_ROOT_PASSWORD  是设置mysql的root账号密码<br>-d  mysql是你的镜像标签 </p><h2 id="在shell中访问mysql"><a href="#在shell中访问mysql" class="headerlink" title="在shell中访问mysql"></a>在shell中访问mysql</h2><p>docker exec -it mingxie-mysql bash<br>root@xxxxxx:/#<br>mysql -uroot -p -h localhost<br>Enter password: </p><p>输入密码即可。 </p><h2 id="在shell中访问mysql日志"><a href="#在shell中访问mysql日志" class="headerlink" title="在shell中访问mysql日志"></a>在shell中访问mysql日志</h2><p>docker logs mingxie-mysql</p><h2 id="使用常用工具链接mysql"><a href="#使用常用工具链接mysql" class="headerlink" title="使用常用工具链接mysql"></a>使用常用工具链接mysql</h2><p>Host:  127.0.0.1<br>UserName:  root<br>Password: 1234<br>Port:   32xxxx</p><p>搞定。 </p>]]></content>
      
      
      <categories>
          
          <category> docker mysql pull </category>
          
      </categories>
      
      
        <tags>
            
            <tag> docker mysql </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL-Config-item</title>
      <link href="/2019/04/22/MySQL-Config-item/"/>
      <url>/2019/04/22/MySQL-Config-item/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>Dubbo_RPC</title>
      <link href="/2019/04/20/Dubbo-RPC/"/>
      <url>/2019/04/20/Dubbo-RPC/</url>
      
        <content type="html"><![CDATA[<p>1、 为什么要RPC</p><ul><li><p>单一应用架构</p></li><li><p>垂直应用架构</p></li><li><p>分布式服务架构</p></li><li><p>流动计算架构</p></li></ul><p>2、 什么是RPC</p><p>RPC（Remote Procedure Call Protocol) 远程过程调用协议， 它是一种通过网络从远程计算机程序上请求服务， 而不需要了解底层网络技术协议。 简言之， PRC使得程序能够像访问本地系统资源一样， 去访问远端系统资源。 比较关键的一些方面包括： 通讯协议、序列化、资源（接口）描述、服务框架、性能、语言支持等。 </p><p>注册中心  调用者  提供者</p><p>3、PRC架构组件</p><p>一个基本的PPC架构里面应该至少包含以下4个组件：</p><ul><li><p>客户端（client）服务调用方（服务消费者）</p></li><li><p>客户端存根（client Stub) 存放服务端地址信息， 将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送服务端。 </p></li><li><p>服务端存根（Server Stub）接收客户端发送过来的请求消息并进行解包， 然后再调用本地服务进行处理</p></li><li><p>服务端（Server）服务的真正提供者</p></li></ul><p>4、 RPC和SOA、SOAP、REST的区别</p><ul><li><p>REST<br>可以看着是HTTP协议的一种直接应用， 默认基于JSON作为传输格式， 使用简单， 学习成本低， 效率高，但是其安全性较低。 </p></li><li><p>SOAP<br>可以看着是一个重量级的数据交换协议， 基于XML、SOAP在安全方面是通过使用XML-Security和XML-Signature两个规范组成了WS-Security来实现安全控制的， 当前已经得到了各个厂商的支持。 </p></li></ul><p>它的优点， 易用， 灵活， 跨语言， 跨平台。 </p><ul><li>SOA</li></ul><p>面向服务架构， 它可以根据需求通过网络对松散耦合的粗粒度应用组件进行分布式部署， 组合和使用。 服务层是SOA的基础， 可以直接被应用调用， 从而有控制系统中的软件代理交互的人为依赖性。 </p><p>SOA是一种组粒度， 松耦合服务架构，服务之间通过简单、精确定义接口进行通讯， 不涉及底层编程接口和通讯模型。 SOA可以看作是B/S模型 ， XML， WEB Service技术之后的自然延伸。 </p><ul><li><p>5、RPC的实现基础？</p></li><li><p>需要有非常高效的网络通信， 比如一般选择Netty作为网络通讯框架。 </p></li><li>需要有比较高效的序列化框架， 比如谷歌的Protobuf序列化框架；</li><li>可靠的寻址方式（主要是提供服务的发现）， 比如可以使用Zookeeper来注册服务等； </li><li>如果是带会话（状态）的PRC调用， 还需要有会话和状态保持的功能； </li></ul><h2 id="Spring-MVC-框架有什么用？"><a href="#Spring-MVC-框架有什么用？" class="headerlink" title="Spring MVC 框架有什么用？"></a>Spring MVC 框架有什么用？</h2><p>Spring Web MVC 框架提供 模型-视图-控制器 架构和随时可用的组件，用于开始灵活且松散耦合的Web应用程序。 MVC模式有助于分离应用程序的不同方面， 如输入逻辑， 业务逻辑和UI逻辑， 同时在所有的这些元素之间提供松散耦合。 </p><ul><li>描述DispatcherServlet的工作流程</li></ul><p>Http Request -》 DispatcherServler -》 寻找处理器 HandlerMapping<br>                                  -》 适配处理器 HandlerAdapter -》 调用处理器  Handler runner<br>                                  《-  返回ModelAndView<br>                                  -》 ViewResolver<br>                                  -》 Model -》 View （Jsp Jstl）</p><h2 id="Tomcat顶层架构说明："><a href="#Tomcat顶层架构说明：" class="headerlink" title="Tomcat顶层架构说明："></a>Tomcat顶层架构说明：</h2><ul><li><p>Tomcat中只有一个Server， 一个Server可以有多个Service， 一人Service可以有多个Connector和一个Container；</p></li><li><p>Server掌管着整个Tomcat的生死大权； </p></li><li><p>Service是对外提供服务的； </p></li><li><p>Connector是用于接受请求和并将请求封装成Request和Response来具体处理； </p></li><li><p>Container是用于封装和管理Servlet， 以及具体处理request请求； </p></li></ul><p>知道了整个Tomcat的顶层的分层架构和各个组件之间的关系以及作用， 对于绝大多数的开发人员来说Server和Service对我们来说确定很远， 而我们开发中绝大部分进行配置的内容是属于Connector和Container， 所以接下介绍一下Connector和Container； </p>]]></content>
      
      
      
        <tags>
            
            <tag> dubbo rpc 面试 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JVM-one</title>
      <link href="/2019/03/07/JVM-one/"/>
      <url>/2019/03/07/JVM-one/</url>
      
        <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>jvm的知识点汇总共6个大方向， 内存模型、类加载机制、GC垃圾回收是比较重点的内容。 性能调优部分偏重实现应用， 重点突出实践能力。编译器优化执行模式部分偏重理论基础， 主要掌握如下。 </p><ul><li><blockquote><p>内存模型部分： 程序计数器、方法区、堆、栈、本地方法栈的作用， 以及数据保存哪些数据； </p></blockquote></li><li><blockquote><p>类加载部分： 双亲委派的加载机制以及常用类加载器分别加载哪种类型的类</p></blockquote></li><li><blockquote><p>GC部分： 分代回收的思想和依据， 以及不同垃圾回收算法实现的思路、适合的场景</p></blockquote></li><li><blockquote><p>性能调优部分： 常用的jvm的优化参数的作用， 参数调优的依据， 要了解常用的jvm分析工具能分析哪类问题以及使用方法。 </p></blockquote></li><li><blockquote><p>执行模式部分： 解释、编译、混合模式的优缺点， 了解java7提供的分层编译技术。需要知道JIT即时编译技术和OSR也就是栈上替换， 知道C1,C2编译器针对的场景， 其中C2针对server模式， 优化更激进。在新技术方面可以了解一下java10提供的由java实现的graal编译器。 </p></blockquote></li><li><blockquote><p>编译优化部分： 前端编译器javac的编译过程， AST抽象语法树， 编译期优化和运行期优化。 编译优化的常用技术， 包括公共子表达式的消除、方法内联， 逃逸分析， 栈上分配， 同步消除等。 明白了这些才能写出对编译器友好的代码。 </p></blockquote></li></ul><h1 id="Jvm内存相关笔记"><a href="#Jvm内存相关笔记" class="headerlink" title="Jvm内存相关笔记"></a>Jvm内存相关笔记</h1><p>jvm内存模型主要是指在运行时的数据区， 包括5个部分。 </p><p>方法区、堆、程序计数器、栈、本地方法区</p><p>栈也叫方法栈， 是线程私有的， 线程在执行每个方法时都会同时创建一个栈帧， 用来存储局部变量表、操作栈、动态链接、方法出口等信息。 调用方法时执行入栈， 方法返回时执行出栈。 </p><p>本地方法栈与栈类拟， 也是用来保存线程执行方法时的信息， 不同的是， 执行java方法使用栈， 而执行native方法使用本地方法栈。不同的时， 执行java方法使用方法栈， 而执行native方法时则会使用本地方法栈。 </p><p>程序计数器保存着当前线程所执行的字节码位置， 每个线程工作时都有一个独立的计数器，程序计数器为执行java方法服务， 执行native方法时， 程序计数器为空。 </p><p><strong>栈、本地方法栈、程序计数器这三个部分都是线程独占的</strong></p><p><strong>堆</strong>， 是jvm管理的内存中最大的一块，jvm的内存回收就是指的堆的内存回收， 回收机制有很多种（分代回收） 堆被所有线程共享， 目的是为了存放对象实例， 几乎所有的对象实例都在这里分配。 当堆内存没有可用的空间时， 会抛出OOM异常。根据对象存活的周期不同， jvm把堆内存进行分代管理，由垃圾回收器来进行对象的回收管理 。 </p><p>方法区， 也是各个线程共享的内存区域， 又叫非堆区。 用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。 </p><p>jdk1.7中的永久代和1.8中的metaspace都是方法区的一种实现。</p><h1 id="详解-jmm内存可见性"><a href="#详解-jmm内存可见性" class="headerlink" title="详解-jmm内存可见性"></a>详解-jmm内存可见性</h1><p>jmm是java内存模型， 与刚才讲到的jvm内存模型是两回事， jmm的主要目标是定义程序中变量的方问规则， 如果所示， 所有的共享的共享变量都存储在主内存中共享。</p>]]></content>
      
      
      <categories>
          
          <category> jvm java jre info </category>
          
      </categories>
      
      
        <tags>
            
            <tag> jvm java jre info </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SpringBoot-config-one</title>
      <link href="/2019/03/05/SpringBoot-config-one/"/>
      <url>/2019/03/05/SpringBoot-config-one/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>MySQL8.0-note-four</title>
      <link href="/2019/03/04/MySQL8-0-note-four/"/>
      <url>/2019/03/04/MySQL8-0-note-four/</url>
      
        <content type="html"><![CDATA[<h2 id="非递归CTE表达式"><a href="#非递归CTE表达式" class="headerlink" title="非递归CTE表达式"></a>非递归CTE表达式</h2><p>MySQL8.0开始支持通用表表达式（CTE），即WITH子句。 </p><p>如<br>select * from (select 1) as dt;</p><p>通用表表达式</p><p>with cte as (select 1)<br>select * from cte;</p><h3 id="递归CTE"><a href="#递归CTE" class="headerlink" title="递归CTE"></a>递归CTE</h3><p>递归CTE在查询中引用自己的定义， 使用RECURSIVE(recursive) 表示</p><p>with recursive cte(n) as<br>(<br>  select 1<br>  union all<br>  select n + 1 from cte where n &lt; 5<br>)<br>select * from cte;</p><p>例子：</p><p>create table employee(id int not null primary key , name varchar(32), manager_id id);</p><p>insert into employee(id, name, manager_id) values(29, ‘Pedro’, 198), (72,’Pierre’,29),(123,’Adil’,692),(198,’John’,333),(333, ‘Yasmina’, NULL),(692, ‘Tarke’, 333),(4610,’Sarah’ 29);</p><p>with recursive employee_paths(id, name, path) as (<br>    -&gt; select id, name, cast(id as char(2000)) from employee where manager_id is null<br>    -&gt; union all<br>    -&gt; select e.id, e.name, concat(ep.path,’,’,e.id) from employee_paths as ep join employee as e on ep.id = e.manager_id<br>    -&gt; )<br>    -&gt; select * from employee_paths;</p><h2 id="在MySQL8-0之后，如果在使用递归SQL时，-的安全处理"><a href="#在MySQL8-0之后，如果在使用递归SQL时，-的安全处理" class="headerlink" title="在MySQL8.0之后，如果在使用递归SQL时， 的安全处理"></a>在MySQL8.0之后，如果在使用递归SQL时， 的安全处理</h2><p>递归容易导致无限递归的现象， 在MySQL8.0添加了二个全局可以限制不健康的递归操作的发生。 配置：<br>cte_max_recursive_depth， 最大的递归次数配置，默认值为1000，查询, 最大值为：4294967295<br>show variables like ‘cte_max%’;  修改默认值 ：<br>set session cte_max_recursive_depth=5;</p><p>max_execution_time， 最大的SQL执行时间配置, 默认值为0,单位为毫秒， 查看配置<br>show variables like ‘max_execution%’;  修改配置， 修改的可见范围为当前会话<br>set session max_execution_time=1000; 表示最长的SQL不能超过1秒； </p>]]></content>
      
      
      <categories>
          
          <category> mysql 8.0 database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql 8.0 database </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL8.0-note-three</title>
      <link href="/2019/03/04/MySQL8-0-note-three/"/>
      <url>/2019/03/04/MySQL8-0-note-three/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL-8-0索引"><a href="#MySQL-8-0索引" class="headerlink" title="MySQL 8.0索引"></a>MySQL 8.0索引</h2><h3 id="创建索引"><a href="#创建索引" class="headerlink" title="创建索引"></a>创建索引</h3><p>create index i_idx on dbname.tablename(colunm_name);</p><p>新特性，创建一个隐藏索引</p><p>create index j_idx on dbname.tablename(column_name) invisible;<br>即可创建一个隐藏索引； </p><h3 id="显示索引"><a href="#显示索引" class="headerlink" title="显示索引"></a>显示索引</h3><p>show index from dbname.tablename\G;</p><h3 id="MySQL索引的优化器"><a href="#MySQL索引的优化器" class="headerlink" title="MySQL索引的优化器"></a>MySQL索引的优化器</h3><p>explain 索引优化器。 </p><h3 id="查看全局的配置"><a href="#查看全局的配置" class="headerlink" title="查看全局的配置"></a>查看全局的配置</h3><p>select @@optimizer_switch\G</p><p>设置对应的配置项目，语法：</p><p>set session optimizer_switch=”config item  = config value”; </p><p>如： set session optimizer_switch=”use_invisible_indexes=on”; </p><p>表示在当前会话里， 打开隐藏索引的配置开关。 </p><h3 id="查看表的创建SQL"><a href="#查看表的创建SQL" class="headerlink" title="查看表的创建SQL"></a>查看表的创建SQL</h3><p>show create table tablename\G;</p><h3 id="MySQL-8-0里面可以创建降序索引"><a href="#MySQL-8-0里面可以创建降序索引" class="headerlink" title="MySQL 8.0里面可以创建降序索引"></a>MySQL 8.0里面可以创建降序索引</h3><p>显示表的过引情况<br>show index from tablename\G;</p><p>显示表的创建SQL<br>show create table tablename\G;</p><h2 id="函数索引"><a href="#函数索引" class="headerlink" title="函数索引"></a>函数索引</h2><ul><li><p>MySQL 8.0.13开始支持在索引中使用函数（表达式）的值； </p></li><li><p>支持降序过引， 支持JSON数据的索引</p></li><li><p>函数索引基于虚拟列功能的实现； </p></li></ul><p>在以前的MySQL中如果在查询条件里添加了函数，则就不会走相关索引， 但是现在不会了， 可以走索引了。</p><p>如。 </p><p>create index fun_idx on tablename( (lower(column)) );<br>create index fun_c2 on t5( (lower(c2)) );</p><p>创建好后， 就可以通过在条件里面添加函数进行走索引查询了。 </p><p>如： select * from t5 where lower(c2) = ‘abc’;</p><h3 id="JSON字段数据走索引查询"><a href="#JSON字段数据走索引查询" class="headerlink" title="JSON字段数据走索引查询"></a>JSON字段数据走索引查询</h3><p>创建</p><p>create index json_idex on emp((cast(data-&gt;&gt;’$.name’ as char(30))));</p><p>查看索引</p><p>show index from emp\G;</p><p>使用索引</p><p>explain select * from emp where cast(c1-&gt;&gt;’$.name’ as char(30)) = ‘abc’;</p><p>显示走了索引查询； </p><h3 id="通过添加虚拟字段来实现索引效果，"><a href="#通过添加虚拟字段来实现索引效果，" class="headerlink" title="通过添加虚拟字段来实现索引效果，"></a>通过添加虚拟字段来实现索引效果，</h3><p>具体， 新的字段列，可以是通过函数操作别的字段可生成的一个虚拟列，不需要单独插件字段数据； </p><p>创建一个虚拟列</p><p>alter table t3 add column c4 int generated always (c1+c2);</p><p>alter table t3 add column c5 varchar(32) generated always (upper(c3));</p><p>如上创建了一个虚拟的字段是通过给字段c2添加函数式的虚拟字段， 这时如何对新创建的虚拟字段c5创建一个普通索引，如<br>create index c5_idx on t3(c5);<br>这个如果要查询c3字段如果通过函数查询的话，会走这个函数索引<br>select * from t3 where upper(c3) = ‘ABC’;<br>这个查询就会自动走刚才创建的c5字段的索引； 历害的新特性。 </p><p>创建函数索引</p><p>create index fun_c2_idx on t3((upper(c2))); </p>]]></content>
      
      
      <categories>
          
          <category> mysql 8.0 database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql 8.0 database </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL8.0-note-two</title>
      <link href="/2019/03/02/MySQL8-0-note-two/"/>
      <url>/2019/03/02/MySQL8-0-note-two/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL-8-0-里面添加了索引的隐藏、灰色发布"><a href="#MySQL-8-0-里面添加了索引的隐藏、灰色发布" class="headerlink" title="MySQL 8.0 里面添加了索引的隐藏、灰色发布"></a>MySQL 8.0 里面添加了索引的隐藏、灰色发布</h2>]]></content>
      
      
      <categories>
          
          <category> mysql 8.0 database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql 8.0 database </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL8.0-note-one</title>
      <link href="/2019/03/01/MySQL8-0-note-one/"/>
      <url>/2019/03/01/MySQL8-0-note-one/</url>
      
        <content type="html"><![CDATA[<h2 id="MySQL-8-0-新特性"><a href="#MySQL-8-0-新特性" class="headerlink" title="MySQL 8.0 新特性"></a>MySQL 8.0 新特性</h2><ul><li><p>窗口函数</p></li><li><p>InnoDB 增强</p></li><li><p>JSON 增强</p></li><li><p>帐户与安全</p></li><li><p>优化器索引</p></li><li><p>通用表表达式</p></li></ul><h2 id="账户与安全"><a href="#账户与安全" class="headerlink" title="账户与安全"></a>账户与安全</h2><h3 id="用户创建和授权"><a href="#用户创建和授权" class="headerlink" title="用户创建和授权"></a>用户创建和授权</h3><ul><li>【新】MySQL8.0 创建用户和用户授权的命令需要分开执行； </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">创建用户语句：</span><br><span class="line">create user &apos;brenda&apos;@&apos;%&apos; identified by &apos;Brenda@2019&apos;;</span><br><span class="line"></span><br><span class="line">给用户授权：</span><br><span class="line">grant all privileges on *.* to &apos;brenda&apos;@&apos;%&apos;;</span><br><span class="line"></span><br><span class="line">给用户授权远程登录：</span><br><span class="line">alter user &apos;tony&apos;@&apos;%&apos; identified by &apos;Tony@2019&apos;;</span><br></pre></td></tr></table></figure><p>在MySQL之前的版本中， 授权与创建用户可以在一个语句中完成， 如<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grant all privileges on *.* to &apos;tony&apos;@&apos;%&apos; identified by &apos;Tony@2019&apos;;</span><br></pre></td></tr></table></figure></p><p>查询MySQL中的用户信息，如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select host,user from mysql.user;</span><br></pre></td></tr></table></figure></p><h3 id="认证插件更新"><a href="#认证插件更新" class="headerlink" title="认证插件更新"></a>认证插件更新</h3><p>MySQL8.0中默认的身份认证插件是caching_sha2_password, 替代了之前的mysql_native_password.</p><p>default_authentication_plugin</p><p>mysql.user</p><p>查看语句：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;default_authentication%&apos;</span><br><span class="line"></span><br><span class="line">select host, user, plugin from mysql.user;</span><br></pre></td></tr></table></figure></p><p>如何修改8.0的数据库认证方式，<br>在my.cnf配置如下配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">default_authentication_plugin=mysql_native_password;</span><br></pre></td></tr></table></figure></p><p>配置去掉就可以回到。 新的认证；</p><h3 id="查看MySQL8-0的密码策略"><a href="#查看MySQL8-0的密码策略" class="headerlink" title="查看MySQL8.0的密码策略"></a>查看MySQL8.0的密码策略</h3><p>show variables like ‘password%’; </p><p>在mysql8.0后，修改全局属性后， 可以通过以下方式配置， 可以免重启， 如重启后也可以何留配置生效； </p><p>set persist password_history=6;</p><p>实现原理就是通过上述命令，配置后， 会在/var/lib/mysql/mysqld-auto.cnf配置文件里进行配置。如果数据库重新启动后会回载这个配置件里面的配置信息； </p><p>可以设置单个用户用的密码历史级别</p><p>alter user ‘tony‘@’%’ password history 5;</p><p>desc mysql.user;</p><p>alter user ‘tony‘@’%’ identified by ‘Tony@2019’;</p><p>desc mysql.password_history;</p><p>可以配置在修改密码时是否需要提供当前密码， 可以通过修改一个全局配置</p><p>set persist password_requese_current = on;</p><p>alter user user() identified by ‘Tony@2020’ replace ‘Tony@2019’;</p><h3 id="角色管理-，"><a href="#角色管理-，" class="headerlink" title="角色管理 ，"></a>角色管理 ，</h3><p>构造环境：</p><p>create database testdb;</p><p>create table eestdb.t1(id int);</p><ul><li>创建一个角色</li></ul><p>create role ‘wite_role’; </p><p>其实就是创建了一个用户， 以用户的形式来实现一个角色的概念。 </p><ul><li>然后再给这个角色授权， </li></ul><p>grant all (select , update, delete ) on testdb.* to ‘write_role’; </p><ul><li>把用户授权给这个角色</li></ul><p>创建一个用户<br>create user ‘user1’ identified by ‘User1@2019’;</p><p>把这个角色授予这个用户</p><p>grant ‘write_role’ to ‘user1’; </p><ul><li>最后可以查看这个用户的权限</li></ul><p>show grants for ‘user1’; </p><p>也可以通过这样的语句查看</p><p>show grants for ‘user1’ using ‘write_rols’;</p><h4 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h4><p>切换user1用户登录MySQL， 发现用户角色没有授成功， </p><p>select user();<br>select current_role();<br>查询出来发现用户角色并没有被设置，<br>需要通过以下命令再次设置<br>set role ‘write_role’;</p><p>为用户设置默认的角色</p><p>set default role ‘write_role’ to ‘user1’;<br>set default role all to ‘user1’;</p><p>查看用户设置角色的情况<br>select <em> from mysql.default_roles;<br>查看用户与角色之间的配置情况<br>select </em> from mysql.role_deges;</p><h4 id="撤销权限"><a href="#撤销权限" class="headerlink" title="撤销权限"></a>撤销权限</h4><p>revoke insert, update, delete on testdb.* from ‘write_role’; </p><p>把数据库testdb下所有表的insert, update, delete从这个角色里的撤销掉； </p>]]></content>
      
      
      <categories>
          
          <category> mysql 8.0 database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mysql 8.0 database </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ElasticSearch-chapter01</title>
      <link href="/2019/02/28/ElasticSearch-chapter01/"/>
      <url>/2019/02/28/ElasticSearch-chapter01/</url>
      
        <content type="html"><![CDATA[<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li><p>索引：  含有相同属性的文档集合</p></li><li><p>类型：  索引可以定义一个或多个类型， 文档必须属于一个类型</p></li><li><p>文档： 文档是可以被索引的基本数据单位 </p></li><li><p>分片： 每一个索引都有多个分片， 每个分片是一个Lucene索引 </p></li><li><p>备份： 拷贝一份分片就是完成了分片的备份 </p></li></ul><h2 id="elasticSearch集群服务安装"><a href="#elasticSearch集群服务安装" class="headerlink" title="elasticSearch集群服务安装"></a>elasticSearch集群服务安装</h2><h3 id="前提准备"><a href="#前提准备" class="headerlink" title="前提准备"></a>前提准备</h3><p>Jdk1.8+,  nodejs 8.0+  </p><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>w<a href="http://www.elastic.co" target="_blank" rel="noopener">www.elastic.co</a> 官网下载相应的版本安装，如果mac或linux可以载下TAR格式的安装包； </p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>解压</p><p>tar -zxvf ….tar.tz</p><p>解压后， 进行配置</p><p>vim ~/config/elasticsearch.yml , 配置项：</p><ul><li>配置与es-head 管理插件配置合，支持服务间的跨域访问 ：</li></ul><p>http.cors.enabled: true (注， 在冒号后需要有空隔)<br>http.cors.allow-origin: “*” </p><ul><li>配置集群的主配置</li></ul><p>cluster.name: EsServer   配置集群名称<br>node.name: es-master  配置当前节点的名称<br>node.master: true   指定当前节点为主节点<br>network.host: 192.168.1.xx  配置当前节点的IP<br>http.port: 9200 配置节点的服务的端口</p><p>discovery.zen.ping.unicast.hosts: [“adsf”,”xxxx”]  配置集群的所有节点ip</p><p>主节点的相关配置完成。 </p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>sh ./bin/elasticsearch [-d]  表示后台启动服务 </p><h3 id="从节点安装就是"><a href="#从节点安装就是" class="headerlink" title="从节点安装就是"></a>从节点安装就是</h3>]]></content>
      
      
      <categories>
          
          <category> elasticSearch es </category>
          
      </categories>
      
      
        <tags>
            
            <tag> es elastic search service </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Redis-chatper01</title>
      <link href="/2019/02/25/Redis-chatper01/"/>
      <url>/2019/02/25/Redis-chatper01/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis有哪些数据结构？"><a href="#Redis有哪些数据结构？" class="headerlink" title="Redis有哪些数据结构？"></a>Redis有哪些数据结构？</h2><p>字符串： String  可以包含任何数据，比如jpg图片或者序列化的对象， 一个键最大的能存储<em>512M</em></p><p>字典Hash：<br>  键值对集合，即编程语言中的Map类型<br>  适合存储对象，并且可以像数据库中update一个属性一样只修改某一项属性值（Memcached)中需要取出整个字符串反序化成对象修改完再序列化存回去）</p><p>List(列表)：<br>  链表（双向链表）增删块，提供了操作某一段元素的API，如最新消息等功能（比如朋友圈的时间线）消息队列</p><p>Set（集合）哈希表实现，元素不重复， 添加删除查找的复杂度都是0（1）2， 为集合提供了求交集， 并集、差集等操作，如共同好友， 访问IP</p><p>SortedSet(有序集合) 将Set中的元素增加一个权重参数score元素按score有序排列。 数据插入集合时， 已经进行天然的排序，如排列榜； 再权重的消息队列； </p><p>列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。</p><p>每一个redis可以有16个默认的表， 每个表之间是隔离的。 可以自行无限创建 。 </p><p>每秒可以处理超过10W次的读写操作， 是已知性能最快的Key-Value DB。 Redis的出色之处不仅仅是性能， 单个value的最大限制是1GB， 而memcached只能保存1MB的数据。 可以定期的通过异步操作把数据库数据flush到硬盘上进行保存。 </p><h2 id="Redis-相比-memcached有哪些优势？"><a href="#Redis-相比-memcached有哪些优势？" class="headerlink" title="Redis 相比 memcached有哪些优势？"></a>Redis 相比 memcached有哪些优势？</h2><ul><li>redis 支持的数据结构丰富， String / map(k-v)/ List/ Set/ SordSet</li><li>速度要快的多</li><li>R可以持久化数据，因为常规是在内存上操作， 数据有丢失的危险</li></ul><h2 id="Redis支持哪几个数据类型-："><a href="#Redis支持哪几个数据类型-：" class="headerlink" title="Redis支持哪几个数据类型 ："></a>Redis支持哪几个数据类型 ：</h2><p>String / List  /Set  / SortedSet / hashes(字典hash)</p><h2 id="Redis主要消耗什么物理资源？"><a href="#Redis主要消耗什么物理资源？" class="headerlink" title="Redis主要消耗什么物理资源？"></a>Redis主要消耗什么物理资源？</h2><p>主要是使用内存来处理数据存储，内存</p><h2 id="Redis-全称为？"><a href="#Redis-全称为？" class="headerlink" title="Redis 全称为？"></a>Redis 全称为？</h2><p>Remote Dictionary Server<br>Remote Dictionary Server<br>Remote Dictionary Server</p><h2 id="Redis有哪几种数据淘汰策略？"><a href="#Redis有哪几种数据淘汰策略？" class="headerlink" title="Redis有哪几种数据淘汰策略？"></a>Redis有哪几种数据淘汰策略？</h2><ul><li><p>noeviction: noeviction 返回错误当内存限制达到并且客户端尝试执行会让更多的内存被使用的命令， 不主动淘汰数据，除了del主动删除</p></li><li><p>allkeys-lru ： 尝试回收最近最少使用的键（LRU）， 使得新添加的数据有空间存放  。 </p></li><li><p>volatile-lru: 在过期集合中回收最近最少使用的键</p></li><li><p>allkeys-random： 在合的的集中的随机删除，</p></li><li><p>volatile-random： 仅在过期的集合中， 随机删除</p></li><li><p>volatile-ttl： 回收在过期集合的键， 并且优先回收存话时间（TTL）较短的键， 使得新添加的数据有空间可存放。 </p></li></ul><h2 id="一个字符串类型能存储最大容量是多少？"><a href="#一个字符串类型能存储最大容量是多少？" class="headerlink" title="一个字符串类型能存储最大容量是多少？"></a>一个字符串类型能存储最大容量是多少？</h2><p>redis中最放字符串最大值为512M， Momcatched最大为1M</p><h2 id="Redis集群方案应用怎么做？-都有哪些方案？"><a href="#Redis集群方案应用怎么做？-都有哪些方案？" class="headerlink" title="Redis集群方案应用怎么做？ 都有哪些方案？"></a>Redis集群方案应用怎么做？ 都有哪些方案？</h2><h2 id="Redis如何设置密码及验证密码？"><a href="#Redis如何设置密码及验证密码？" class="headerlink" title="Redis如何设置密码及验证密码？"></a>Redis如何设置密码及验证密码？</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">设置密码： config set requirepass 123456</span><br><span class="line">授权密码： auth 123456</span><br></pre></td></tr></table></figure><h2 id="Jedis与Redisson对比什么优缺点？"><a href="#Jedis与Redisson对比什么优缺点？" class="headerlink" title="Jedis与Redisson对比什么优缺点？"></a>Jedis与Redisson对比什么优缺点？</h2><p>Jedis是Redis的Java实现的客户端， 其API提供了比较全面的Redis命令的支持； Reddisson实现了分布式和可扩展的Java数据结构， 和Jedis相比， 功能较为简单， 不支持字符串操作， 不支持排序、事务、管道、分区等Redis特生。 Redisson的宗旨是促进使用者对Redis的关注分离， 从而让使用者能够将精力更集中地放在处理业务逻辑上。 </p><p>## </p>]]></content>
      
      
      <categories>
          
          <category> redis config nosql cacheserver </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis config nosql cacheserver </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spring-aop-@Pointcut</title>
      <link href="/2019/02/19/spring-aop-Pointcut/"/>
      <url>/2019/02/19/spring-aop-Pointcut/</url>
      
        <content type="html"><![CDATA[<h1 id="Spring-AOP-中-Pointcut的用法"><a href="#Spring-AOP-中-Pointcut的用法" class="headerlink" title="Spring AOP 中@Pointcut的用法"></a>Spring AOP 中@Pointcut的用法</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">配置格式 ：</span><br><span class="line">execution(modifiers-pattern? ret-type-pattern declaring-type-pattern? name-pattern(param-pattern) throws-pattern?)</span><br></pre></td></tr></table></figure><p>以上各个配置说明：问号表示可选配置</p><ul><li>修饰符匹配（modifiers-pattern?) </li><li>返回值匹配（ret-type-pattern),可以为*表示任何返回值，全路径的类名等</li><li>类路径匹配（declaring-type-pattern?) </li><li>方法名匹配（name-pattern) 可以指定方法名，或用<em>代表所有，set</em>,代表set开头的所有方法</li><li>参数匹配（param-pattern)可以指定具体的参数类型 ， 多个参数间用“，”隔开， 各个参数也可以用“<em>”来表示匹配任意类型的参数， 如（String）表示匹配一个String参数的方法；（</em>，String）表示匹配有二个参数的方法， 第一个参数可以是任意类型， 而第二个参数是String类型； 可以用（..)表示零个或多个任意参数</li><li>异常类型匹配（throws-pattern?)</li><li>其中后面跟着“？“表示是可选项。</li></ul><p>如：<br><code>`</code></p><p>execution(<em> </em>(..)) //表示匹配所有的方法</p><p>execution(public <em> com.savage.service.UserService.UserService.</em>(..))<br>// 表示匹配com.savage.service.UserService中所有的公有方法，匹配任意参数</p><p>execution(<em> com.savage.server..</em>.*(..))<br>//表示匹配com.savage.server包及其子包下所有的方法</p>]]></content>
      
      
      <categories>
          
          <category> aop pointcut aspect springcloud </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aop pointcut aspect springcloud </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Ajax-cross-domain</title>
      <link href="/2019/02/16/Ajax-cross-domain/"/>
      <url>/2019/02/16/Ajax-cross-domain/</url>
      
        <content type="html"><![CDATA[<h1 id="深度讨论-amp-分析AJAX在请求过程中的跨域问题！！"><a href="#深度讨论-amp-分析AJAX在请求过程中的跨域问题！！" class="headerlink" title="深度讨论&amp;分析AJAX在请求过程中的跨域问题！！"></a>深度讨论&amp;分析AJAX在请求过程中的跨域问题！！</h1><h2 id="出现跨域问题的三个条件："><a href="#出现跨域问题的三个条件：" class="headerlink" title="出现跨域问题的三个条件："></a>出现跨域问题的三个条件：</h2><ul><li>1、 浏览器访问</li><li>2、 跨域访问： ip + port</li><li>3、 发送了XHR（XMLHTTPRequest）请求</li></ul><h2 id="第一种解决跨域的方案：-Jsonp"><a href="#第一种解决跨域的方案：-Jsonp" class="headerlink" title="第一种解决跨域的方案： Jsonp"></a>第一种解决跨域的方案： Jsonp</h2><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>就是通过一个小众的jsonp协议来做到绕开浏览器跨域问题。以上提到了出现跨域问题的原因以三个条件。 采用jsonp就是让发送的请求不是xhr类型，而成为script类型 ，如采用jquery发送jsonp ajax请求代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$.ajax(&#123;</span><br><span class="line">  url: base + &quot;/xxx&quot;,</span><br><span class="line">  dataType: &quot;jsonp&quot;,</span><br><span class="line">  jsonp: &quot;callback2&quot;,</span><br><span class="line">  cache: true,</span><br><span class="line">  success: function(json)&#123;</span><br><span class="line">    result = json;</span><br><span class="line">  &#125;,</span><br><span class="line">  error: function(err) &#123;</span><br><span class="line">    console.log(err);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">注： 通过dataType指定jsonp的请求类型 ， 在真实的请求中会表现成为script;</span><br><span class="line">jsonp: 是指定， 前台发送请求后， 后台区别于jsonp请求的标识，后台也需要指定这个标识；</span><br><span class="line">cache: 表示在发送请求时是否需要被缓存， 默认是不被缓存， 即在发起请求时会在后面添加一个_为key的随时值 ；</span><br></pre></td></tr></table></figure></p><p>通过上述发送请求的逻辑， 表示， 后台在处理jsonp请求是也是需要做特殊处理的， 所以后台也是需要进行代码调整的。 </p><p>一般处理思路是针对controller添加一个切面处理类（@ControllerAdvice)： 再判断每一次请求是否是一个jsonp的请求。 所以jsonp也会对服务的性能有一定的影响。小的应用一般可以忽略。 </p><h3 id="JSONP的处理跨域的弊端"><a href="#JSONP的处理跨域的弊端" class="headerlink" title="JSONP的处理跨域的弊端"></a>JSONP的处理跨域的弊端</h3><ul><li><p>服务器的代码需要个性， 性能有一定的影响</p></li><li><p>只支持GET请求</p></li><li><p>发送的不是XHR请求， （XMLHttpRequest请求本身有很多的特性， 如果异步、http2的支持等等）</p></li></ul><p>所以jsonp处理跨域不是一定很理解的处理方案， 在小型的应用里可以考虑。</p><h2 id="第二种-，-被调用方解决-–-跨域问题"><a href="#第二种-，-被调用方解决-–-跨域问题" class="headerlink" title="第二种 ， 被调用方解决 – 跨域问题"></a>第二种 ， 被调用方解决 – 跨域问题</h2><ul><li><p>服务器端实现</p></li><li><p>Nginx配置实现</p></li><li><p>Apache配置实现</p></li></ul><p>不管是那个实现， 思路就是在 <strong><em>请求头上</em></strong> 应该是在响应头上添加信息， 告诉这次请求是允许跨域请求的。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res.addHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;http://localhost:8081&quot;);</span><br><span class="line">res.addHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;GET&quot;);</span><br><span class="line"></span><br><span class="line">后面二个配置可以都可以用* 可配置。</span><br></pre></td></tr></table></figure><h3 id="简单请求-和-非简单请求"><a href="#简单请求-和-非简单请求" class="headerlink" title="简单请求 和  非简单请求"></a>简单请求 和  非简单请求</h3><p>说明： 简单请求： 对于浏览器来讲是先发送请求（即后台会先响应给数据）再判断安全， 如果是跨域了就会报错 ，其实这时已经拿到的请求响应的数据了。<br>什么情况属于简单请求呢：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">方法为： </span><br><span class="line">  GET</span><br><span class="line">  HEAD</span><br><span class="line">  POST</span><br><span class="line">请求header里面：</span><br><span class="line">  无自定义头</span><br><span class="line">  Content-Type为以下几种情况：</span><br><span class="line">    text/plain</span><br><span class="line">    multipart/form-data</span><br><span class="line">    application/x-www-form-urlencoded</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">返之， 非简单请求有：</span><br><span class="line">  put, delete 方法的ajax请求</span><br><span class="line">  发送json格式的ajax请求</span><br><span class="line">  带自定义头的ajax请求</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">非简单请求会发出一条预检命令， options,  这个预检命令的类型是Content-Type，所以在后台可以配置允许访问，配置如下：</span><br><span class="line">res.addHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type&quot;);</span><br><span class="line">即， 非简单请求一会会发出二条， </span><br><span class="line">1条是预检请求， 通过后， </span><br><span class="line">2再发一条真正的数据请求； </span><br><span class="line">这样明显就会存在性能问题， 也就是说每一个非简单的请求都会发送二次请求， 应该是有可以优化的方法， 通用是考虑把预检的配置先缓存起来了， 配置如下：</span><br><span class="line"></span><br><span class="line">res.addHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;)</span><br><span class="line">配置服务器针对非简单请求的预检信息在3600秒之内缓存了预检命令， 在3600秒之内客户端就可以不再发送预检请求了。 以提升性能 。 </span><br><span class="line">注： 这个预检命令的缓存是会缓存在浏览器客户端的，而不是缓存在服务器端。</span><br></pre></td></tr></table></figure><p>注： 要想在后台代码里拿到指定key的cookie的值 ， 可以通过如下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getCookie</span><span class="params">(@CookieValue(value = <span class="string">"cookie1"</span>)</span> String cookie1) </span>&#123;</span><br><span class="line">  System.out.println(cookie1);</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">这里的cookie1就是拿到了key= cookie1的值 ； </span><br><span class="line"></span><br><span class="line">前端构造一个发送带上cookie的ajax请求：</span><br><span class="line"></span><br><span class="line">$.ajax(&#123;</span><br><span class="line">  type: <span class="string">"get"</span>,</span><br><span class="line">  url: base + <span class="string">"/getCookie"</span>,</span><br><span class="line">  xhrFields: &#123;</span><br><span class="line">    withCredentials: <span class="keyword">true</span></span><br><span class="line">  &#125;,</span><br><span class="line">  success: function(json) &#123;</span><br><span class="line">    result = json;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;); </span><br><span class="line"></span><br><span class="line">  xhrFields: &#123;</span><br><span class="line">    withCredentials: <span class="keyword">true</span></span><br><span class="line">  &#125;,</span><br><span class="line"></span><br><span class="line">  表示发送请求时会带上cookie信息； </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  服务端的配置如下：</span><br><span class="line"></span><br><span class="line">  res.addHeader(<span class="string">"Access-Control-Allow-Origin"</span>, <span class="string">"http://localhost:8080"</span>);<span class="comment">// 这个配置不能配置星号 * ， 这个配置就有一个问题来了， 有了硬编码， 需要解决。 思路是可以通过request取到请求头里面的Origin的值 ，并配置即可。 </span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  res.addHeader(<span class="string">"Access-Control-Allow-Methods"</span>, <span class="string">"*"</span>)</span><br><span class="line">  res.addHeader(<span class="string">"Access-Control-Headers"</span>, <span class="string">"Content-Type"</span>);</span><br><span class="line">  res.addHeader(<span class="string">"Access-Control-Max-Age"</span>, <span class="string">"3600"</span>)</span><br><span class="line">  <span class="comment">//另外还要添加一个</span></span><br><span class="line">  res.addHeader(<span class="string">"Access-Control-Allow-Credentials"</span>, <span class="string">"true"</span>); <span class="comment">// 这个是处理还cookie跨域请求的配置；</span></span><br></pre></td></tr></table></figure></p><p>在controller里面获取请求头的信息，代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getHeader</span><span class="params">(@RequestHeader(<span class="string">"x-header1"</span>)</span> String header1) </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  header1 就是取到的请求头部的值 ； </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="Ngin里面处理跨域的问题"><a href="#Ngin里面处理跨域的问题" class="headerlink" title="Ngin里面处理跨域的问题"></a>Ngin里面处理跨域的问题</h2><p>配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">add_header Access-Control-Allow-Methods *;</span><br><span class="line">add_header Access-Control-Max-Age 3600;</span><br><span class="line">add_header Access-Control-Allow-Credentials true;</span><br><span class="line"></span><br><span class="line">add_header Access_Control-Allow-Origin $http_origin;</span><br><span class="line">add_header Access_Control-Allow-Headers $http_access_control_request_headers;</span><br><span class="line"></span><br><span class="line">// 这个处理是把所有的预检请求都成功返回， 不需要再发送到后台服务器， </span><br><span class="line">if ($request_method = OPTIONS) &#123;</span><br><span class="line">  return 200;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">这个处理方案是最优的。</span><br></pre></td></tr></table></figure><h3 id="最后种，-Spring框架的跨域解决方案"><a href="#最后种，-Spring框架的跨域解决方案" class="headerlink" title="最后种， Spring框架的跨域解决方案"></a>最后种， Spring框架的跨域解决方案</h3><p>非常简单， 思路还是通过强大的注解还搞定</p><p>@CrossOrigin </p><p>@CrossOrigin(allowCredentials=”true”)</p><p>即可。 </p><h2 id="第三种-，-调用方解决-–-跨域问题"><a href="#第三种-，-调用方解决-–-跨域问题" class="headerlink" title="第三种 ， 调用方解决 – 跨域问题"></a>第三种 ， 调用方解决 – 跨域问题</h2><p>原因， 就可能在被 调用方我们无法解决跨域问题没有编码权限， 所以可以考虑在调用方进行解决， 思路是绕过浏览器的安全跨域检查， 可以通过nginx的反向代理的功能来实现，具体配置demo如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">server&#123;</span><br><span class="line">    <span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line">    <span class="attribute">server_name</span> a.com;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">location</span> / &#123;</span><br><span class="line">      proxy_pass http://localhost:8081/; // 前端请求</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="attribute">location</span> /ajaxrequest &#123;</span><br><span class="line">      proxy_pass http://localhost:8080/; // 后端的真实请求； </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">通过以上配置后， 在前端请代码里面就只要向/ajaxrequest的url的发起请求， 就nginx再代理到真正的服务器上去处理。</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      <categories>
          
          <category> ajax cross domain miroservice </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ajax cross domain miroservice </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>mac-nodejs-version</title>
      <link href="/2019/02/16/mac-nodejs-version/"/>
      <url>/2019/02/16/mac-nodejs-version/</url>
      
        <content type="html"><![CDATA[<h2 id="mac下命令行安装node-js及切换不同版本nodejs"><a href="#mac下命令行安装node-js及切换不同版本nodejs" class="headerlink" title="mac下命令行安装node.js及切换不同版本nodejs"></a>mac下命令行安装node.js及切换不同版本nodejs</h2><p><em>前提：在电脑上已经安装了node.js然后才能采用以下命令（以下代码最好不要同时运行）</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo n --lastest // 安装最新版本</span><br><span class="line">sudo n --stable  // 安装稳定版本</span><br><span class="line">sudo n 4.x   // 安装4系列的版本</span><br><span class="line">sudo n 6.x  // 安装6系列的版本</span><br></pre></td></tr></table></figure><h3 id="切换"><a href="#切换" class="headerlink" title="切换"></a>切换</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">sudo n</span><br></pre></td></tr></table></figure><p>可以查看到电脑已经安装的所有版本， 高亮显示的版本就是当前运行的node.js版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">node / 10.5.1</span><br><span class="line">node / 11.0.1</span><br></pre></td></tr></table></figure><p>需要在电脑上运行什么版本， 只需要当下移动光标选中，回车确认即可生效。 </p>]]></content>
      
      
      <categories>
          
          <category> mac nodejs version upgrade </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mac nodejs version upgrade </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SpringCloud_001.md</title>
      <link href="/2019/01/25/SpringCloud-001-md/"/>
      <url>/2019/01/25/SpringCloud-001-md/</url>
      
        <content type="html"><![CDATA[<h1 id="在docker里安装RabbitMQ"><a href="#在docker里安装RabbitMQ" class="headerlink" title="在docker里安装RabbitMQ"></a>在docker里安装RabbitMQ</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --hostname my-rabbit -p 5672:5672 -p 15672:15672 rabbitmq:3.7.8-management</span><br></pre></td></tr></table></figure><p>如上：<br>docker 容器命令<br>5672  rabbitmq对外服务端口<br>15672  rabbiqmq管理服务的访问端口</p><h1 id="spring-cloud中常用的网关方案"><a href="#spring-cloud中常用的网关方案" class="headerlink" title="spring cloud中常用的网关方案"></a>spring cloud中常用的网关方案</h1><ul><li>Nginx + lua</li><li>Tyk （go开发的语言）</li><li>Kong  (基于nginx 基大部分插件是收费的商业插件)</li><li>spring cloud Zuul</li></ul><h1 id="Zuul的特点"><a href="#Zuul的特点" class="headerlink" title="Zuul的特点"></a>Zuul的特点</h1><ul><li><p>路由 + 过滤器 = Zuul </p></li><li><p>核心是一系列的过滤器 </p></li></ul><h1 id="Git操作标准"><a href="#Git操作标准" class="headerlink" title="Git操作标准"></a>Git操作标准</h1><p>git reset –hard 分支id</p><p>表示将当前目录所的分支强行的重置到指定的源码分支上。 </p><h2 id="查看运行容器"><a href="#查看运行容器" class="headerlink" title="查看运行容器"></a>查看运行容器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure><h2 id="查看所有容器"><a href="#查看所有容器" class="headerlink" title="查看所有容器"></a>查看所有容器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br></pre></td></tr></table></figure><h2 id="进入容器"><a href="#进入容器" class="headerlink" title="进入容器"></a>进入容器</h2><p>其中字符串为容器ID：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it 容器ID /bin/bash</span><br></pre></td></tr></table></figure></p><h3 id="停止全部运行中的容器"><a href="#停止全部运行中的容器" class="headerlink" title="停止全部运行中的容器"></a>停止全部运行中的容器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker stop $(docker ps -q)</span><br></pre></td></tr></table></figure><h3 id="删除全部容器"><a href="#删除全部容器" class="headerlink" title="删除全部容器"></a>删除全部容器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm $(docker ps -aq)</span><br></pre></td></tr></table></figure><h3 id="一条命令实现停用并删除容器"><a href="#一条命令实现停用并删除容器" class="headerlink" title="一条命令实现停用并删除容器"></a>一条命令实现停用并删除容器</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">docker stop $(docker ps -q) &amp; docker rm $(docker ps -aq)</span><br><span class="line"></span><br><span class="line">**附：**</span><br><span class="line">docker ps         # 查看正在运行的容器</span><br><span class="line">docker ps -a      # 查看所有容器</span><br><span class="line">docker ps -l      # 查看最近一次运行的容器</span><br><span class="line"></span><br><span class="line">docker create 容器名或者容器ID    # 创建容器</span><br><span class="line">docker start [-i] 容器名        # 启动容器</span><br><span class="line">docker run 容器名或者容器ID       # 运行容器，相当于docker create + docker start</span><br><span class="line">docker attach 容器名或者容器ID bash     # 进入容器的命令行（退出容器后容器会停止）</span><br><span class="line">docker exec -it 容器名或者容器ID bash   # 进入容器的命令行</span><br><span class="line">docker stop 容器名                    # 停止容器</span><br><span class="line">docker rm 容器名                      # 删除容器</span><br><span class="line"></span><br><span class="line">docker top 容器名                    # 查看WEB应用程序容器的进程</span><br><span class="line">docker inspect 容器名                # 查看Docker的底层信息</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> spring cloud springboot service </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springcloud springboot service </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CMS，知识点整理</title>
      <link href="/2018/12/24/java-jvm-cms/"/>
      <url>/2018/12/24/java-jvm-cms/</url>
      
        <content type="html"><![CDATA[<h2 id="CMS基础"><a href="#CMS基础" class="headerlink" title="CMS基础"></a>CMS基础</h2><p>CMS收集器，Mostly-Concurrent收集器， 也称并发票记清除收集器（Concurrent Mark-Sweep GC, CMS收集器）， 它管理新生代的方式与Parallel收集器和Serial收集器相同， 而在老年代则是尽可能得并发执行，每一个垃圾收集器周期只有2次短停顿。</p><p>注： CMS是最主要的并发收集器； 不仅针对老年代资源， 而最对新生代的资源同样生效， 只是针对新生代的收集与Parallel和Serial相同；</p><p><strong>CMS的初衷和目的：为了消除Throught收集器和Serial收集器在Full GC周期中的长时间停顿。</strong></p><p>CMS的适用场景：如果你的应用需要更快的响应， 不希望有长时间的停顿， 同时你的CPU资源也比较丰富， 就适合适用CMS收集器。 </p><h2 id="CMS的过程"><a href="#CMS的过程" class="headerlink" title="CMS的过程"></a>CMS的过程</h2><ul><li>CMS的正常过程, </li></ul><p>先看下CMS并发收集周期正常完成的几个状态：</p><ul><li><p>SWT 初始标记， 这个阶段是标记GcRoots直接可达老年代对象、新生代引用的老年代对象。<em>这个过程是单线程的</em>。</p></li><li><p>并发标记， </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> cms jvm gc Throught Serial </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cms gc full gc </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Nginx在处理请求的11个过程中的Content的处理阶段笔记</title>
      <link href="/2018/12/20/nginx-http-content-module/"/>
      <url>/2018/12/20/nginx-http-content-module/</url>
      
        <content type="html"><![CDATA[<h2 id="在content阶段分如下几个过程："><a href="#在content阶段分如下几个过程：" class="headerlink" title="在content阶段分如下几个过程："></a>在content阶段分如下几个过程：</h2><ul><li>concat</li><li>random_index</li><li>index</li><li>auto_index </li><li>static</li></ul><h2 id="static-过程中提供了root-和-alias"><a href="#static-过程中提供了root-和-alias" class="headerlink" title="static 过程中提供了root 和 alias"></a>static 过程中提供了root 和 alias</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Syntax: alias path;</span><br><span class="line">Default: ----</span><br><span class="line">Context: location </span><br><span class="line"></span><br><span class="line">Syntax: root path;</span><br><span class="line">Default:  root  html;</span><br><span class="line">Context:  http, server, location, if in location ;</span><br></pre></td></tr></table></figure><p>说明：<br>|相同|不同|<br>|:—:|:—:|<br>|都是将url映射为文件路径， 以返回静态文件内容| root会将完整url映射进文件路径中；alias只会将location后URL映射到文件路径中|</p><h1 id="static模块针对uri不以斜杠结尾的请求有以下三个控制方法；"><a href="#static模块针对uri不以斜杠结尾的请求有以下三个控制方法；" class="headerlink" title="static模块针对uri不以斜杠结尾的请求有以下三个控制方法；"></a>static模块针对uri不以斜杠结尾的请求有以下三个控制方法；</h1><ul><li><p>absolute_redirect  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Syntax:  absolute_redirect   on|off;</span><br><span class="line">Default: absolute_redirect   on;</span><br><span class="line">Context:  http, server, location </span><br><span class="line"></span><br><span class="line">说明： </span><br><span class="line">  默认配置是on，表示在301重定向时会把$request_uri的值自动拼在请求目录的前面； 但是如果在请求的头部如果有HOST的值时，会把HOST的值自动拼接在请求的目录前面国；</span><br><span class="line">  如果修改成off的值 后， 则在301重定后， 不会拼接这个值 ；</span><br></pre></td></tr></table></figure></li><li><p>port_in_redirect </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Syntax:  port_in_redirect on|off;</span><br><span class="line">Default: port_in_redirect  on;</span><br><span class="line">Contect:  http, server, location </span><br><span class="line"></span><br><span class="line">不加说明，直译就可以；</span><br></pre></td></tr></table></figure></li><li><p>server_name_in_redirect  on|off;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Syntax: server_name_in_redirect  on|off;</span><br><span class="line">Default: server_name_in_redirect  off;</span><br><span class="line">Context: http, server, location</span><br><span class="line">说明：</span><br><span class="line">  配置on ， 表示以server_name里的主域名进行重定向； </span><br><span class="line">  配置off， 表示关闭，仍然按照absolute_redirect进行配置规则重定向；</span><br></pre></td></tr></table></figure></li></ul><h2 id="在content阶段，-index-与-autoindex的使用说明："><a href="#在content阶段，-index-与-autoindex的使用说明：" class="headerlink" title="在content阶段， index 与 autoindex的使用说明："></a>在content阶段， index 与 autoindex的使用说明：</h2><ul><li>index 生效的优先级比 autoindex要高； </li><li>index 方法是默认在nginx包里，无法移除；</li><li>如果在访问的目录下有index默认指定的index.html页面时， 那么autoindex是不可能执行的； </li><li>如果要让autoindex生效， 就需要让index执行访问不会对应的页面即楞； </li><li>autoindex在显示文件目录结构时， 可以指定不同的显示格式 如html, json， xml， jsonp;</li><li>可以通过–without-http_autoindex_module将些模块移除；<br>配置命令如下：<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">index</span>  index.html ;</span><br><span class="line"><span class="attribute">autoindex</span> <span class="literal">on</span>; <span class="comment">#可以配置成on|off;</span></span><br><span class="line"><span class="attribute">autoindex_format</span>  html|xml|jsp|jsonp;</span><br><span class="line"><span class="attribute">autoindex_localtime</span> <span class="literal">on</span>|<span class="literal">off</span>;</span><br><span class="line"><span class="attribute">autoindex_exact_size</span> <span class="literal">on</span>|<span class="literal">off</span>;</span><br></pre></td></tr></table></figure></li></ul><h2 id="重点-提升性能：-content阶段的concat模块"><a href="#重点-提升性能：-content阶段的concat模块" class="headerlink" title="[重点] 提升性能： content阶段的concat模块"></a>[重点] 提升性能： content阶段的concat模块</h2><ul><li><p>功能， 当页面需要访问多个小文件时， 把它们的内容合并到一次http响应中返， 以提升性能； ；</p></li><li><p>安装方法， ngx_http_concat_module,需要从Tengine(<a href="https://github.com/alibaba/nginx_http_concat),在编译时通过--add-module=../nginx-http-concat/" target="_blank" rel="noopener">https://github.com/alibaba/nginx_http_concat),在编译时通过--add-module=../nginx-http-concat/</a></p></li><li><p>使用： 在URI后加上？？， 后通过多个， 逗号分隔文件。 如果还有参数， 则在最后通过？添加参数；</p></li></ul><h2 id="重点-在Nginx里面加包引入ngx-http-concat-module模块"><a href="#重点-在Nginx里面加包引入ngx-http-concat-module模块" class="headerlink" title="[重点] 在Nginx里面加包引入ngx_http_concat_module模块"></a>[重点] 在Nginx里面加包引入ngx_http_concat_module模块</h2><p>首先， 如何将第三方的nginx模块打进nginx里面</p><ul><li><p>下载第三方的模块源码， 如：<a href="https://github.com/alibaba/nginx-http-concat" target="_blank" rel="noopener">ngx_http_concat_module</a></p></li><li><p>把下载好的源文件拷贝到nginx源码目录同级目录下，然后进编译，命令如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./configure --add-module=../nginx-http-concat/ --with-http_auth_request_module</span><br><span class="line">--add-module表示打包第三方源码包； </span><br><span class="line">--with添加nginx里面的源码包；</span><br><span class="line">--without去除nginx里面的源码包；</span><br></pre></td></tr></table></figure></li><li><p>编译完成后， make，完成后， 再进行在线升级nginx，升级步骤如下：</p><blockquote><ul><li>备份线上nginx sbin目录下的nginx二进制文件；  </li><li>将编译好的新的nginx文件拷贝到这里， 命令如下：<figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">cp</span> **/nginx-****/objs/nginx ***/nginx-<span class="number">1</span>***/sbin/ -f </span><br><span class="line">一定要添加-f参数， 否则无法替换文件件； </span><br><span class="line">注意： 由于编译了第三方的源码模块， 这里还需要把编译好的addon目录拷贝到nginx/sbin/目录下</span><br></pre></td></tr></table></figure></li></ul></blockquote></li></ul><blockquote><ul><li>完成文件拷贝后， 再通过给master进程发送相关信息号完成nginx的平滑升级 </li><li>ps -ef|grep nginx 查看到nginx master进程的ID</li><li>kill -USR2  pid;   向master进程发送USR2信号， 会启动一套信息的工作进程； </li><li>kill -WINCH oldpid; 向旧的master进程发送WINCH信号， 表示让旧的master进程关闭掉worker进程， 这时需要注意， 有时可能worker短时间无法关闭掉， 这时需要配置一个关闭的参数指定最长关闭时间； </li><li>到些， 会有二个master进程，一个新的一个旧的， 主要是为以防止升级完nginx后，有问题方便 回滚； 回滚操作：</li><li>第一，给旧的master进程发送 HUP信号， 表示再次根据配置信息，创建出worker进程； </li><li>第二， 给新的master进程发送 QUIT信息号， 表示将新的master进程优雅的退出掉； </li><li>到此完成了回滚操作； </li></ul></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Nginx content static auto_index index random_index concat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx-http_nginx中http模块整理</title>
      <link href="/2018/12/17/nginx-http/"/>
      <url>/2018/12/17/nginx-http/</url>
      
        <content type="html"><![CDATA[<h2 id="ngx-http-referer-module"><a href="#ngx-http-referer-module" class="headerlink" title="ngx_http_referer_module"></a>ngx_http_referer_module</h2><p>是一个防盗链处理的模块； </p><h2 id="listen指定配置"><a href="#listen指定配置" class="headerlink" title="listen指定配置"></a>listen指定配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">listen unix:/var/run/nginx.sock;</span><br><span class="line">listen 127.0.0.1:8000;</span><br><span class="line">listen 127.0.0.1;</span><br><span class="line">listen 8000;</span><br><span class="line">listen *:8000;</span><br><span class="line">listen localhost:8000 bind;</span><br><span class="line">listen [::]:8000 ipv6only=on;</span><br><span class="line">listen [::1];</span><br></pre></td></tr></table></figure><h2 id="接收请求事件模块流程"><a href="#接收请求事件模块流程" class="headerlink" title="接收请求事件模块流程"></a>接收请求事件模块流程</h2><p>第一步： 操作系统内核：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SYN</span><br><span class="line">SYN + ACK</span><br><span class="line">ACK (负载均衡选中CPU上的worker)</span><br></pre></td></tr></table></figure></p><p>第二步： 事件模块：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">epoll_wait</span><br><span class="line"></span><br><span class="line">accept, 分配连接内存池</span><br><span class="line">（connection_pool_size: 512）</span><br><span class="line">这个内存还不是解析请求uri的所需内存， 是用来存储连接用的； </span><br><span class="line"></span><br><span class="line">epoll_wait</span><br></pre></td></tr></table></figure></p><p>第三步： HTTP模块：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ngx_http_init_commection 设置回调方法， ecpoll_wait， 添加超时定时器</span><br><span class="line">client_header_timeout: 60s; 在这里创建了一个请求连接的超时时间，如果在这个时间内没有获取连接，就会自动超时断开连接； </span><br><span class="line"></span><br><span class="line">ngx_http_wait_request_handler 分配内存， read读缓冲区</span><br><span class="line">client_header_buffer_size: 1K;</span><br><span class="line">用来存放请示头部的信息，主要可能是cookie比较大</span><br></pre></td></tr></table></figure><h2 id="接收请求HTTP模块"><a href="#接收请求HTTP模块" class="headerlink" title="接收请求HTTP模块"></a>接收请求HTTP模块</h2><p>接收URI<br>分配请求内存池（request_pool_size: 4K)<br>这个分配的内存是用来存放解新http请求URI的数据，如果内容很大。 会进行大内存分配<br>large_client_header_buffers: 4 8K<br>会进行四次递增分配，每次8K， 不会一下分配出32k的内存空间； </p><h2 id="处理请求头部数据"><a href="#处理请求头部数据" class="headerlink" title="处理请求头部数据"></a>处理请求头部数据</h2><p>过大的请求头部</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">default:</span><br><span class="line"></span><br><span class="line">Syntax:  client_header_buffer_size size;</span><br><span class="line">Default:   client_header_buffer_size 1k;</span><br><span class="line">Context:  http, server</span><br><span class="line"></span><br><span class="line">Syntax:   large_client_header_buffers  number size;</span><br><span class="line">Default:   large_client_header_buffers 4 8k;</span><br><span class="line">Context:   http, server</span><br></pre></td></tr></table></figure><h2 id="Server-name指令"><a href="#Server-name指令" class="headerlink" title="Server_name指令"></a>Server_name指令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">指令后可以跟多个域名， 第一个被 认为是指定的主域名</span><br><span class="line"></span><br><span class="line">Syntax : server_name_in_redirect on|off;</span><br><span class="line">Default: server_name_in_redirect off;</span><br><span class="line">Context http, server, location</span><br></pre></td></tr></table></figure><p><strong>可以指定一个泛域名， 仅支持在最前或者最后配置</strong><br>如：<br>server_name <em>.ant-loiter.com<br>server_name </em>.ant-loiter.*</p><p>正则表达式配置，必须在配置域名前加~符号表示正则配置开始； </p><p>server_name <a href="http://www.ant-loiter.com">www.ant-loiter.com</a> ~^www\d+.ant-loiter.com&amp;;</p><h2 id="在server模块中定了return的语法："><a href="#在server模块中定了return的语法：" class="headerlink" title="在server模块中定了return的语法："></a>在server模块中定了return的语法：</h2><p>如：<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  <span class="attribute">server_name</span> primary.ant-loiter.com;</span><br><span class="line">  <span class="attribute">set_real_ip_from</span>  <span class="number">192.168.1.120</span>;</span><br><span class="line">  <span class="attribute">real_ip_recursive</span> <span class="literal">off</span>;</span><br><span class="line">  <span class="attribute">real_ip_header</span>  X-Forwarded-For;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">location</span> / &#123;</span><br><span class="line">    <span class="attribute">return</span> <span class="number">302</span> <span class="string">"https://www.ant-loiter.com"</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>上面的代码代里面，如果命中这个规划就会被重新定向到指定的URL中； 但在在http1.0和http1.1里面针对重定向的code定义有所不同； 如下：</p><h3 id="http1-0定义："><a href="#http1-0定义：" class="headerlink" title="http1.0定义："></a>http1.0定义：</h3><p>301： http永久重定向<br>302： 临时重定向， 禁止被缓存 </p><h3 id="http1-1定义："><a href="#http1-1定义：" class="headerlink" title="http1.1定义："></a>http1.1定义：</h3><p>303: 临时重定向， 允许改变方法， 禁止被缓存<br>307： 临时重定向， 不允许改变方法， 禁止被缓存<br>308: 永久重定向， 不允许改变方法</p><h2 id="HTTP请求处理时的11个阶段"><a href="#HTTP请求处理时的11个阶段" class="headerlink" title="HTTP请求处理时的11个阶段"></a>HTTP请求处理时的11个阶段</h2><table><thead><tr><th style="text-align:center">阶段名</th><th style="text-align:center">模块名</th></tr></thead><tbody><tr><td style="text-align:center">POST_READ</td><td style="text-align:center">realip</td></tr><tr><td style="text-align:center">SERVER_REWRITE</td><td style="text-align:center">rewrite</td></tr><tr><td style="text-align:center">FIND_CONFIG</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">REWRITE</td><td style="text-align:center">rewrite</td></tr><tr><td style="text-align:center">POST_REWRITE</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">PREACCESS</td><td style="text-align:center">limt_conn, limit_req</td></tr><tr><td style="text-align:center">ACCESS</td><td style="text-align:center">auth_basic, access, auth_request</td></tr><tr><td style="text-align:center">POST_ACCESS</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">PRECONTENT</td><td style="text-align:center">try_files</td></tr><tr><td style="text-align:center">CONTENT</td><td style="text-align:center">index, autoindex, concat</td></tr><tr><td style="text-align:center">LOG</td><td style="text-align:center">access_log</td></tr></tbody></table><h2 id="error-page命令语法如下："><a href="#error-page命令语法如下：" class="headerlink" title="error_page命令语法如下："></a>error_page命令语法如下：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Syntax: Default: Context: </span><br><span class="line">error_page code ... [=[response]] uri; http, server, location, if in location </span><br><span class="line">如：</span><br><span class="line"></span><br><span class="line">1. error_page 404 /404.html;</span><br><span class="line">2. error_page 500 502 503 504 /50x.html;</span><br><span class="line">3. error_page 404 =200 /empty.gif;</span><br><span class="line">4. error_page 404 = /404.php;</span><br><span class="line">5. location / &#123;error_page 404 = @fallback; &#125;location @fallback &#123;proxy_pass http://backend;&#125;</span><br><span class="line">6. error_page 403 http://example.com/forbidden.html;</span><br><span class="line">7. error_page 404 =301 http://example.com/notfound.html;</span><br></pre></td></tr></table></figure><h2 id="rewrite模块：-rewrite指令"><a href="#rewrite模块：-rewrite指令" class="headerlink" title="rewrite模块： rewrite指令"></a>rewrite模块： rewrite指令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Syntax: rewrite  regex replacement[flag];</span><br><span class="line">Default:   ----</span><br><span class="line">Context:   server, location , if</span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line"></span><br><span class="line">将regex指定的url替换成replacement这个新的url</span><br><span class="line">- 可以使用正则表达式及变量提取； </span><br><span class="line"></span><br><span class="line">当replacement以http://或者https://或者$schema开头， 则直接返回302重定向</span><br><span class="line"></span><br><span class="line">替换后的url根据flag 指定的方式进行处理，如下：</span><br><span class="line"></span><br><span class="line">- last : 用replacement这个URL进行新的location匹配</span><br><span class="line"></span><br><span class="line">- break： break指令停止当前脚本指令的执行， 等价于独立的break指令； </span><br><span class="line"></span><br><span class="line">- redirect: 返回302重定向， 并向新的replacement连接重定向跳转； </span><br><span class="line"></span><br><span class="line">- permanent: 返回301重定向， 并赂新的replacement链接重定向跳转；</span><br></pre></td></tr></table></figure><h2 id="location匹配规则，-仅匹配URI，-忽略参数"><a href="#location匹配规则，-仅匹配URI，-忽略参数" class="headerlink" title="location匹配规则， 仅匹配URI， 忽略参数"></a>location匹配规则， 仅匹配URI， 忽略参数</h2><ul><li><p>前缀字符串匹配<br>常规<br>=  表示精确匹配<br>^~  表示匹配上后则不再进行正则表达式匹配， 如果根后面的字符匹配上后， 是不会再进行正则表达式的匹配的， 就算有匹配的正则表达式； </p></li><li><p>正则表达式匹配<br>~ 表示大小写敏感的正则匹配<br>~* 表示忽略大小写的正则匹配（大小写不敏感）</p></li><li><p>用于内部跳转的命名location </p></li></ul><p>@ 用来表示配置文件内部不同location间的跳转； </p><ul><li><p>合并连续/ 符号</p><p>merge_slashes   on/off; </p><p>表示是否要合并URI中连续的//符号； 如果url没有被编码后， 建议配置为on,即表示合并 ； </p></li></ul><h2 id="limit-conn指令"><a href="#limit-conn指令" class="headerlink" title="limit_conn指令"></a>limit_conn指令</h2><p>定义共享内存（包括大小）， 以及key关键字<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax: limit_conn_zone key zone=name:size;</span><br><span class="line">Default: ---</span><br><span class="line">Context: http</span><br></pre></td></tr></table></figure></p><h2 id="限制并发连接数"><a href="#限制并发连接数" class="headerlink" title="限制并发连接数"></a>限制并发连接数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax:  limit_conn  zone number;</span><br><span class="line">Default:  ---</span><br><span class="line">Context: http, server, location</span><br></pre></td></tr></table></figure><h2 id="限制发生时的日志级别"><a href="#限制发生时的日志级别" class="headerlink" title="限制发生时的日志级别"></a>限制发生时的日志级别</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax: limit_conn_log_level info|notice|warn|error;</span><br><span class="line">Default:  limit_conn_log_level error;</span><br><span class="line">Context: http, server, location</span><br></pre></td></tr></table></figure><h2 id="限制发生时向客户端返回的错误码"><a href="#限制发生时向客户端返回的错误码" class="headerlink" title="限制发生时向客户端返回的错误码"></a>限制发生时向客户端返回的错误码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax: limit_conn_status code;</span><br><span class="line">Default: limit_conn_status 503;</span><br><span class="line">Context:  http, server, location</span><br></pre></td></tr></table></figure><h2 id="创建一个共享内存"><a href="#创建一个共享内存" class="headerlink" title="创建一个共享内存"></a>创建一个共享内存</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 以下代码是在http模块里</span><br><span class="line">limit_conn_zone  $binary_remote_addr zone=addr:10m;</span><br><span class="line">limit_conn_zone $binary_remote_addr zone=one:10m rate=3r/s;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">  server_name limit.taofei.tech;</span><br><span class="line">  root html/;</span><br><span class="line">  error_log logs/myerror.log info;</span><br><span class="line"></span><br><span class="line">  location / &#123;</span><br><span class="line">    # 自定义了超出了最大连接数时返回的错误码；</span><br><span class="line">    limit_conn_status 500;</span><br><span class="line">    # 自定义了连接最大连接的错误级别； </span><br><span class="line">    limit_conn_log_level warn;</span><br><span class="line">    # 限制极限的返回的速度， 这个配置是每秒50字节； </span><br><span class="line">    limit_rate 50;</span><br><span class="line">    # 限制同时的并发连接数限制为1</span><br><span class="line">    limit_conn addr 1;</span><br><span class="line">    # limit_req zone=one burst=1 nodelay;</span><br><span class="line">    # limit_req zone=one;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="limit-req指令"><a href="#limit-req指令" class="headerlink" title="limit_req指令"></a>limit_req指令</h2><ul><li><p>定义共享内存（包括大小）以及key关键字和限制速率</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Syntax:   limit_req_zone  key zone=name:size rate=rate;</span><br><span class="line">Default:    --</span><br><span class="line">Context:  http</span><br><span class="line">rate取值单位： r/s 每秒多少个请求；  r/m  每分钟多少个请求；</span><br></pre></td></tr></table></figure></li><li><p>限制并发请求连接数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Syntax:   limit_req zone=name [burst=number] [nodelay]</span><br><span class="line">Default:   ---</span><br><span class="line">Context:  http, server, location</span><br><span class="line"></span><br><span class="line">说明：</span><br><span class="line">burst默认为0 </span><br><span class="line">nodelay, 对burst中的请求不再采用延时处理的做法， 而是立刻处理；</span><br></pre></td></tr></table></figure></li><li><p>限制发生时的日志级别</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax:  limit_req_log_level  info|notice|warn|error;</span><br><span class="line">Default:   limit_req_log_level  error;</span><br><span class="line">Context:    http,server,location</span><br></pre></td></tr></table></figure></li><li><p>限制发生时向客户返回的错误码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Syntax:  limit_req_status code;</span><br><span class="line">Default:   limit_red_status   503;</span><br><span class="line">Context:  http, server, location</span><br></pre></td></tr></table></figure></li></ul><h2 id="如何限制某些IP地址的访问权限？"><a href="#如何限制某些IP地址的访问权限？" class="headerlink" title="如何限制某些IP地址的访问权限？"></a>如何限制某些IP地址的访问权限？</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Syntax:  allow address | CIDR | unix: | all;</span><br><span class="line">Default:  -- </span><br><span class="line">Context:  http, server, location, limit_except</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Syntax:  deny address |CIDR | unix: | all;</span><br><span class="line">Default:  -- </span><br><span class="line">Context: http, server, location, limit_except</span><br><span class="line"></span><br><span class="line">如：</span><br><span class="line">location  / &#123;</span><br><span class="line"></span><br><span class="line">  deny 192.168.1.1;</span><br><span class="line">  allow 192.168.1.0/24;</span><br><span class="line">  allow 10.1.1.0/16;</span><br><span class="line">  allow 2001:0db8::/32;</span><br><span class="line">  deny all;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">以上请求是单项目匹配的， 只要匹配到一个规则就会结束匹配；</span><br></pre></td></tr></table></figure><h2 id="auth-basic模块的指令"><a href="#auth-basic模块的指令" class="headerlink" title="auth_basic模块的指令"></a>auth_basic模块的指令</h2><ul><li><p>功能：<br>基于HTTP Basic Authutication协议进行用户名密码认证； </p><p>默认编译进Nginx<br>   –without-http_auth_basic_module<br>   在编码时添加上面的配置就可以把这个模块去除； </p></li><li><p>指令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Syntax: auth_basic string|off;  这里的string会显示在输入账号密码窗口的标题上； </span><br><span class="line">Default:  auth_basic off;</span><br><span class="line">Context:  http, server, location, limit_except</span><br><span class="line"></span><br><span class="line">Syntax:  auth_basic_user_file   file;</span><br><span class="line">Default:   --</span><br><span class="line">Context:   http, server, location, limit_except</span><br></pre></td></tr></table></figure><ul><li>在认证时，需要有账号密码， 可以通过httpd-tools工具还生成账号密码文件； </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -c file -b user pass</span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> nginx http </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令收集（不断更新）</title>
      <link href="/2018/12/12/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86%EF%BC%88%E4%B8%8D%E6%96%AD%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
      <url>/2018/12/12/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%94%B6%E9%9B%86%EF%BC%88%E4%B8%8D%E6%96%AD%E6%9B%B4%E6%96%B0%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h2 id="采用wget下载指定页面内容（包含相关资源）"><a href="#采用wget下载指定页面内容（包含相关资源）" class="headerlink" title="采用wget下载指定页面内容（包含相关资源）"></a>采用wget下载指定页面内容（包含相关资源）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -c -r -np -k -L -p https://docs.oracle.com/en/java/javase/11/docs/api/index.html</span><br></pre></td></tr></table></figure><h2 id="查看当前目录下文件个数及大小"><a href="#查看当前目录下文件个数及大小" class="headerlink" title="查看当前目录下文件个数及大小"></a>查看当前目录下文件个数及大小</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ls -l |grep &quot;^-&quot;|wc -l</span><br><span class="line">或</span><br><span class="line">find ./company -type f | wc -l</span><br></pre></td></tr></table></figure><h2 id="find删除指定时间之前的文件"><a href="#find删除指定时间之前的文件" class="headerlink" title="find删除指定时间之前的文件"></a>find删除指定时间之前的文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">find .  -type f  -name *.log  -mtime +180  -exec rm &#123;&#125; \;</span><br><span class="line"></span><br><span class="line">// 查看， 后面可以跟上执行</span><br><span class="line">find . -name &quot;*.png&quot; -type f -mtime +299 ;</span><br></pre></td></tr></table></figure><blockquote><p>find 后面紧跟的是要查找的目录，. 表示当前目录<br>-type f：指定查找对象为文件<br>-name *.log：指定查找对象名称以.log结尾<br>-mtime +180: 查找180天以前的老文件<br>-exec rm {} \;  :执行删除命令，这句长得很奇怪，后面有个 {} \; 是必须的，也可以执行其他指令，比如ls， rm -i之类的</p></blockquote><h2 id="curl-命令"><a href="#curl-命令" class="headerlink" title="curl 命令"></a>curl 命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl www.ant-loiter -I </span><br><span class="line"></span><br><span class="line">访问对应的域名， -I，表示回显请示的头部信息；</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> linux command </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>zookeeper特性学习二</title>
      <link href="/2018/11/30/zookeeper%E7%89%B9%E6%80%A7%E5%AD%A6%E4%B9%A0%E4%BA%8C/"/>
      <url>/2018/11/30/zookeeper%E7%89%B9%E6%80%A7%E5%AD%A6%E4%B9%A0%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="zookeeper-集群搭建"><a href="#zookeeper-集群搭建" class="headerlink" title="zookeeper 集群搭建"></a>zookeeper 集群搭建</h1><ul><li><p>zk集群，主从节点， 心跳机制（选举模式）<br>塔建一个集群，最少需要三个节点</p></li><li><p>zk集群搭建需要注意的点</p></li></ul><blockquote><p>配置数据文件 myid 1/2/3 对应 server.1/2/3 </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> zookeeper 分布式 注册 管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper 分布式 注册 管理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>zookeeper特性学习一</title>
      <link href="/2018/11/29/zookeeper1-0/"/>
      <url>/2018/11/29/zookeeper1-0/</url>
      
        <content type="html"><![CDATA[<h1 id="zookeeper-的特性"><a href="#zookeeper-的特性" class="headerlink" title="zookeeper 的特性"></a>zookeeper 的特性</h1><ul><li><p>一致性： 数据一致性， 数据按照顺序分批入库； </p></li><li><p>原子性： 事务要么成功要么失败， 不会局部化； </p></li><li><p>单一视图： 客户端连接集群中的任一zk节点， 数据都是一致的； </p></li><li><p>可靠性： 每次对zk的操作状态都会保存在服务端； </p></li><li><p>实时性： 客户端可以读取到zk服务端的最新数据； 如果有数据更新，一会会在秒内完成更新； </p></li></ul><p>以上是zk的五个特性； 非常适合做分布式的管理； </p><h1 id="zoo-cfg-配置"><a href="#zoo-cfg-配置" class="headerlink" title="zoo.cfg 配置"></a>zoo.cfg 配置</h1><ul><li><p>tickTime: 用于计算的时间单元。 比如session超时： N * tickTime; </p></li><li><p>initLimit: 用于集群， 允许从节点连接并同步到master节点的初始化连接时间， 以tickTime的倍数来表示；</p></li><li><p>syncLimit: 用于集群， master主节点与从节点之间发送消息， 请求和应答时间长度。（心跳机制）</p></li><li><p>dataDir: 必须配置， 用来存放zookeeper时产生的临时文件； </p></li><li><p>dataLogDir: 日志目录， 如果没有配置会和dataDir分用一个目录 ； </p></li><li><p>clientPort: 连接服务器的端口，默认为， 2181； </p></li></ul><h1 id="zookeeper基本数据模型介绍一"><a href="#zookeeper基本数据模型介绍一" class="headerlink" title="zookeeper基本数据模型介绍一"></a>zookeeper基本数据模型介绍一</h1><ul><li><p>是一个树形结构， 类似于前端开发中的tree.js组件； </p></li><li><p>zk的数据模型也可以理解为linux/unix的文件目录： /usr/local/…</p></li><li><p>每一个节点都称之为znode， 它可以有子节点， 也可以有数据； </p></li><li><p>每个节点分为临时节点和永久节点， 临时节点在客户端断开后消失；</p></li><li><p>每个zk节点都有各自的版本号， 可以通过命令行来显示节点信息； 在每个zk节点信息里都有一个版本号信息； </p></li><li><p>每当节点数据发生变化， 那么该点节的版本号会累加（乐观销机制），在更新节点之前先拿到节点信息，里面有版本号， 提交更新时，要比对版本号信息；如果不对就不提交更新； </p></li><li><p>删除/修改过时节点， 版本号不匹配则会报错； </p></li><li><p>每个zk节点存储的数据不宜过大， 几K即可。 </p></li><li><p>节点可以设置权限acl ， 可以通过权限来限制用户的访问； </p></li></ul><h1 id="zk-客户端如何连接？"><a href="#zk-客户端如何连接？" class="headerlink" title="zk 客户端如何连接？"></a>zk 客户端如何连接？</h1><p>在zk的安装目录下，/bin目录下有个zkcli.sh就是用来连接zkServer服务的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; zkCli.sh </span><br><span class="line">会显示如下信息，表示连接成功， </span><br><span class="line"></span><br><span class="line">[zk: localhost:2181(CONNECTED) 0 ]</span><br></pre></td></tr></table></figure><p>进去后，输入help可以查看zkCli的所有命令：  help; </p><h2 id="zk的作用体现一"><a href="#zk的作用体现一" class="headerlink" title="zk的作用体现一"></a>zk的作用体现一</h2><blockquote><ul><li>master 节点选举， 主节点挂了以后， 从节点就会接手工作， 并且保证这个节点是唯一的， 这也是所谓首脑模式， 从而保证了我们的集群是高可用的；</li></ul></blockquote><blockquote><ul><li>统一配置文件管理， 即只需要部署一台服务器， 则可以把相同的配置文件同步更新到其他的服务器， 此操作在云计算中用的特别多（假设修改了redis统一配置）；</li></ul></blockquote><blockquote><ul><li>发布与订阅， 类似消息队列MQ（amq， rmq…），dubbo发布者把数据存在znode上， 订阅者会读取这个数据；</li></ul></blockquote><blockquote><ul><li>提供了分布锁， 分布锁环境中不同进程争夺资源， 类似于多线程中的锁； </li></ul></blockquote><blockquote><ul><li>集群管理， 集群中保证数据的强一致性； </li></ul></blockquote><h2 id="zkCli-sh命令使用"><a href="#zkCli-sh命令使用" class="headerlink" title="zkCli.sh命令使用"></a>zkCli.sh命令使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">进入shell命令行，输入</span><br><span class="line">./bin/zkCli.sh</span><br><span class="line"></span><br><span class="line">注：回二次车，可以进入client的交互窗口；</span><br><span class="line"></span><br><span class="line">help 查看支持的命令信息；</span><br></pre></td></tr></table></figure><h3 id="ls-与-ls2-命令的区别"><a href="#ls-与-ls2-命令的区别" class="headerlink" title="ls 与 ls2 命令的区别"></a>ls 与 ls2 命令的区别</h3><p>ls命令只是查看节点的名，ls2不但可以查看节点名还可以显示出当前节点的详细信息； 他其实就是把ls和stat二个命令结合了； </p><h3 id="get-命令"><a href="#get-命令" class="headerlink" title="get 命令"></a>get 命令</h3><p>就是可以把指定节点下的信息读出； 如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">get /</span><br></pre></td></tr></table></figure><h3 id="create-s-e-path-data-acl"><a href="#create-s-e-path-data-acl" class="headerlink" title="create [-s] [-e] path data acl"></a>create [-s] [-e] path data acl</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">create /imooc imooc-data-info</span><br><span class="line">这样就创建了一个节点imooc,里面的数据是imooc-data-info,通过上面的命令创建出来的节点就是一个持久化的节点； </span><br><span class="line"></span><br><span class="line">create -e /imooc/tmp imooc-temp</span><br><span class="line"></span><br><span class="line">这个命令就是创建了一个临时节点； </span><br><span class="line">cversion = -1</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0 // 表示持久化节点</span><br><span class="line">dataLength = 0</span><br><span class="line">numChildren = 1</span><br><span class="line"></span><br><span class="line">---------</span><br><span class="line">pZxid = 0xd</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x100003128270005 //表示临时节点</span><br><span class="line">dataLength = 10</span><br><span class="line">numChildren = 0</span><br><span class="line"></span><br><span class="line">create -s /imooc/sec seqinfo</span><br><span class="line">这个命令可以创建出一个序列式的节点， 节点的名称是一个序列，步长为1的自增序列</span><br></pre></td></tr></table></figure><p>注意， 创建的临时节点，当当前这个zknoke心跳没有的话， 那么这个zknode节点就会被丢失，这时所有的临时节点就会被删除掉； </p><h2 id="zk-特性-watchet机制-一"><a href="#zk-特性-watchet机制-一" class="headerlink" title="zk 特性 -  watchet机制 一"></a>zk 特性 -  watchet机制 一</h2><blockquote><ul><li>针对每个节点的操作， 都会有一个监督者 （ watcher)</li></ul></blockquote><blockquote><ul><li>如， 当监控的某个对象（znode)发生变化了， 则触发watcher事件； </li></ul></blockquote><blockquote><ul><li>注意： zk中的watcher是一次生的， 触发后立即销毁掉； （是针对每一个节点都有一个各自的wacher)</li></ul></blockquote><blockquote><ul><li>父子节点进行 CRUD时都会触发其watcher功能； </li></ul></blockquote><blockquote><ul><li>针对不同类型的操作， 触发的watcher事件也不同：</li></ul></blockquote><ul><li><p>（子）节点创建事件</p></li><li><p>（子）节点删除事件</p></li><li><p>（子）节点数据变化事件</p></li></ul><p>都会有相对应的watcher事件与之对应； 操作；</p><p>可以把watcher理解成为一个trigger即可。 </p><h2 id="Watcher-命令行操作"><a href="#Watcher-命令行操作" class="headerlink" title="Watcher 命令行操作"></a>Watcher 命令行操作</h2><blockquote><ul><li>通过 get path [watch] 设置watcher </li></ul></blockquote><blockquote><ul><li>父节点增删改操作触发watcher 进行。 </li></ul></blockquote><blockquote><ul><li>子节点增删改操作触发watcher 进行。 </li></ul></blockquote><h2 id="Watcher事件类型-之一"><a href="#Watcher事件类型-之一" class="headerlink" title="Watcher事件类型 之一"></a>Watcher事件类型 之一</h2><blockquote><ul><li>创建父节点触发： NodeCreated  </li></ul></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">stat /imooc watch  </span><br><span class="line">表示为/imooc节点添加watch事件， 注意， 如果/imooc这个节点没有也没关系， 这个节点的/imooc的watch节点还是存在的。 </span><br><span class="line"></span><br><span class="line">create /imooc imoocinfo</span><br><span class="line"></span><br><span class="line">执行上面的命令后， 会自动触发watch事件， 事件名叫做NodeCreated</span><br><span class="line"></span><br><span class="line">实验操作</span><br><span class="line"></span><br><span class="line">WATCHER::</span><br><span class="line"></span><br><span class="line">WatchedEvent state:SyncConnected type:NodeCreated path:/zk001</span><br><span class="line">Created /zk001</span><br></pre></td></tr></table></figure><p>针对一个节点如果有CRUD的相关操作，想有watcher的事件发生， 就需要事件对这个事情添加上watcher事件， 否则是不会有watcher事件的发生； </p><p>有一个要注意的地方， 就是可以对父节点添加watcher事件， 这个对其子节点进行增加和删除操作时会触发NodeChildChanged事件； 修改是不是会触发的。 为什么呢。 修改某个节点的内容时其实是不会改变tree的结构所以不会鉵发相应的父节点对应的事件； </p><p>由些可以推出，某个子节点的更新watcher事件， 是需要对某个子节点单独添加的。 </p><p>get /imooc/abc watch 这个就可以给这个节点添加一个watcher事件，<br>set /imooc/abc xyz 这个命令执行时， 就会触发一个watcher事件； </p><h2 id="ACL-命令行"><a href="#ACL-命令行" class="headerlink" title="ACL 命令行"></a>ACL 命令行</h2><blockquote><ul><li>getACL 获取某个节点acl的权限信息</li></ul></blockquote><blockquote><ul><li>setAcl 设置某个节点的acl权限；</li></ul></blockquote><blockquote><ul><li>addauth 输入认证授权信息， 注册时输入明文密码（登录 ） 但是在zk系统 里在密码会以加密形式存在。<br>注意： 只有通过addauth命令创建的用户，才可以登录后zk系统 ； </li></ul></blockquote><h2 id="ACL-的构成"><a href="#ACL-的构成" class="headerlink" title="ACL 的构成"></a>ACL 的构成</h2><blockquote><ul><li>zk的acl通过[scheme:id:permissions]来构成权限列表</li></ul></blockquote><ul><li>scheme : 代表采用的某种权限机制</li><li>id: 代表允许访问的用户</li><li>permissions 权限组合字符串</li></ul><h2 id="acl的构成-scheme"><a href="#acl的构成-scheme" class="headerlink" title="acl的构成   scheme"></a>acl的构成   scheme</h2><ul><li><p>world  world下只有一个id， 即只有一个用户， 也就是anyone， 那么组合的写法就是world：anyone:[permission]</p></li><li><p>auth： 代表认证登录， 需要注册用户有权限就可以， 形式为auth:user:password:[permissions]</p></li><li><p>digest 需要对密码加密才能访问， 组合形式为 disest:username:BASE64(SHA1(password)):[permissions]</p></li><li><p>ip: 当设置为ip指定的IP地址， 此时限制ip进行访问， 比如 ip:192.179.12.23:[permissions]</p></li><li><p>super 代表超级管理员， 拥有所有的权限； </p></li></ul><h2 id="acl权限中permissions的构成"><a href="#acl权限中permissions的构成" class="headerlink" title="acl权限中permissions的构成"></a>acl权限中permissions的构成</h2><ul><li><p>create 创建子节点</p></li><li><p>read 获取节点、子节点</p></li><li><p>write 设置节点数据</p></li><li><p>delete 删除子节点</p></li><li><p>admin </p></li></ul><p>缩写就是这样的一个字符串， crwda  取每个权限单词的首字母； </p><h2 id="acl-命令操作"><a href="#acl-命令操作" class="headerlink" title="acl 命令操作"></a>acl 命令操作</h2><ul><li><p>world:anyone:cdrwa</p></li><li><p>auth:user:pwd:cdrwa</p></li><li><p>digest:user:BASE64(SHA1(pwd)):cdrwa</p></li><li><p>addauth digest user:pwd</p></li><li><p>ip: 192.179.23.3:cdrwa</p></li></ul><h2 id="Acl-命令操作里关于Super-的操作"><a href="#Acl-命令操作里关于Super-的操作" class="headerlink" title="Acl 命令操作里关于Super 的操作"></a>Acl 命令操作里关于Super 的操作</h2><ul><li><p>修改zkServer.sh  增加super管理员； </p></li><li><p>修改后必须 要重启zk  ./bin/zkServer.sh restart </p></li></ul><p>配置超级管理员需要配置如下信息：</p><p>-Dzookeeper.DigestAuthenticationProvider.superDigest=username:BASE64(sha1(passwd)) </p><h2 id="zk-四字命令-（Four-Letter-Words"><a href="#zk-四字命令-（Four-Letter-Words" class="headerlink" title="zk 四字命令 （Four Letter Words)"></a>zk 四字命令 （Four Letter Words)</h2><ul><li><p>zk 可以通过它自身提供的简写命令来和服务器进行交互 </p></li><li><p>需要使用nc命令， 安装： yum install nc </p></li><li><p>echo [commond] | nc [ip] [port]</p></li></ul><p>如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo conf | nc 192.168.1.231 2181</span><br><span class="line">echo stat | nc 192.168.1.231 2181</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p><p>stat 查看zk的状态信息， 以及是否mode</p><p>ruok 查看当前zkserver是否启动， 返回 imok</p><p>dump 列出末经处理的会话和临时节点</p><p>dump 列出末经处理的会话和临时节点</p><p>conf 查看服务器相关的配置信息</p><p>cons 展示连接到服务器的客户端信息 </p><p>envi 环境变量 </p><p>mntr 是监控zk的健康信息 </p><p>echo mntr | nc localhost 2181<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost zookeeper]# echo mntr | nc localhost 2181</span><br><span class="line">zk_version      3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT</span><br><span class="line">zk_avg_latency  0</span><br><span class="line">zk_max_latency  61</span><br><span class="line">zk_min_latency  0</span><br><span class="line">zk_packets_received     560</span><br><span class="line">zk_packets_sent 559</span><br><span class="line">zk_num_alive_connections        2</span><br><span class="line">zk_outstanding_requests 0</span><br><span class="line">zk_server_state standalone</span><br><span class="line">zk_znode_count  11</span><br><span class="line">zk_watch_count  0</span><br><span class="line">zk_ephemerals_count     0</span><br><span class="line">zk_approximate_data_size        158</span><br><span class="line">zk_open_file_descriptor_count   25</span><br><span class="line">zk_max_file_descriptor_count    4096</span><br><span class="line">zk_fsync_threshold_exceed_count 0</span><br></pre></td></tr></table></figure></p><p>wchs 展示watch的相关信息</p><p>echo wchs | nc localhost 2181 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost zookeeper]# echo wchs | nc localhost 2181</span><br><span class="line">0 connections watching 0 paths</span><br><span class="line">Total watches:0</span><br></pre></td></tr></table></figure><p>注意， 在zookeeper中默认不是所有的四字命令都可以使用的。 需要配置命令的白名单或配置成通配符； </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim ./conf/zoo.cfg</span><br><span class="line"></span><br><span class="line">4lw.commands.whilelist=* 或 指定命令名称； </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">4lw.commands.whilelist=*</span><br><span class="line"></span><br><span class="line">配置完成后， 需要重启 </span><br><span class="line">./zkServer.sh restart</span><br></pre></td></tr></table></figure><p>wchc | wchp 展示session与watch及path与watch信息； </p>]]></content>
      
      
      <categories>
          
          <category> zookeeper 分布式 注册 管理 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> zookeeper 分布式 注册 管理 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>工作任务队列，myself</title>
      <link href="/2018/11/29/work-todo-list/"/>
      <url>/2018/11/29/work-todo-list/</url>
      
        <content type="html"><![CDATA[<h1 id="zk-原码分析"><a href="#zk-原码分析" class="headerlink" title="zk 原码分析"></a>zk 原码分析</h1><ul><li><p>接下阅读软文 <a href="http://www.cnblogs.com/xguo/archive/2013/06/10/3130589.html" target="_blank" rel="noopener">http://www.cnblogs.com/xguo/archive/2013/06/10/3130589.html</a></p></li><li><p><a href="https://jboot.io/started/#%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2" target="_blank" rel="noopener">https://jboot.io/started/#%E5%88%86%E9%A1%B5%E6%9F%A5%E8%AF%A2</a></p></li><li><p>阅读jboot源码</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> todolist work jobs myself </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>系统架构谩谈一</title>
      <link href="/2018/11/29/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%B0%A9%E8%B0%88%E4%B8%80/"/>
      <url>/2018/11/29/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%B0%A9%E8%B0%88%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h1 id="计算与存储分离的架构"><a href="#计算与存储分离的架构" class="headerlink" title="计算与存储分离的架构"></a>计算与存储分离的架构</h1><p><em>架构中一个致命的问题， 数据的存储和计算混在一个地方， 都在同一个MySQL库中</em></p><p>要解决这个问题，设想之一有：</p><ul><li><p>数据直接写入一个存储， 仅仅只是简单的写入即可。 </p></li><li><p>然后在计算的时候从数据存储中提取你需要的那个数据分片里可能就千条数据， 写入另外一个专用于计算的临时表中， 那个临时表内数据非常少； </p></li><li><p>然后运行你的各种复杂的SQL</p></li></ul><h1 id="关于memcache一些基础特征："><a href="#关于memcache一些基础特征：" class="headerlink" title="关于memcache一些基础特征："></a>关于memcache一些基础特征：</h1><p>1、 mc的核心职能是KV内存管理， value存储最大为1M， 它不支持复合数据结构（哈希，列表，集合， 有序集合等）<br>2、mc不支持持久化<br>3、 mc支持key过期<br>4、 <em>mc持续运行很少会出现内存碎片， 速度不会随着服务运行时间降低</em><br>5、mc使有非阻塞IO复用网络模型， 使用监听线程、工作线程的多线程模型； </p><ul><li><p>采用什么技术实现key过期的？<br>懒淘汰（lazy expiration）</p></li><li><p>为什么能保证运行性能， 且很少会出现内存碎片？<br>提前分配内存； </p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 架构 MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 MySQL Master Slave </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>JSR提供的校验注解</title>
      <link href="/2018/11/28/JSR%E6%8F%90%E4%BE%9B%E7%9A%84%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3/"/>
      <url>/2018/11/28/JSR%E6%8F%90%E4%BE%9B%E7%9A%84%E6%A0%A1%E9%AA%8C%E6%B3%A8%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h2 id="JSR提供的核验注解配置如下："><a href="#JSR提供的核验注解配置如下：" class="headerlink" title="JSR提供的核验注解配置如下："></a>JSR提供的核验注解配置如下：</h2><table><thead><tr><th style="text-align:left">序号</th><th style="text-align:left">配置关键字</th><th style="text-align:center">注解说明</th></tr></thead><tbody><tr><td style="text-align:left">1</td><td style="text-align:left">@Null</td><td style="text-align:center">被注释的元素必须为 null</td></tr><tr><td style="text-align:left">2</td><td style="text-align:left">@NotNull</td><td style="text-align:center">被注释的元素必须不为 null</td></tr><tr><td style="text-align:left">3</td><td style="text-align:left">@AssertTrue</td><td style="text-align:center">被注释的元素必须为 true</td></tr><tr><td style="text-align:left">4</td><td style="text-align:left">@AssertFalse</td><td style="text-align:center">被注释的元素必须为 false    </td></tr><tr><td style="text-align:left">5</td><td style="text-align:left">@Min(value)</td><td style="text-align:center">被注释的元素必须是一个数字，其值必须大于等于指定的最小值</td></tr><tr><td style="text-align:left">6</td><td style="text-align:left">@Max(value)</td><td style="text-align:center">被注释的元素必须是一个数字，其值必须小于等于指定的最大值</td></tr><tr><td style="text-align:left">7</td><td style="text-align:left">@DecimalMin(value)</td><td style="text-align:center">被注释的元素必须是一个数字，其值必须大于等于指定的最小值</td></tr><tr><td style="text-align:left">8</td><td style="text-align:left">@DecimalMax(value)</td><td style="text-align:center">被注释的元素必须是一个数字，其值必须小于等于指定的最大值</td></tr><tr><td style="text-align:left">9</td><td style="text-align:left">@Size(max=, min=)</td><td style="text-align:center">被注释的元素的大小必须在指定的范围内</td></tr><tr><td style="text-align:left">10</td><td style="text-align:left">@Digits (integer, fraction)</td><td style="text-align:center">被注释的元素必须是一个数字，其值必须在可接受的范围内</td></tr><tr><td style="text-align:left">11</td><td style="text-align:left">@Past</td><td style="text-align:center">被注释的元素必须是一个过去的日期</td></tr><tr><td style="text-align:left">12</td><td style="text-align:left">@Future</td><td style="text-align:center">被注释的元素必须是一个将来的日期</td></tr><tr><td style="text-align:left">13</td><td style="text-align:left">@Pattern(regex=,flag=)</td><td style="text-align:center">被注释的元素必须符合指定的正则表达式</td></tr></tbody></table><h2 id="例如："><a href="#例如：" class="headerlink" title="例如："></a>例如：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">@NotBlank</span><br><span class="line">private String name;</span><br><span class="line"></span><br><span class="line">@Min(18)</span><br><span class="line">private Integer age;</span><br><span class="line"></span><br><span class="line">@Pattern(regexp = &quot;^1(3|4|5|7|8)\\d&#123;9&#125;$&quot;,message = &quot;手机号码格式错误&quot;)</span><br><span class="line">@NotBlank(message = &quot;手机号码不能为空&quot;)</span><br><span class="line">private String phone;</span><br><span class="line"></span><br><span class="line">@Email(message = &quot;邮箱格式错误&quot;)</span><br><span class="line">private String email;</span><br><span class="line"></span><br><span class="line">//... getter setter</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>如何在OpenRestry开源版本中编译使用Tengine的ngx_slab_stat</title>
      <link href="/2018/11/26/nginx-configure-slab-stat-module/"/>
      <url>/2018/11/26/nginx-configure-slab-stat-module/</url>
      
        <content type="html"><![CDATA[<p><em>下载openresty最新版本， 在编译安装时， 只要是符合nginx的模块插件， 都 可以在编译时进行编译加入基中</em></p><p>Nginx是个多进程的技术框架， 多个进程之间通讯可以通过以下二个方式通讯：</p><ul><li><p>信号 （ 参照前面写的博文）</p></li><li><p>内存共享 （tengine里面的 Slab模块）像使用mamcache.</p></li></ul><h1 id="下载opensesty-如："><a href="#下载opensesty-如：" class="headerlink" title="下载opensesty, 如："></a>下载opensesty, 如：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget https://openresty.org/download/openresty-1.13.6.2.tar.gz</span><br><span class="line">tar -zxvf openresty-1.13.6.2.tar.gz</span><br><span class="line">cd openresty-1.13.6.2</span><br></pre></td></tr></table></figure><h1 id="由于ngx-slab-stat在github上没有源码提供，所以先下载Tengine使用里面的模块源码，如下："><a href="#由于ngx-slab-stat在github上没有源码提供，所以先下载Tengine使用里面的模块源码，如下：" class="headerlink" title="由于ngx_slab_stat在github上没有源码提供，所以先下载Tengine使用里面的模块源码，如下："></a>由于ngx_slab_stat在github上没有源码提供，所以先下载Tengine使用里面的模块源码，如下：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://tengine.taobao.org/download/tengine-2.2.3.tar.gz</span><br><span class="line">tar -zxvf tengine-2.2.3.tar.gz</span><br><span class="line">cd tengine-2.2.3/modules/</span><br><span class="line">目录下需有一个ngx_slab_stat</span><br></pre></td></tr></table></figure><h1 id="编译openresty-如下："><a href="#编译openresty-如下：" class="headerlink" title="编译openresty, 如下："></a>编译openresty, 如下：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd ./openresty-1.13.6.2</span><br><span class="line">./configure --prefix=/usr/local/openresty/ --add-module=配置刚才tengine目录下modules里面的ngx_slab_stat模块</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>完成了openresty编译时添加ngx_slab_stat模块。</p><p>完成了，在配置文件里面可以使用这个模块功能，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">vim ./nginx/conf/nginx.conf</span><br><span class="line"></span><br><span class="line">添加如下代码：</span><br><span class="line">lua_shared_dict dogs 10m;  # 定义一个共享内存，命名为dogs 大小为10M</span><br><span class="line"></span><br><span class="line">如下可以使用这个共享内存，</span><br><span class="line"></span><br><span class="line">location /set &#123;</span><br><span class="line">  content_by_lua_block &#123;</span><br><span class="line">    local dogs = ngx.shared.dogs</span><br><span class="line">    dogs:set(&quot;jim&quot;, 8)</span><br><span class="line">    ngx.say(&quot;STORED&quot;);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 在共享内存区域创建了一个key-value对， 存储了一个值；如何使用空上值，如下</span><br><span class="line">location /get &#123;</span><br><span class="line">  content_by_lua_block&#123;</span><br><span class="line">    local dogs = ngx.shared.dogs;</span><br><span class="line">    ngx.say(dogs:get(&quot;jim&quot;));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 以上是获取共享内存中的数据信息</span><br><span class="line"># 查看slab_stat的使用情况</span><br><span class="line">location = /slab_stat &#123;</span><br><span class="line">  slab_stat;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>查询后， 会显示如下信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">* shared memory: my_cache</span><br><span class="line">total:        5120(KB) free:        5080(KB) size:           4(KB)</span><br><span class="line">pages:        5080(KB) start:00007F5CE20FC000 end:00007F5CE25F4000</span><br><span class="line">slot:           8(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:          16(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:          32(Bytes) total:         127 used:           1 reqs:           1 fails:           0</span><br><span class="line">slot:          64(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:         128(Bytes) total:          32 used:           1 reqs:          45 fails:           0</span><br><span class="line">slot:         256(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:         512(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:        1024(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:        2048(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">* shared memory: dogs</span><br><span class="line">total:       10240(KB) free:       10168(KB) size:           4(KB)</span><br><span class="line">pages:       10168(KB) start:00007F5CE1704000 end:00007F5CE20F4000</span><br><span class="line">slot:           8(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:          16(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:          32(Bytes) total:         127 used:           1 reqs:           1 fails:           0</span><br><span class="line">slot:          64(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:         128(Bytes) total:          32 used:           2 reqs:           2 fails:           0</span><br><span class="line">slot:         256(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:         512(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:        1024(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br><span class="line">slot:        2048(Bytes) total:           0 used:           0 reqs:           0 fails:           0</span><br></pre></td></tr></table></figure></p><h1 id="Nginx-中最常用的容器：-红黑树"><a href="#Nginx-中最常用的容器：-红黑树" class="headerlink" title="Nginx 中最常用的容器： 红黑树"></a>Nginx 中最常用的容器： 红黑树</h1><p>红黑树， 是用来管理nginx共享内存里面的对象信息； 存储、查找、更新等； </p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>自平衡二叉查找树</p><ul><li>高度不会超过2倍（log(n)）</li><li>增删改查算法复杂度o（log(n))</li><li>遍历复杂度o(n)</li></ul><p>在nginx里面使用红黑树的模块有如：</p><ul><li>ngx_conf_module</li><li>ngx_event_timer_rbtree</li><li>ngx_http_file_cache</li><li>ngx_http_geo_module</li><li>ngx_http_limit_conn_module</li><li>ngx_http_limit_req_module</li><li>ngx_http_lua_shdict:ngx.shared.DICT    LRU链表性质</li><li>resolver   ngx_resolver_t</li><li>ngx_stream_geo_module</li><li>ngx_stream_limit_conn_module</li></ul><h1 id="使用动态模块来提升运维效率"><a href="#使用动态模块来提升运维效率" class="headerlink" title="使用动态模块来提升运维效率"></a>使用动态模块来提升运维效率</h1><p>静态库： 会直接把源码编译到生成的nginx二进制的文件中。</p><p>动态库： 在编译时只会把动态库的引用保存在编译后的nginx二进制的文件中， 调用时会运行动态库的代码。 </p><p>过程：</p><p>1、 Configure 加入动态模块</p><p>2、 编译进binary</p><p>3、 启动进初始模块数组</p><p>4、 读取load_module配置</p><p>5、 打开动态库并加入模块数组</p><p>6、 基于模块数组开始初始化</p><p>说明，如何查看哪些模块支持动态编译。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --help | more</span><br></pre></td></tr></table></figure><p>如下， 模块带有=dynamic,如：</p><p>–with-http_image_filter_module=dynamic, 表示可以编译成一个动态模块； </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/local/nginx --with-http_image_filter_module=dynamic</span><br></pre></td></tr></table></figure><p>编译成功后， 如何使用这个模块呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">load_module modules/ngx_http_image_filter_module.so;</span><br><span class="line">引入这个动态模块</span><br><span class="line"></span><br><span class="line">在locaction的访问里面添加如下代码：</span><br><span class="line"></span><br><span class="line">image_filter resize 15 10;</span><br></pre></td></tr></table></figure><p>实验，动手操作一下； </p>]]></content>
      
      
      
        <tags>
            
            <tag> nginx openretry tengine ngx_slab_stat </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Centos7.2使用yum安装MariaDB10.1</title>
      <link href="/2018/11/21/Centos7-2%E4%BD%BF%E7%94%A8yum%E5%AE%89%E8%A3%85MariaDB10-1/"/>
      <url>/2018/11/21/Centos7-2%E4%BD%BF%E7%94%A8yum%E5%AE%89%E8%A3%85MariaDB10-1/</url>
      
        <content type="html"><![CDATA[<h2 id="配置MariaDB的yum-源"><a href="#配置MariaDB的yum-源" class="headerlink" title="配置MariaDB的yum 源"></a>配置MariaDB的yum 源</h2><p>1、创建MariaDB.repo<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/yum.repos.d/MariaDB.repo</span><br></pre></td></tr></table></figure></p><p>2、将以下文件中的字段添加到MariaDB.repo文件中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># MariaDB 10.1 CentOS repository list - created 2016-12-01 03:36 UTC</span><br><span class="line"># http://downloads.mariadb.org/mariadb/repositories/</span><br><span class="line">[mariadb]</span><br><span class="line">name = MariaDB</span><br><span class="line">baseurl = http://yum.mariadb.org/10.1/centos7-amd64</span><br><span class="line">gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB</span><br><span class="line">gpgcheck=1</span><br></pre></td></tr></table></figure></p><h2 id="yum-安装MariaDB"><a href="#yum-安装MariaDB" class="headerlink" title="yum 安装MariaDB"></a>yum 安装MariaDB</h2><blockquote><p>sudo yum -y install MariaDB-server MariaDB-client</p></blockquote><h2 id="启动MariaDB服务"><a href="#启动MariaDB服务" class="headerlink" title="启动MariaDB服务"></a>启动MariaDB服务</h2><blockquote><p>systemctl start mysql.service </p></blockquote><h2 id="配置MariaDB服务"><a href="#配置MariaDB服务" class="headerlink" title="配置MariaDB服务"></a>配置MariaDB服务</h2><p><strong>使用mysql_secure_installation配置MariaDB服务</strong></p><blockquote><p>mysql_secure_installation</p></blockquote><p><strong>具体设置</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#由于一开始安装MariaDB数据库后, root用户默认密码为空, 所以只需要按Enter键</span><br><span class="line">Enter current password for root (enter for none):</span><br><span class="line"></span><br><span class="line">#是否设置root用户的新密码</span><br><span class="line">Set root password? [Y/n] y</span><br><span class="line"></span><br><span class="line">#录入新密码</span><br><span class="line">New password:</span><br><span class="line"></span><br><span class="line">#确认新密码</span><br><span class="line">Re-enter new password:</span><br><span class="line"></span><br><span class="line">#是否删除匿名用户,生产环境建议删除</span><br><span class="line">Remove anonymous users? [Y/n] y</span><br><span class="line"></span><br><span class="line">#是否禁止root远程登录,根据自己的需求选择</span><br><span class="line">Disallow root login remotely? [Y/n] n</span><br><span class="line"></span><br><span class="line">#是否删除test数据库</span><br><span class="line">Remove test database and access to it? [Y/n] y</span><br><span class="line"></span><br><span class="line">#是否重新加载权限表</span><br><span class="line">Reload privilege tables now? [Y/n] y</span><br></pre></td></tr></table></figure></p><h2 id="开启远程访问"><a href="#开启远程访问" class="headerlink" title="开启远程访问"></a>开启远程访问</h2><p>1、防火墙添加3306端口<br><strong>查看firewall状态</strong></p><blockquote><p>firewall-cmd –state<br><strong>状态是not running, 启动firewall</strong><br>systemcal start firewalld<br><strong>状态是running</strong><br>开放3306端口<br>firewall-cmd –zone=public –add-port=3306/tcp –permanent<br>重新载入<br>firewall-cmd –reload</p></blockquote><p>2、明明之前有设置root开启远程的， 但是我这里访问不了， 所以生新去MariaDB赋权限<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#进入Mariadb</span><br><span class="line">mysql -uroot -p</span><br><span class="line">#选择数据库</span><br><span class="line">user mysql;</span><br><span class="line">#添加权限 </span><br><span class="line">grant all on *.* to &apos;root&apos;@&apos;%&apos; identified by &apos;root用户密码&apos; with grant option;</span><br><span class="line">#重新载入</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure></p>]]></content>
      
      
      
        <tags>
            
            <tag> centos 7.2 MariaDB 10.1 yum </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux CentOS 7下Nginx安装Let’ s Encrypt 证书</title>
      <link href="/2018/11/21/%E8%AF%81%E4%B9%A6/"/>
      <url>/2018/11/21/%E8%AF%81%E4%B9%A6/</url>
      
        <content type="html"><![CDATA[<p><strong>证书发行的官方网站：<a href="https://letsencrypt.org" target="_blank" rel="noopener">https://letsencrypt.org</a></strong></p><h3 id="早请Let’-s-Encrypt-证书可以有三种方式："><a href="#早请Let’-s-Encrypt-证书可以有三种方式：" class="headerlink" title="早请Let’ s Encrypt 证书可以有三种方式："></a>早请Let’ s Encrypt 证书可以有三种方式：</h3><ul><li>通过certbot脚本；</li><li>通过支持letencript的虚拟主机提供商</li><li>手工申请manual mode</li></ul><p>这里采用certbot脚本方式申请；</p><h1 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h1><ul><li>拥有一个域名，例如mydomain.com (在国内主机的用的话，还需要通过ICP备案)</li><li>在域名服务器创建一条A记录，指向云主机的公网IP地址。例如demo.mydomain.com指向xxx.xxx.xxx.xxx的IP地址</li><li>要等到新创建的域名解析能在公网上被解析到。</li></ul><h1 id="在主机上安装nginx服务器，-配置好最基本的80的nginx站点"><a href="#在主机上安装nginx服务器，-配置好最基本的80的nginx站点" class="headerlink" title="在主机上安装nginx服务器， 配置好最基本的80的nginx站点"></a>在主机上安装nginx服务器， 配置好最基本的80的nginx站点</h1><p>例如： demo.domain.com 快速配置一个最简单的nginx站点</p><p>1、安装nginx服务器<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nginx</span><br></pre></td></tr></table></figure></p><p>2、配置一个nginx站点<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/www/demo.mydomain.com -p</span><br><span class="line">chown nginx:nginx /opt/www/demo.mydomain.com/ -R</span><br><span class="line">vi /etc/nginx/conf.d/demo.mydomain.com.conf</span><br></pre></td></tr></table></figure></p><p>配置一个80商品的nginx配置文件<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line"><span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line"><span class="attribute">server_name</span> demo.mydomain.com;</span><br><span class="line"><span class="attribute">charset</span> utf-<span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="attribute">root</span> /opt/www/demo.mydomain.com;</span><br><span class="line"><span class="attribute">index</span> index.html index.htm;</span><br><span class="line"></span><br><span class="line"><span class="attribute">access_log</span>  /var/log/nginx/demo.mydomain.com_access.log;</span><br><span class="line"><span class="attribute">error_log</span>   /var/log/nginx/demo.mydomain.com_error.log;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>3、启动nginx服务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/systemctl start nginx</span><br></pre></td></tr></table></figure></p><p>注：要确认CentOS服务器开放了80及443端口<br>4、在浏览器上确认访问到<a href="http://demo.domain.com；" target="_blank" rel="noopener">http://demo.domain.com；</a> 记得在目录里添加一个页面哦； </p><h1 id="安装certbot工具"><a href="#安装certbot工具" class="headerlink" title="安装certbot工具"></a>安装certbot工具</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release</span><br><span class="line">yum install -y certbot</span><br></pre></td></tr></table></figure><h1 id="使用certbot命令初次申请证书"><a href="#使用certbot命令初次申请证书" class="headerlink" title="使用certbot命令初次申请证书"></a>使用certbot命令初次申请证书</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 使用方法：certbot certonly --webroot -w [Web站点目录] -d [站点域名] -m [联系人email地址] --agree-tos</span><br><span class="line"></span><br><span class="line">certbot certonly --webroot -w /opt/www/demo.mydomain.com -d demo.mydomain.com -m myname@gmail.com --agree-tos</span><br></pre></td></tr></table></figure><p>注：联系人email地址要填写真实有效的，letsencrypt会在证书在过期以前发送预告的通知邮件。 申请成功后，会显示以下Congratulations信息<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">IMPORTANT NOTES:</span><br><span class="line"> - Congratulations! Your certificate and chain have been saved at</span><br><span class="line">   /etc/letsencrypt/live/[xxx.xxx.xxx]/fullchain.pem. Your cert will</span><br><span class="line">   expire on 2017-03-20. To obtain a new or tweaked version of this</span><br><span class="line">   certificate in the future, simply run certbot again. To</span><br><span class="line">   non-interactively renew *all* of your certificates, run &quot;certbot</span><br><span class="line">   renew&quot;</span><br><span class="line"> - If you like Certbot, please consider supporting our work by:</span><br><span class="line"></span><br><span class="line">   Donating to ISRG / Let&apos;s Encrypt:   https://letsencrypt.org/donate</span><br><span class="line">   Donating to EFF:                    https://eff.org/donate-le</span><br></pre></td></tr></table></figure></p><p>表示申请成功，证书的保存位置在：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/etc/letsencrypt/live/demo.mydomain.com/</span><br><span class="line"></span><br><span class="line">用户证书                              cert.pem -&gt; ../../archive/demo.mydomain.com/cert1.pem</span><br><span class="line">中间证书                              chain.pem -&gt; ../../archive/demo.mydomain.com/chain1.pem</span><br><span class="line">证书链, chain.pem + cert.pemfullchain.pem -&gt; ../../archive/demo.mydomain.com/fullchain1.pem</span><br><span class="line">证书私钥                              privkey.pem -&gt; ../../archive/demo.mydomain.com/privkey1.pem</span><br></pre></td></tr></table></figure></p><h1 id="查看书有效期的命令"><a href="#查看书有效期的命令" class="headerlink" title="查看书有效期的命令"></a>查看书有效期的命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -noout -dates -in /etc/letsencrypt/live/[demo.mydomain.com]/cert.pem</span><br></pre></td></tr></table></figure><h1 id="设置定时任务自动更新证书"><a href="#设置定时任务自动更新证书" class="headerlink" title="设置定时任务自动更新证书"></a>设置定时任务自动更新证书</h1><p><em>letsencrypt证书有的效期是90天， 但是可以用脚本去更新。</em></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 更新证书</span><br><span class="line">certbot renew --dry-run</span><br><span class="line"></span><br><span class="line"># 如果不需要返回信息， 可以用静默方式</span><br><span class="line">certbot renew --quiet</span><br></pre></td></tr></table></figure><p>注： 更新证书时候网站必须是能访问到的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 可以使用crontab定时更新，例如：</span><br><span class="line"># 每月1号5时执行执行一次更新，并重启nginx服务器</span><br><span class="line">00 05 01 * * /usr/bin/certbot renew --quiet &amp;&amp; /bin/systemctl restart nginx</span><br></pre></td></tr></table></figure></p><h1 id="应用实例，配置nginx使用证书开通https站点"><a href="#应用实例，配置nginx使用证书开通https站点" class="headerlink" title="应用实例，配置nginx使用证书开通https站点"></a>应用实例，配置nginx使用证书开通https站点</h1><p>1、生成Perfect Forward Security (PFS）键值<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /etc/ssl/private/ -p</span><br><span class="line">cd /etc/ssl/private/</span><br><span class="line">openssl dhparam 2048 -out dhparam.pem</span><br></pre></td></tr></table></figure></p><p>说明：</p><ul><li>Perfect Forward Security（PFS)是个什么东西，中文翻译成完美前向保密，一两句话也说不清楚，反正是这几年才提倡的加强安全性的技术。如果本地还没有生成这个键值，需要先执行生成的命令。</li><li>生成的过程还挺花时间的，喝杯咖啡歇会儿吧。</li></ul><p>2、配置nginx站点，例如/etc/ngix/conf.d/demo.domain.com.conf,样例内容如下：<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">server</span> &#123;</span><br><span class="line"><span class="attribute">listen</span> <span class="number">80</span>;</span><br><span class="line"><span class="attribute">server_name</span> demo.mydomain.com;</span><br><span class="line"><span class="attribute">rewrite</span><span class="regexp"> ^</span> https://<span class="variable">$server_name</span><span class="variable">$request_uri</span>? <span class="literal">permanent</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="section">server</span> &#123;</span><br><span class="line">  <span class="attribute">listen</span> <span class="number">443</span> ssl;</span><br><span class="line">  <span class="attribute">server_name</span> demo.mydomain.com;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">charset</span> utf-<span class="number">8</span>;</span><br><span class="line">  <span class="attribute">root</span> /opt/www/demo.mydomain.com;</span><br><span class="line">  <span class="attribute">index</span> index.html index.htm;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">access_log</span>  /var/log/nginx/demo.mydomain.com_access.log;</span><br><span class="line">  <span class="attribute">error_log</span>  /var/log/nginx/demo.mydomain.com_error.log;</span><br><span class="line"></span><br><span class="line">  <span class="comment"># letsencrypt生成的文件</span></span><br><span class="line">  <span class="attribute">ssl_certificate</span> /etc/letsencrypt/live/demo.mydomain.com/fullchain.pem;</span><br><span class="line">  <span class="attribute">ssl_certificate_key</span> /etc/letsencrypt/live/demo.mydomain.com/privkey.pem;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">ssl_session_timeout</span> <span class="number">1d</span>;</span><br><span class="line">  <span class="attribute">ssl_session_cache</span> shared:SSL:<span class="number">50m</span>;</span><br><span class="line">  <span class="attribute">ssl_session_tickets</span> <span class="literal">on</span>;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">ssl_dhparam</span> /etc/ssl/private/dhparam.pem;</span><br><span class="line"></span><br><span class="line">  <span class="attribute">ssl_protocols</span> TLSv1 TLSv1.<span class="number">1</span> TLSv1.<span class="number">2</span>;</span><br><span class="line">  <span class="comment"># 一般推荐使用的ssl_ciphers值: https://wiki.mozilla.org/Security/Server_Side_TLS</span></span><br><span class="line">  <span class="attribute">ssl_ciphers</span> <span class="string">'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128:AES256:AES:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK'</span>;</span><br><span class="line">  <span class="attribute">ssl_prefer_server_ciphers</span> <span class="literal">on</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>3、在浏览器打开<a href="http://demo.domain.com" target="_blank" rel="noopener">http://demo.domain.com</a>, 如果正常跳转到<a href="https://demo.domain.com，就算成功了。" target="_blank" rel="noopener">https://demo.domain.com，就算成功了。</a> 如果是chrome浏览器，在地址栏点击小锁的图标，可以查看证书的详情</p><h1 id="问题分析："><a href="#问题分析：" class="headerlink" title="问题分析："></a>问题分析：</h1><p>在配置过程中有可能会找如下错误信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ImportError: pyOpenSSL</span><br></pre></td></tr></table></figure></p><p>可能是因为linxu的pyOpenSSL的版本过低， 也有可能是certbot的版本太低造成的。 可以试着如下操作一下：<br>1、先卸载yum安装的certbot和pyOpenSSL<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum remove certbot pyOpenSSL;</span><br></pre></td></tr></table></figure></p><p>2、升级pip(如果不是最新版本,pip会提示你升级后再使用)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install --upgrade pip</span><br></pre></td></tr></table></figure></p><p>3、再通过pip安装certbot<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install certbot</span><br></pre></td></tr></table></figure></p><p>4、如果找不到python之类的信息；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y python-devel;</span><br><span class="line">yum install -y openssl-devel;</span><br></pre></td></tr></table></figure></p><p>再执行 pip istall certbot;</p><p>附： 如果电脑没有python信息也可以采用<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y python-devel</span><br><span class="line">yum install -y openssl-devel</span><br></pre></td></tr></table></figure></p><p>还可以通过pip安装pyOpenSSL<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyOpenSSL</span><br></pre></td></tr></table></figure></p><p>OK !<br>附： <a href="https://www.ant-loiter.com">https://www.ant-loiter.com</a> 是成功申请的案例。</p>]]></content>
      
      
      
        <tags>
            
            <tag> Linux Centos Nginx Let’Encrypt ssl TLS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>配置云服务器免密码登录（简单流程）</title>
      <link href="/2018/11/20/%E9%85%8D%E7%BD%AE%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%EF%BC%88%E7%AE%80%E5%8D%95%E6%B5%81%E7%A8%8B%EF%BC%89/"/>
      <url>/2018/11/20/%E9%85%8D%E7%BD%AE%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%EF%BC%88%E7%AE%80%E5%8D%95%E6%B5%81%E7%A8%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<p><code>在本机（这里以mac命令为例， 如果是其它的操作机请自行完成命令转换）</code></p><h4 id="在本机生成本地的私钥和公钥，命令如下："><a href="#在本机生成本地的私钥和公钥，命令如下：" class="headerlink" title="在本机生成本地的私钥和公钥，命令如下："></a>在本机生成本地的私钥和公钥，命令如下：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;xxx@xx.com&quot;</span><br></pre></td></tr></table></figure><p>命令执行完成后， 会有如下几步的交互：</p><ul><li>询问生成的私钥和公钥存放的位置，默认为~/.ssh/目录下名为：id_rsa 和 id_rsa.pub</li><li>询问是否设置密码： 输入密码，再确认输入密码</li><li>确认后， 完成；</li></ul><p>在~/.ssh/目录下就会生成二个文件，./id_rsa和id_rsa.pub ； </p><p>接下来，启动一个ssh的代理进程，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;(ssh-agent -s)&quot; //将ssh添加到代理当时，</span><br><span class="line">ssh-add ~/.ssh/id_rsa //将刚生成的私钥添加到ssh命令中</span><br></pre></td></tr></table></figure></p><p>再往后， 上到需要远程连接的服务器，cd 到根目录，确保在~/.ssh/上没有类假的id_rsa和id_rsa.pub文件， 如果有的话，一定要先备份（备份时id_rsa.pub文件最好不改变后缀名），命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;aaa@bbb.com&quot;</span><br><span class="line">第一步确认生成文件保存的位置， 一般情况下默认位置即可。</span><br><span class="line">第二步确认输入密码</span><br><span class="line">完成后，生成文件</span><br></pre></td></tr></table></figure></p><p>再往后， 需要在~/.ssh目录下生成一个较验授权文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~/.ssh/authorized_keys</span><br><span class="line">vi authorized_keys</span><br></pre></td></tr></table></figure></p><p>完成以上的配置之后， 接下来就是对authorized_keys文件进行授权处理，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 600 authorized_keys</span><br></pre></td></tr></table></figure></p><p>重启 ssh 命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service ssh restart</span><br></pre></td></tr></table></figure></p><p>完成， 有问题请随时批评指正！！</p><p>蚂蚁学技！！！ <a href="http://www.ant-loiter.com">www.ant-loiter.com</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> logo 免密 ssh-keygen 登录 云服务器  ssh-keygen 无密码登录 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx-web-ssl 从网络原理来看SSL安全协议</title>
      <link href="/2018/11/16/nginx-web-ssl/"/>
      <url>/2018/11/16/nginx-web-ssl/</url>
      
        <content type="html"><![CDATA[<h1 id="SSL-TLS"><a href="#SSL-TLS" class="headerlink" title="SSL / TLS"></a>SSL / TLS</h1><p>SSL (Secure Sockets Layer )<br>TLS (Transport Layer Security)</p><p>网络请求的安全加密码是发生成ISO/OSI模型的表示层的， TCP/IP模型的应用层 </p><p>完成了， 握手、交换密钥、告警、对称加密的应用数据 </p><h1 id="安全密码套件解读"><a href="#安全密码套件解读" class="headerlink" title="安全密码套件解读"></a>安全密码套件解读</h1><p>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256</p><ul><li>密钥交换算法；  ECDHE</li><li>身份验证算法：  RSA</li><li>对称加密算法、强度、分组模式： AES_128_GSM</li><li>签名hash算法： SHA256</li></ul><h1 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h1><p>密钥 与 明文 进行 异或操作后等到密文； </p><p>接收者可以，将拿到的密码文稿与密钥再进行异或操作，便可以还原明文内容 。 </p><h1 id="证书类型"><a href="#证书类型" class="headerlink" title="证书类型"></a>证书类型</h1><p>DV  OV   EV</p><p>Nginx 可以打开OCSP的配置， 主动去OCSP（CA）下的运验证评书的有效性。 </p><p>DV（domain validated) 域名验证</p><p>OV（organization validated) 组织验证</p><p>EV（extended validation) 扩展验证 ，（最高级， 验证更严格）会在地址栏里面显示公司名称。 </p><h1 id="证书链"><a href="#证书链" class="headerlink" title="证书链"></a>证书链</h1><p>发送二个证书， 一个是域名证书， 二个就是二级证书， 。 根证书不需要发送。 操作系统内置了。 </p><h1 id="TLS-通讯过程"><a href="#TLS-通讯过程" class="headerlink" title="TLS 通讯过程"></a>TLS 通讯过程</h1><ul><li><p>验证身份</p></li><li><p>达成安全套件共识  （椭圆曲线算法）</p></li><li><p>传递密钥  （采用非对称加密码算法，DHCE）</p></li><li><p>加密通讯 </p></li></ul><h1 id="创建DV-证书"><a href="#创建DV-证书" class="headerlink" title="创建DV 证书"></a>创建DV 证书</h1><ul><li><p>centos 下， yum install python2-certbot-nginx<br>安装成功手， 会有certbot命令：</p></li><li><p>certbot –nginx –nginx-server-root=/usr/local/openresty/nginx/conf/ -d ant-loiter.sub.pu </p></li></ul><p>后面会作一个交互， 是否做重定向选择：</p><p>成功后， nginx的配置也完成了。 </p><p>/etc/letsencrypt/options-ssl-nginx.conf 配置文件里面有关于证书有效性的握手操作：</p><p>ssl_session_cache shared:le_nginx_SSL:1m;  作了一个1m的证书缓存， 1M大约可以搞定4000个链接； </p><p>ssl_session_timeout 1440m;  在这个配置时间后才会断开连接， 表示一天时间； </p><p>ssl_protocols TLSv1 TLSv1.1 TLSv1.2</p><p>ssl_preper_server_ciphers on;</p><h1 id="openresty-整合lua-扩展nginx-的功能；"><a href="#openresty-整合lua-扩展nginx-的功能；" class="headerlink" title="openresty 整合lua 扩展nginx 的功能；"></a>openresty 整合lua 扩展nginx 的功能；</h1><p>多线程设计时， 如果有一个程序出现内存或能寻址错误时， 有可能导致崩溃。</p><p>所以nginx是采用了多进程的设计模式：</p><ul><li><p>master process 进程</p></li><li><p>Worker进程， 最好是配置成cpu核心一致的进程数， 最好还是要把每一个worker进程与cpu进行绑定。 </p></li><li><p>Cache manager 进程</p></li><li><p>Cache loader 进程</p></li></ul><h1 id="Nginx进程管理：-信号-模式"><a href="#Nginx进程管理：-信号-模式" class="headerlink" title="Nginx进程管理： 信号 模式"></a>Nginx进程管理： 信号 模式</h1><ul><li><p>Master 进程信号</p><ul><li>监控worker进程： CHLD   这是worker进程给master进程发送的信息号，表示退出了。 </li><li>管理worker进程</li><li><p>接收信号</p><ul><li>TERM, INT   表示立刻停止；</li><li>QUIT         表示优雅的停止；</li><li>HUP          表示重装配置文件；</li><li>USR1         表示重新打开日志文件， 作日志文件的切割</li><li>USR2*</li><li>WINCH*</li></ul><p>说明： 上面四个信号是可以直接给master进程发送的信息号， 后面二个（带星号）只能通过kill 命令对master的pid进程发送的信号，这二个进程是专来用来做热布置用的， USR2 表示启动另一个master进程用来升级nginx的版本， WINCH信号是用来让master进程关闭掉旧的worker进程； </p></li></ul></li></ul><ul><li><p>Worker 进程信号</p><ul><li><p>接收信号</p><ul><li>TERM,INT</li><li>QUIT</li><li>USR1</li><li>WINCH</li></ul><p>不建议直接对worker进程发送信号； 统一用master管理。</p></li></ul></li><li><p>nginx 命令行信息</p><ul><li>reload: HUP</li><li>reopen: USR1</li><li>stop: TERM</li><li>quit: QUIT</li></ul><p>这三个信号，前面的使用语法是直接通过调用nginx命令 -s 进执行，与用kill<br>对master进程发送信息， 是一样的效果； </p><h1 id="reload-流程"><a href="#reload-流程" class="headerlink" title="reload 流程"></a>reload 流程</h1><p>使用语法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./sbin/nginx -s reload </span><br><span class="line">或</span><br><span class="line">kill -HUP master pid</span><br></pre></td></tr></table></figure><p>执行了哪些操作，如下：</p><ul><li>向master进程发送HUP信号（reload命令）</li><li>master进程核验配置语法是否正确</li><li>master进程打开新的监听端口</li><li>master进程用新配置启动新的worker子进程</li><li>master进程向老worker子进程发送QUIT信号（优雅退出信号，而不是TERM立即停止信号）</li><li>老的worker进程关闭监听句柄， 处理完当前连接后结束进程</li></ul><p>如果旧的worker进程由于请求的问题长时间没有被关闭掉时， 在新版本的nginx里有一个配置项，worker_shutdown_timeout 配置， ； </p></li></ul><h1 id="Nginx热升级流程"><a href="#Nginx热升级流程" class="headerlink" title="Nginx热升级流程"></a>Nginx热升级流程</h1><p> 步骤如下：</p><ul><li>将旧Nginx文件换成新的Nginx文件（注意备份）<br>说明： linxu在替换一个正在执行的文件时， 是需要加参数-f<br>操作：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mv ./sbin/nginx ./sbin/nginx.old</span><br><span class="line"></span><br><span class="line">cp -r ~~/nginx ./sbin/nginx -f </span><br><span class="line">即可</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>向master进程发送USR2信号， 表示要根据新的配置文件启动master进程<br>这里指的master进程是根据旧配置文件的master进程，找到其PID进程ID， 采用kill -USR2 pid 发送信号。注意一般在nginx安装目录conf下有一个nginx.pid文件，是记录了当前主要工作的master进程的id值 </p></li><li><p>master进程修改pid文件名， 加后缀.oldbin</p></li><li><p>master进程用新Nginx文件启动新Master进程</p></li><li><p>向老master进程发送WINCH信号， 关闭老worker；<br>kill -WINCH oldmaster pid</p></li><li><p>回滚： 向老master发送HUP， 向新master发送QUIT信号</p></li></ul><h1 id="worker进程：优雅的关闭"><a href="#worker进程：优雅的关闭" class="headerlink" title="worker进程：优雅的关闭"></a>worker进程：优雅的关闭</h1><ul><li><p>在nginx.conf配置文件中配置<br>worker_shutdown_timeout 配置项， 这个配置项就是针对优雅关闭的；<br>就是指定当master进程给worker发送优雅关闭时， 有可能有些worker进程还是阻塞中， 不能很快关闭， 所以这上配置项就是针对这种情况的。 超时后， 就会执行立即关闭worker进程的动作； </p></li><li><p>关闭监听句柄</p></li><li><p>关闭空闲连接</p></li><li><p>在循环中等待全部连接关闭</p></li><li><p>退出进程</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> nginx openresty tengine ssl </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>wget 、 yum及yum repo，使用技巧</title>
      <link href="/2018/11/16/wget/"/>
      <url>/2018/11/16/wget/</url>
      
        <content type="html"><![CDATA[<h1 id="通过wget-下载整个站点内容"><a href="#通过wget-下载整个站点内容" class="headerlink" title="通过wget 下载整个站点内容"></a>通过wget 下载整个站点内容</h1><p>wget -c -r -np -k -L -p <a href="https://docs.oracle.com/en/java/javase/11/docs/api/index.html" target="_blank" rel="noopener">https://docs.oracle.com/en/java/javase/11/docs/api/index.html</a></p><h1 id="yum-配置源仓库"><a href="#yum-配置源仓库" class="headerlink" title="yum 配置源仓库"></a>yum 配置源仓库</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install yum-utils</span><br><span class="line"></span><br><span class="line">sudo yum-config-manager --add-repo https://openresty.org/package/centos/openresty.repo</span><br><span class="line"></span><br><span class="line">上命令是配置openresty源的配置命令。</span><br></pre></td></tr></table></figure><p>配置好源后， 就可以采用yum install 进行安装相应的组件。 </p><p>如  sudo yum install openresty </p>]]></content>
      
      
      
        <tags>
            
            <tag> wget download 爬取 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx-config 配置知识点</title>
      <link href="/2018/11/15/nginx-config/"/>
      <url>/2018/11/15/nginx-config/</url>
      
        <content type="html"><![CDATA[<h1 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h1><h2 id="location-表示一个请求的路径，-如"><a href="#location-表示一个请求的路径，-如" class="headerlink" title="location 表示一个请求的路径， 如"></a>location 表示一个请求的路径， 如</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location / &#123;</span><br><span class="line">  root  dlib/;    # 不建议 ，一般会会URL中的一些路径带到文件目录中来</span><br><span class="line">  alias dlib/;    # 建议</span><br><span class="line">&#125;</span><br><span class="line">这里的二个配置意思都是一样的， 就是将请求过来的所有请求与dlib里面的页面一一对应； </span><br><span class="line">这里建议采用alias 进行配置， 放弃root配置的方式；</span><br></pre></td></tr></table></figure><h2 id="配置giz"><a href="#配置giz" class="headerlink" title="配置giz"></a>配置giz</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gzip on;   打开gzip开关， off 是半闭</span><br><span class="line">gzip_min_length  1;   指定最小压缩的阀值，但位为bytes, 可以显示的指定单位</span><br><span class="line">gzip_comp_level   2;   指定压缩级别，级别越低压缩速度越快文件压缩比越小，反之速度更慢 文件压缩比越大。 </span><br><span class="line">gzip_types  text/plain application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png; 配置允许压缩的文件类型</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line">## autoindex 组件配置</span><br></pre></td></tr></table></figure><p>Syntax:    autoindex on | off;<br>Default:<br>autoindex off;</p><h2 id="Context-http-server-location"><a href="#Context-http-server-location" class="headerlink" title="Context:    http, server, location"></a>Context:    http, server, location</h2><p>Syntax:    autoindex_exact_size on | off;<br>Default:<br>autoindex_exact_size on;</p><h2 id="Context-http-server-location-1"><a href="#Context-http-server-location-1" class="headerlink" title="Context:    http, server, location"></a>Context:    http, server, location</h2><p>Syntax:    autoindex_format html | xml | json | jsonp;<br>Default:<br>autoindex_format html;<br>Context:    http, server, location</p><h2 id="This-directive-appeared-in-version-1-7-9"><a href="#This-directive-appeared-in-version-1-7-9" class="headerlink" title="This directive appeared in version 1.7.9."></a>This directive appeared in version 1.7.9.</h2><p>Syntax:    autoindex_localtime on | off;<br>Default:<br>autoindex_localtime off;<br>Context:    http, server, location</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 针对不同的浏览配置不同的访问带宽，</span><br></pre></td></tr></table></figure><p>set $limit_rate 1k;<br>配置nginx控制的访问速度， 以上配置是每秒1K的访问速度；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">查看文档： www.nginx.org -&gt; ngx_http_core_module -&gt; Embedded Variables; 里面可以查阅到相应的系统定义的变量信息。</span><br><span class="line"></span><br><span class="line">## access.log日志格式定义 format</span><br></pre></td></tr></table></figure></p><p>log_format main  ‘$remote_addr -  $remote_user [$time_local] “$request”‘<br>‘$status $body_bytes_sent “$http_referer” ‘<br>‘“$http_user_agent” “$http_x_forwarded_for”‘;</p><p>配置好后， 在不同的模块中可以选择性的使用他， 采用access_log 指令，如：<br>access_log    logs/geek_access.log main;<br>指令名          日志目录和名称          采用哪一个日志格式定义<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">以上可以自定议日志文件的记录格式 ， 所有内部组件和第三方组件里的变量都 可以在日志项目里面进行配置。 根据业务需要，来定义日志格式 。 </span><br><span class="line"></span><br><span class="line">## 配置请求的来源限制， </span><br><span class="line"></span><br><span class="line">如， 只允许本机访问当前应用， 配置如下：</span><br></pre></td></tr></table></figure></p><p>server {<br>  listen  8080; 换成 listen  127.0.0.1:8080;<br>  这个配置就表示只允许本机访问当前应用。<br>}<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 配置反向代理步骤，</span><br><span class="line"></span><br><span class="line">1、 在配置里添加一个upstream 模块如下：</span><br></pre></td></tr></table></figure></p><p>upstream local {<br>  server  127.0.0.1:8080;   这是指向了一个应用服务地址，可以添加多个upstream 模块；并取名为local<br>}<br>这个模板需要定义在http模块内部； </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">2、 配置一个server_name 域名</span><br><span class="line"></span><br><span class="line">server_name geektime.taohui.pub;</span><br><span class="line"></span><br><span class="line">3、配置代理的几个参数</span><br><span class="line"></span><br><span class="line">proxy_set_header  Host  $host;</span><br><span class="line">proxy_set_header  X-Real-IP  $remote_addr;</span><br><span class="line">proxy_set_header  X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line"></span><br><span class="line">4、配置缓存的启用，可以提升访问效率</span><br><span class="line"></span><br><span class="line">proxy_cache my_cache;   my_cache是一个定义好的缓存名称； 在location里面配置了这个， 表示当前请求需要启用缓存，并且将缓存存在这个目录下。 </span><br><span class="line"></span><br><span class="line">proxy_cache_key  $host$uri$is_args$args;  可以自定义缓存的key  </span><br><span class="line">proxy_cache_valid  200 304 302 1d;   配置什么样的请求缓存不起作用</span><br><span class="line"></span><br><span class="line">5、最一步配置反向代理</span><br><span class="line"></span><br><span class="line">proxy_pass  http://local;   指向local这个上层应用的名称； </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 配置缓存</span><br><span class="line"></span><br><span class="line">在 ngx_http_proxy_module 里面有一个 proxy_cache 模块， 基础配置例子：</span><br><span class="line">1、 配置一个缓存用例， 如下：</span><br></pre></td></tr></table></figure><p>proxy_cache_path /tmp/nginxcache levels=1:2 keys_zone=my_cache:10m max_size=10g inactive=60m use_temp_path=off;</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 配置Goaccess工具，对access.log文件进行实时监控</span><br><span class="line"></span><br><span class="line">1、 先在服务器上安装goaccess命令的支持， 其官方地址为：https://goaccess.io/</span><br><span class="line"></span><br><span class="line">通过源码安装，命令如下：</span><br></pre></td></tr></table></figure><p>$ wget <a href="https://tar.goaccess.io/goaccess-1.2.tar.gz" target="_blank" rel="noopener">https://tar.goaccess.io/goaccess-1.2.tar.gz</a><br>$ tar -xzvf goaccess-1.2.tar.gz<br>$ cd goaccess-1.2/<br>$ ./configure –enable-utf8 –enable-geoip=legacy<br>$ make</p><h1 id="make-install"><a href="#make-install" class="headerlink" title="make install"></a>make install</h1><p>yum -y install GeoIP-devel</p><p>yum install ncurses-devel</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">使用时的命令如下：</span><br><span class="line">``` </span><br><span class="line">goaccess loiter.access.log -o ../html/report.html --real-time-html --time-format=&apos;%H:%M:%S&apos; --date-format=&apos;%M:%S&apos; --date-format=&apos;%d/%b/%Y&apos; --log-format=COMBINED</span><br><span class="line">执行这个命令后， 就会启动一个webstock的进程， 来实时的监听服务，来解析指定的access.log日志文件 。 </span><br><span class="line"></span><br><span class="line">--real-time-html 表示实进更新报告页面数据；</span><br></pre></td></tr></table></figure><p>以上命令会生成一个报告性的页面， 指定的时report.html ， 在nginx里面可以配置一个location 就可以，如下：<br><code>`</code><br>location /report.html {<br>  alias /usr/local/nginxxx/html/report.html;<br>}</p><p>然后再对它进行 nginx -s reload 更新配置文件，即可。 </p>]]></content>
      
      
      
        <tags>
            
            <tag> nginx web config nginx.conf </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>nginx 知识点</title>
      <link href="/2018/11/15/nginx/"/>
      <url>/2018/11/15/nginx/</url>
      
        <content type="html"><![CDATA[<h1 id="nginx官网"><a href="#nginx官网" class="headerlink" title="nginx官网"></a>nginx官网</h1><p><a href="http://www.nginx.org" target="_blank" rel="noopener">www.nginx.org</a> 开源免费版本<br><a href="http://www.nginx.com" target="_blank" rel="noopener">www.nginx.com</a>  企业收费版本</p><p>点击 download 下载稳定， 中间版本号为单数表示Mainline version, 中间版本号为双数时表示稳定版本（Stable version)</p><p>阿里巴巴， Tengine 也是一个修改了nginx的一个版本， 也有一个自已的生态， 但是不能跟着nginx同步更新。 </p><p>免费OpenResty 与商业版 </p><p>开源OpenResty  <a href="http://www.openresty.org" target="_blank" rel="noopener">www.openresty.org</a><br>商业版OpenResty, <a href="http://www.openresty.com" target="_blank" rel="noopener">www.openresty.com</a></p><p>章亦春， 创始人兼CEO</p><h1 id="配置nginx时-VI编辑时的高亮配置，"><a href="#配置nginx时-VI编辑时的高亮配置，" class="headerlink" title="配置nginx时 VI编辑时的高亮配置，"></a>配置nginx时 VI编辑时的高亮配置，</h1><p>需要把nginx下载包contrib/vim目录下的所有文件拷贝到当前用户家目录下的.vim、目录下，操作如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp -r ./contrib/vim/* ~/.vim/</span><br></pre></td></tr></table></figure></p><p>这样， 在配置nginx的配置时，就会高亮显示对应语法； </p><h1 id="编译nginx源码时，-里面有一个目录可参考虑，"><a href="#编译nginx源码时，-里面有一个目录可参考虑，" class="headerlink" title="编译nginx源码时， 里面有一个目录可参考虑，"></a>编译nginx源码时， 里面有一个目录可参考虑，</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./configure --help | more (进行分页显示)</span><br><span class="line">可以查看编写帮助，在里面可以配置相应的参数添加不周的模块支持</span><br><span class="line"></span><br><span class="line">--prefix=PATH 表示指定需要将nginx编译到哪个目录下</span><br></pre></td></tr></table></figure><p>编译成功后， 还是不会在指定的目录下进行创建目录和文件 ，会在源码目录下创建一个objs目录， 进行 make， 接下来时行 make install<br>其实就是进行一个目录安装目录创建和文件拷贝。</p><p>如果成功后， 就会在目标安装目录下有安装好的文件， 进入。<br>conf html logs sbin<br>四个目录；</p><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>./sbin/nginx -c ./conf/nginx.conf<br>指定配置文件启动nginx服务， </p><h2 id="检查nginx配置文件正确性"><a href="#检查nginx配置文件正确性" class="headerlink" title="检查nginx配置文件正确性"></a>检查nginx配置文件正确性</h2><p>./sbin/nginx -t 检查配置文件正确性， 也可以指定配置文件<br>./bin/nginx -t -c ./conf/nginx.conf</p><h1 id="异常处理-如果在编辑nginx时报如下异常信息："><a href="#异常处理-如果在编辑nginx时报如下异常信息：" class="headerlink" title="[异常处理]如果在编辑nginx时报如下异常信息："></a>[异常处理]如果在编辑nginx时报如下异常信息：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./configure: error: the HTTP rewrite module requires the PCRE library.</span><br><span class="line">You can either disable the module by using --without-http_rewrite_module</span><br><span class="line">option, or install the PCRE library into the system, or build the PCRE library</span><br><span class="line">statically from the source with nginx by using --with-pcre=&lt;path&gt; option.</span><br></pre></td></tr></table></figure><p>可以通过安装pcre-devel解决问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install pcre-devel</span><br></pre></td></tr></table></figure></p><p>继续编辑</p><h1 id="异常处理-如果在编辑nginx时报如下异常信息：-1"><a href="#异常处理-如果在编辑nginx时报如下异常信息：-1" class="headerlink" title="[异常处理]如果在编辑nginx时报如下异常信息："></a>[异常处理]如果在编辑nginx时报如下异常信息：</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">./configure: error: the HTTP gzip module requires the zlib library.</span><br><span class="line">You can either disable the module by using --without-http_gzip_module</span><br><span class="line">option, or install the zlib library into the system, or build the zlib library</span><br><span class="line">statically from the source with nginx by using --with-zlib=&lt;path&gt; option.</span><br><span class="line"></span><br><span class="line">可以通过安装：</span><br><span class="line"></span><br><span class="line">yum -y install zlib-devel</span><br></pre></td></tr></table></figure><h2 id="异常处理-没有openSSL支持错误"><a href="#异常处理-没有openSSL支持错误" class="headerlink" title="[异常处理] 没有openSSL支持错误"></a>[异常处理] 没有openSSL支持错误</h2><p>./configure: error: SSL modules require the OpenSSL library.<br>You can either do not enable the modules, or install the OpenSSL library<br>into the system, or build the OpenSSL library statically from the source<br>with nginx by using –with-openssl=<path></path> option.</p><p>可以通以以下命令安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install openssl openssl-devel</span><br></pre></td></tr></table></figure></p><h1 id="nginx配置语法"><a href="#nginx配置语法" class="headerlink" title="nginx配置语法"></a>nginx配置语法</h1><ul><li>配置文件由指令和指令块构成</li><li>每条指令以； 分号结尾， 指令与参数间以空格答号分隔</li><li>指令块以{}大括号将多条指令组织在一起</li><li>include语句允许组合多个配置文件以提升可维护性</li><li>使用#符号添加注解， 提高可读性</li><li>使用$符号使用变量， 变量有系统变量和自定义变量</li><li>部分指令的参数支持正则表达式， 如 ~* (jpg|png|gif|jpeg)/g/i</li></ul><h1 id="Nginx命令行"><a href="#Nginx命令行" class="headerlink" title="Nginx命令行"></a>Nginx命令行</h1><ul><li><p>格式 ： nginx -s reload  表示重启加载或叫做启用新的配置文件 </p></li><li><p>帮助 ： -？ -h    如 ./sbin/nginx -? [-h]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Options:</span><br><span class="line">  -?,-h         : this help   </span><br><span class="line">  -v            : show version and exit</span><br><span class="line">  -V            : show version and configure options then exit</span><br><span class="line">  -t            : test configuration and exit</span><br><span class="line">  -T            : test configuration, dump it and exit</span><br><span class="line">  -q            : suppress non-error messages during configuration testing</span><br><span class="line">  -s signal     : send signal to a master process: stop, quit, reopen, reload 给nginx主进程发送信号，如stop,quit,reopen,reload;</span><br><span class="line">  -p prefix     : set prefix path (default: /usr/local/nginx-1.14.1/)</span><br><span class="line">  -c filename   : set configuration file (default: conf/nginx.conf)</span><br><span class="line">  -g directives : set global directives out of configuration file</span><br></pre></td></tr></table></figure></li><li><p>使用指定的配置文件： -c</p></li><li>指定配置指令： -g</li><li>指定运行目录： -p</li><li><p>发送信息： -s </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">立刻停止服务： stop</span><br><span class="line">优雅的停止服务： quit</span><br><span class="line">重载配置文件： reload</span><br><span class="line">重新开始记录日志文件： reopen</span><br></pre></td></tr></table></figure></li><li><p>测试配置文件是否有语法错误： -t  -T</p></li><li>打印nginx的版本信息、编译信息等： -v -V</li></ul><h2 id="重载配置文件"><a href="#重载配置文件" class="headerlink" title="重载配置文件"></a>重载配置文件</h2><p>先修改好配置文件 ， 采用-t进行测试，没有问题后， 可以用以下命令进行配置文件重载；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/nginx -s reload</span><br></pre></td></tr></table></figure></p><h2 id="热部署"><a href="#热部署" class="headerlink" title="热部署"></a>热部署</h2><p>只需要升级./bin/nginx的二进制文件， 就可以完成版本的升级； </p><p>1、 配置现有的nginx文件<br>cp  ./sbin/nginx ./sbin/nginx-bak<br>2、进入新编译后的nginx后，再把nginx二进制文件拷贝到安装目录./sbin下<br>cp -r ./nginx /usr/local/nginx-1.14.1/sbin/ -f<br>选择覆盖，即可完成拷贝；</p><p>完成上面的准备工作后， 就可以开始进行热部署了， </p><ul><li>给nginx的主进程发送一个信号-USR2  如下<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kill -USR2 PID</span><br><span class="line">这样nginx就会采用新的nginx命令启动master和相应的worker进程， 端口也会被新的进程监听， 接下来就可以给老的master</span><br><span class="line">进程再发送一个-WINCH信号</span><br><span class="line"></span><br><span class="line">kill -WINCH PID</span><br><span class="line">这时，老的master进程还会在运行着， 老的worker进程就会被优雅的关闭掉； 到些就完成了一次nginx的版本升级。 不停服务的情况下的升级； 帅</span><br><span class="line"></span><br><span class="line">老的master进行还在， 为的是如果新的版本存在问题，可以进行回滚操作； </span><br><span class="line">如查操作， 继续学习中......</span><br><span class="line">针对老的master进程可以发送-reload的信号让他重新进行任务接管。</span><br></pre></td></tr></table></figure></li></ul><h2 id="切割日志文件"><a href="#切割日志文件" class="headerlink" title="切割日志文件"></a>切割日志文件</h2><p>1、 把日志文件移动并重命名<br>2、 再给nginx发一个reopen的信号即可。<br>可以将这相操作编写成一个shell脚本，<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Rotate the Nginx logs to prevent a single logfile from consuming too mach disk space;</span></span><br><span class="line">LOGS_PATH=/usr/local/nginx-1.14.1/logs/history</span><br><span class="line">CUR_LOGS_PATH=/usr/local/nginx-1.14.1/logs</span><br><span class="line">YESTERDAY=$(date -d "yesterday" +%Y-%m-%d)</span><br><span class="line">mv $&#123;CUR_LOGS_PATH&#125;/access.log $&#123;LOGS_PATH&#125;/access_$&#123;YESTERDAY&#125;.log</span><br><span class="line">mv $&#123;CUR_LOGS_PATH&#125;/error.log $&#123;LOGS_PATH&#125;/error_$&#123;YESTERDAY&#125;.log</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 向Nginx 主进程发送USR1信号， USR1信号就是重新打开日志文件</span></span></span><br><span class="line">kill -USR1 $(cat /usr/local/nginx-1.14.1/logs/nginx.pid)</span><br></pre></td></tr></table></figure></p><p><code>可以通过tree命令进行目录内容展示</code></p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>如何进行容量设计</title>
      <link href="/2018/11/12/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%AE%B9%E9%87%8F%E8%AE%BE%E8%AE%A1/"/>
      <url>/2018/11/12/%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%AE%B9%E9%87%8F%E8%AE%BE%E8%AE%A1/</url>
      
        <content type="html"><![CDATA[<p>常见的容量评估包括数据量、并发量、带宽、CPU/MEM/DISK等， 今天分享的内容， 就以并发量为例， 看看如何通过五个步骤， 得到问题的答案：</p><p>步骤一： 评估总访问量</p>]]></content>
      
      
      <categories>
          
          <category> 架构性能分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 容量设计 架构 压力 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Elasticsearch 高可靠实时分布式的搜索工具</title>
      <link href="/2018/11/09/Elasticsearch/"/>
      <url>/2018/11/09/Elasticsearch/</url>
      
        <content type="html"><![CDATA[<h2 id="Elastricsearch"><a href="#Elastricsearch" class="headerlink" title="Elastricsearch"></a>Elastricsearch</h2><p>是一个采用Restfal API标准的高扩展、高可用的实时数据分析的全文搜索工具。 </p><h2 id="常用概念"><a href="#常用概念" class="headerlink" title="常用概念"></a>常用概念</h2><ul><li><p>Node （节点）： 单个的装有Elasticsearch服务并且提供故障转移和扩展的服务器。</p></li><li><p>Cluster （集群）： 一个集群就是由一个可多个node组织在一起， 共同工作， 共同分享整个数据具有负载均衡功能的集群。补充一点， Elastricsearch的每一个节点都是平等的。只是master节点，</p></li><li><p>Document (文档)：一个文档是一个可被索引的基础信息单元。 </p></li><li><p>Index （索引）： 索引就是一个拥有几分相似特征的文档的集合。 </p></li><li><p>Type （类型）： 一个索引中， 你可以定义一种或多种类型。 </p></li><li><p>Field（列）： Field 是 Elastriscearch的最小单位， 相当于数据的某一列。 </p></li><li><p>Shards （分片）：Elastricsearch将索引分成若干份， 每个部分就是一个shard。</p></li><li><p>Replicas（复制）： Replicas 是索引一份或多份拷贝。 </p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> elasticsearch HA 时实 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>分库分表</title>
      <link href="/2018/11/08/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"/>
      <url>/2018/11/08/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/</url>
      
        <content type="html"><![CDATA[<p>常用的分库分表的中间件：</p><ul><li><p>阿里的TDDL， DRDS和cobar</p></li><li><p>开源社区的sharding-jdbc (3.x已经更名为sharding-sphere);</p></li><li><p>民间组织的MyCAT</p></li><li><p>360的Atlas</p></li><li><p>美团的zebra</p></li></ul><p>当前所有的分库分表的中间件全部可以归结为两大类：</p><ul><li><p>CLIENT 模式； </p></li><li><p>PROXY 模式；</p></li></ul><p>CLIENT 模式代表有TDDL， sharding-jdbc， </p><p>PROXY 模式代表有cobar MyCAT， sharding-sphere；</p><p>但是，无论是CLIENT模式， 还是PROXY模式。 几个核心的步骤是一样的： </p><ul><li><p>SQL 解析</p></li><li><p>重写</p></li><li><p>路由</p></li><li><p>执行</p></li><li><p>结果归并</p></li></ul><p>CLIENT 模式，架构简单， 性能损耗小， 运维成本低； </p><p>例如：</p><p>分库分表， 第一步就是（最重要的一步）， 即sharding column的选取， sharding column选择的好坏将直接决定整个分库分表方案最终是否成功。 而sharding column 的选取跟业务强相关， 笔者认为选择sharding column的方法最主要的分析你是API流量，优先考虑流量大的API， 将流量比较大的API对应的SQL提取出来， 将这些SQL共同的条件作为sharding column。 例如一般的OLTP系统都是对用户提供服务， 这些API对应的SQL都有条件用户ID， 那么， 用户ID就是非常好的sharding column。 </p><p>如：</p><p>几个主要的处理思路：</p><ul><li><p>只选取一个sharding column 进行分库分表； </p></li><li><p>多个sharding column 多个分库分表； </p></li><li><p>sharding column分库分表 + es； </p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 分库 分表 公区 高效 海量数据 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MySQL数据库几个常用的配置经验（十大错误案例）</title>
      <link href="/2018/11/07/MySQL%E2%80%94%E2%80%94config/"/>
      <url>/2018/11/07/MySQL%E2%80%94%E2%80%94config/</url>
      
        <content type="html"><![CDATA[<h2 id="One-Too-Many-Connections-连接数过多，-导致连接不上数据库，-业务无法正常进行"><a href="#One-Too-Many-Connections-连接数过多，-导致连接不上数据库，-业务无法正常进行" class="headerlink" title="One: Too Many Connections (连接数过多， 导致连接不上数据库， 业务无法正常进行)"></a>One: Too Many Connections (连接数过多， 导致连接不上数据库， 业务无法正常进行)</h2><p>问题：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">show variables like &apos;%max_connection%&apos;;</span><br><span class="line"></span><br><span class="line">可以查出允许的最大连接数；</span><br><span class="line"></span><br><span class="line">配置全局的最大连接数：</span><br><span class="line"></span><br><span class="line">set global max_connection = 1;</span><br></pre></td></tr></table></figure></p><p>配置完成后， 再登录的话就会报错， 因为超出了最大的连接数； 报如下错误：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error 1040 (00000) : Too Many Connections</span><br></pre></td></tr></table></figure></p><p>解决：</p><ul><li><p>首先考虑在我们Mysql数据库参数文件里面， 对应的max_connections这个参数值 是不是设置的太小了， 导致客户端连接数超过了数据库所承受的最大值 。 </p></li><li></li></ul>]]></content>
      
      
      <categories>
          
          <category> MySQL config </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL config my.conf 案例 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CentOS7使用firewalld打开关闭防火墙与端口</title>
      <link href="/2018/11/05/firewalld/"/>
      <url>/2018/11/05/firewalld/</url>
      
        <content type="html"><![CDATA[<p>1、firewalld的基本使用<br>启动： systemctl start firewalld<br>关闭： systemctl stop firewalld<br>查看状态： systemctl status firewalld<br>开机禁用  ： systemctl disable firewalld<br>开机启用  ： systemctl enable firewalld</p><p>2.systemctl是CentOS7的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。<br>启动一个服务：systemctl start firewalld.service<br>关闭一个服务：systemctl stop firewalld.service<br>重启一个服务：systemctl restart firewalld.service<br>显示一个服务的状态：systemctl status firewalld.service<br>在开机时启用一个服务：systemctl enable firewalld.service<br>在开机时禁用一个服务：systemctl disable firewalld.service<br>查看服务是否开机启动：systemctl is-enabled firewalld.service<br>查看已启动的服务列表：systemctl list-unit-files|grep enabled<br>查看启动失败的服务列表：systemctl –failed</p><p>3.配置firewalld-cmd</p><p>查看版本： firewall-cmd –version<br>查看帮助： firewall-cmd –help<br>显示状态： firewall-cmd –state<br>查看所有打开的端口： firewall-cmd –zone=public –list-ports<br>更新防火墙规则： firewall-cmd –reload<br>查看区域信息:  firewall-cmd –get-active-zones<br>查看指定接口所属区域： firewall-cmd –get-zone-of-interface=eth0<br>拒绝所有包：firewall-cmd –panic-on<br>取消拒绝状态： firewall-cmd –panic-off<br>查看是否拒绝： firewall-cmd –query-panic</p><p>那怎么开启一个端口呢<br>添加<br>firewall-cmd –zone=public –add-port=80/tcp –permanent    （–permanent永久生效，没有此参数重启后失效）<br>重新载入<br>firewall-cmd –reload<br>查看<br>firewall-cmd –zone= public –query-port=80/tcp<br>删除<br>firewall-cmd –zone= public –remove-port=80/tcp –permanent</p>]]></content>
      
      
      <categories>
          
          <category> centos7防火墙 firewalld </category>
          
      </categories>
      
      
        <tags>
            
            <tag> centos7 firewalld iptables 防火墙 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RabbitMq 学习笔记</title>
      <link href="/2018/11/05/rabbitmq/"/>
      <url>/2018/11/05/rabbitmq/</url>
      
        <content type="html"><![CDATA[<p>RabbitMQ 是一个开源的消息代理和队列服务器， 用来通过普通协议在完全不同的应用之间共享数据， RabbitMQ是使用Erlang语言来编写的，并且RabbitMQ是基于AMQP协议的。 </p><h2 id="RabbitMQ简介"><a href="#RabbitMQ简介" class="headerlink" title="RabbitMQ简介"></a>RabbitMQ简介</h2><ul><li>目前很多互联网公司都在使用RabbitMQ</li><li>RabbitMQ底层采用Erlang语言进行编写</li><li>开源、性能优秀、稳定性保障</li><li>与SpringAMQP完美的整合、API丰富</li><li>集群模式丰富、表达式配置、HA模式、镜像队列模型 </li><li>保证数据不丢失的前提做到主可靠性、可用性</li></ul><p>注： 镜像对列模型比较通用， 在这个上层需要一下proxy ， 和 HA高可用的架构形式； </p><ul><li>AMQP  （Advanced Message Queuing Protocol) 高级消息队列协议</li></ul><p>Publisher Application </p><p>Consumer Application </p><p>Server -&gt; virtual host -&gt; Exchange -&gt; Message Queue </p><h2 id="RabbitMQ-安装"><a href="#RabbitMQ-安装" class="headerlink" title="RabbitMQ 安装"></a>RabbitMQ 安装</h2><p>1、 准备<br>yum install build-essential openssl openssl-devel unixODBC unixODBC-devel make gcc gcc-c++ kernel-devel m4 ncurses-devel tk tc xz</p><p>2、下载：<br>wget <a href="http://www.rabbitmq.com/releases/erlang/erlang-18.3-1.el7.centos.x86_64.rpm" target="_blank" rel="noopener">www.rabbitmq.com/releases/erlang/erlang-18.3-1.el7.centos.x86_64.rpm</a><br>wget <a href="http://repo.iotti.biz/CentOS/7/x86_64/socat-1.7.3.2-5.el7.lux.x86_64.rpm" target="_blank" rel="noopener">http://repo.iotti.biz/CentOS/7/x86_64/socat-1.7.3.2-5.el7.lux.x86_64.rpm</a></p><p>wget <a href="http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.5/rabbitmq-server-3.6.5-1.noarch.rpm" target="_blank" rel="noopener">www.rabbitmq.com/releases/rabbitmq-server/v3.6.5/rabbitmq-server-3.6.5-1.noarch.rpm</a></p><p>3、配置vim /etc/hosts/ 以及 /etc/hostname  (防火墙需要关闭)</p><p>4、配置文件：<br>vim /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.5/ebin/rabbit.app<br>比如修改密码， 配置等，例如 loopback_users 中的&lt;&lt;”guest”&gt;&gt;, 中保留 guest</p><p>启动： rabbitmq-server start &amp;<br>停止： rabbitmqctl app_stop</p><p>查看插件： rabbitmq-plugins list, 可以查看所有的插件列表<br>启动一个插件：<br>rabbitmq-plugins enable rabbitmq_management<br>启动一个管理控制台的插件</p><p>5、管理插件： rabbitmq-plugins enable rabbitmq-management<br>6、访问地址： <a href="http://192.168.11.76:15672/" target="_blank" rel="noopener">http://192.168.11.76:15672/</a></p><h2 id="AMQP-核心概念"><a href="#AMQP-核心概念" class="headerlink" title="AMQP 核心概念"></a>AMQP 核心概念</h2><ul><li><p>Server： 又称Broker， 接受客户端的连接， 实现AMQP实例服务</p></li><li><p>Connection： 连接， 应用程序与Broker的网络连接</p></li><li><p>Channel: 网络信道， 几乎所有的操作都在Channel中进行， Channel是行行消息读写的通道。 客户端可建立多个Channel每个Channel代表一个会话任务。 </p></li><li><p>Message： 消息， 服务器和应用程序之间传送的数据， 由Properties和Body组成。 Properties可以对消息进行修饰， 比如消息的优先级、延迟等高级特性； Body则就是消息体内容 。 </p></li><li><p>Virtual Host： 虚拟地址， 用于进行逻辑隔离， 最上层的消息路由。 一个Virtual Host里面可以有苦于个Exchange和Queue， 同一个VirtualHost里面不能有相同名称的Exchange或Queue。</p></li><li><p>Exchange： 交换机， 接收消息， 根据路由键转发消息到绑定的队列。</p></li><li><p>Binding ： Exchange 和 Queue之间的虚拟连接， binding中可以包含routing key。</p></li><li><p>Routing key： 一个路由规则， 虚拟机可用它来确定如何路由一个特定的消息。 在RabbitMQ的控制台上进行配置routing key时， 往往会填写模糊匹配，如 order.* 表示可以匹配order.agasd 或 order.123等一级的模糊匹配，<br>order.#表示可以匹配多级。  </p></li><li><p>Queue： 也称为Message Queue， 消息队列， 保存消息并将它们转发给消费者。</p></li></ul><h1 id="Consumer-消息端的配置"><a href="#Consumer-消息端的配置" class="headerlink" title="Consumer 消息端的配置"></a>Consumer 消息端的配置</h1><ul><li>spring.rabbitmq.listener.simple.concurrency = 5 , 配置消费端并发线程数</li><li>spring.rabbiqmq.listener.simple.max-concurrency = 10, 配置消费端并发的最大线程数</li><li>spring.rabbitmq.listener.simple.acknowledge-mode = auto/manual  表示自动接收或手动接收<br>如果配置了手工接收消息， 就需要通过channel进行。</li><li>spring.rabbitmq.listener.simple.prefetch = 1, 可以进行消息消费端限流处理， 每次处理一条消息</li></ul>]]></content>
      
      
      <categories>
          
          <category> RabbitMQ MQ 消息队列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ AMQP 对列 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Spring Cloud GateWay 初识</title>
      <link href="/2018/11/02/springcloudgateway/"/>
      <url>/2018/11/02/springcloudgateway/</url>
      
        <content type="html"><![CDATA[<p>官网： <a href="https://spring.io/guides/gs/gateway/" target="_blank" rel="noopener">https://spring.io/guides/gs/gateway/</a></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Spring Cloud GateWay 是 Spring Cloud官方推出的第二代网关框架， 取代Zuul网关。 网关作为流量的控制， 在微服务系统中有着非常重要的作用， 网关常见的功能有路由转发、权限校验、限流控制等作用。 本文首先用官方的案例带领用户体验Spring Cloud的一些简单的功能， 在后续文章中我会使用详细案例和源码解析来详细讲解Spring Cloud GateWay。</p><h1 id="创建工程"><a href="#创建工程" class="headerlink" title="创建工程"></a>创建工程</h1><p>本案例的源码下载于官方案例， 也可以在我的GitHub上下载， 工程使用的Spring Boot版本为2.0.5 Release， Spring Cloud版本为Finchiley.SR1.</p><p>新建一个工程， 取名为sc-f-gateway-first-sight在工程的Pom文件引用工程所需的依赖， 包括spring boot 和 spring cloud， 以及gateway的起步依赖spring-starter-gateway, 代码如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">&lt;parent&gt;</span><br><span class="line">        </span><br><span class="line">&lt;groupId&gt;</span><br><span class="line">org.springframework.boot</span><br><span class="line">&lt;/groupId&gt;</span><br><span class="line">        </span><br><span class="line">&lt;artifactId&gt;</span><br><span class="line">spring-boot-starter-parent</span><br><span class="line">&lt;/artifactId&gt;</span><br><span class="line">        </span><br><span class="line">&lt;version&gt;</span><br><span class="line"><span class="number">2.0</span>.5.RELEASE</span><br><span class="line">&lt;/version&gt;</span><br><span class="line">    </span><br><span class="line">&lt;/parent&gt;</span><br><span class="line">    </span><br><span class="line">&lt;dependencyManagement&gt;</span><br><span class="line">        </span><br><span class="line">&lt;dependencies&gt;</span><br><span class="line">            </span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">                </span><br><span class="line">&lt;groupId&gt;</span><br><span class="line">org.springframework.cloud</span><br><span class="line">&lt;/groupId&gt;</span><br><span class="line">                </span><br><span class="line">&lt;artifactId&gt;</span><br><span class="line">spring-cloud-dependencies</span><br><span class="line">&lt;/artifactId&gt;</span><br><span class="line">                </span><br><span class="line">&lt;version&gt;</span><br><span class="line">Finchley.SR1</span><br><span class="line">&lt;/version&gt;</span><br><span class="line">                </span><br><span class="line">&lt;type&gt;</span><br><span class="line">pom</span><br><span class="line">&lt;/type&gt;</span><br><span class="line">                </span><br><span class="line">&lt;scope&gt;</span><br><span class="line"><span class="keyword">import</span></span><br><span class="line">&lt;/scope&gt;</span><br><span class="line">            </span><br><span class="line">&lt;/dependency&gt;</span><br><span class="line">        </span><br><span class="line">&lt;/dependencies&gt;</span><br><span class="line">    </span><br><span class="line">&lt;/dependencyManagement&gt;</span><br><span class="line"> </span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">            </span><br><span class="line">&lt;groupId&gt;</span><br><span class="line">org.springframework.cloud</span><br><span class="line">&lt;/groupId&gt;</span><br><span class="line">            </span><br><span class="line">&lt;artifactId&gt;</span><br><span class="line">spring-cloud-starter-gateway</span><br><span class="line">&lt;/artifactId&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure><p><em>注： 详细的POM文件依赖， 可以见源码。</em></p><h1 id="创建一个简单的路由"><a href="#创建一个简单的路由" class="headerlink" title="创建一个简单的路由"></a>创建一个简单的路由</h1><p>在Spring cloud gateway中使用RouteLocator的Bean 进行中由转发， 将请求进行处理， 最后转发到目标的下游服务。 在本案例中， 会将请求转发到<a href="http://httpbin.org:80这个地址上。" target="_blank" rel="noopener">http://httpbin.org:80这个地址上。</a> 代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span></span></span><br><span class="line"><span class="class"> </span></span><br><span class="line"><span class="class"><span class="title">Application</span></span></span><br><span class="line"><span class="class"> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">static</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">void</span></span><br><span class="line"> main</span><br><span class="line">(</span><br><span class="line">String</span><br><span class="line">[]</span><br><span class="line"> args</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">&#123;</span><br><span class="line">        </span><br><span class="line">SpringApplication</span><br><span class="line">.</span><br><span class="line">run</span><br><span class="line">(</span><br><span class="line">Application</span><br><span class="line">.</span><br><span class="line"><span class="class"><span class="keyword">class</span></span></span><br><span class="line"><span class="class">,</span></span><br><span class="line"><span class="class"> <span class="title">args</span></span></span><br><span class="line"><span class="class">)</span>;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="meta">@Bean</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">public</span></span><br><span class="line"> </span><br><span class="line">RouteLocator</span><br><span class="line"> myRoutes</span><br><span class="line">(</span><br><span class="line">RouteLocatorBuilder</span><br><span class="line"> builder</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">&#123;</span><br><span class="line">       </span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"> builder</span><br><span class="line">.</span><br><span class="line">routes</span><br><span class="line">()</span><br><span class="line">        </span><br><span class="line">.</span><br><span class="line">route</span><br><span class="line">(</span><br><span class="line">p </span><br><span class="line">-&gt;</span><br><span class="line"> p</span><br><span class="line">            </span><br><span class="line">.</span><br><span class="line">path</span><br><span class="line">(</span><br><span class="line"><span class="string">"/get"</span></span><br><span class="line">)</span><br><span class="line">            </span><br><span class="line">.</span><br><span class="line">filters</span><br><span class="line">(</span><br><span class="line">f </span><br><span class="line">-&gt;</span><br><span class="line"> f</span><br><span class="line">.</span><br><span class="line">addRequestHeader</span><br><span class="line">(</span><br><span class="line"><span class="string">"Hello"</span></span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line"><span class="string">"World"</span></span><br><span class="line">))</span><br><span class="line">            </span><br><span class="line">.</span><br><span class="line">uri</span><br><span class="line">(</span><br><span class="line"><span class="string">"http://httpbin.org:80"</span></span><br><span class="line">))</span><br><span class="line">        </span><br><span class="line">.</span><br><span class="line">build</span><br><span class="line">();</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的myRoutes方法中， 使用了一个RouteLocatorBuilder的Bean去创建路由， 除了创建路由RouteLocatorBuilder可以让你添加各种predicates和filters, predicates断言的意思， 顾名思义就是根据具体的请求的规则， 由具体的route去处理， filters是各种过滤器， 用来对请求做各种判断和修改。 </p><p>上面创建的route可以让请求“/get”请求都转到”<a href="http://httpbin.org:80/“。" target="_blank" rel="noopener">http://httpbin.org:80/“。</a> 在route配置上， 我们添加了一个filter。 该filter会将请求添加一个header, key 为hell， value 为 world。</p><p>启动springboot项目， 在浏览器上<a href="http://localhost:8080/get，" target="_blank" rel="noopener">http://localhost:8080/get，</a> 在浏览器显示如上：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  </span><br><span class="line">&quot;args&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&#123;&#125;,</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">&quot;headers&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&#123;</span><br><span class="line">    </span><br><span class="line">&quot;Accept&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Accept-Encoding&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;gzip, deflate, br&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Accept-Language&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;zh-CN,zh;q=0.9,en;q=0.8&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Cache-Control&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;max-age=0&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Connection&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;close&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Cookie&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;_ga=GA1.1.412536205.1526967566; JSESSIONID.667921df=node01oc1cdl4mcjdx1mku2ef1l440q1.node0; screenResolution=1920x1200&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Forwarded&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;proto=http;host=\&quot;localhost:8080\&quot;;for=\&quot;0:0:0:0:0:0:0:1:60036\&quot;&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Hello&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;World&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Host&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;httpbin.org&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;Upgrade-Insecure-Requests&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;1&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;User-Agent&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">    </span><br><span class="line">&quot;X-Forwarded-Host&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;localhost:8080&quot;</span><br><span class="line">  </span><br><span class="line">&#125;,</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">&quot;origin&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;0:0:0:0:0:0:0:1, 210.22.21.66&quot;</span><br><span class="line">,</span><br><span class="line"> </span><br><span class="line">  </span><br><span class="line">&quot;url&quot;</span><br><span class="line">:</span><br><span class="line"> </span><br><span class="line">&quot;http://localhost:8080/get&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 微服务网关路由 GateWay </category>
          
      </categories>
      
      
        <tags>
            
            <tag> springcloud GateWay Zuul </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>apache集成轻量级压测试工具 AB</title>
      <link href="/2018/11/01/apache-ab/"/>
      <url>/2018/11/01/apache-ab/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux安装ab压力测试命令"><a href="#Linux安装ab压力测试命令" class="headerlink" title="Linux安装ab压力测试命令"></a>Linux安装ab压力测试命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install httpd-tools</span><br></pre></td></tr></table></figure><p>ab -c100 -n1000 <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a></p><p>-n requests // 在测试会话中执行的请求个数， 默认时， 仅执行一个请求</p><p>-c concurrency // 一次产生的请求个数， 默认为一次一个； </p><p>上面的执行命令，表示为：</p><p>发送100个请求， 每次行发，1000个请求个数； 访问 后台对应的url</p><p>执行结束后的报告说明如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">Server Software:        Apache/2.2.19    ##apache版本 </span><br><span class="line">Server Hostname:        vm1.jianfeng.com   ##请求的机子 </span><br><span class="line">Server Port:            80 ##请求端口</span><br><span class="line"></span><br><span class="line">Document Path:          /a.html </span><br><span class="line">Document Length:        25 bytes  ##页面长度</span><br><span class="line"></span><br><span class="line">Concurrency Level:      100  ##并发数 </span><br><span class="line">Time taken for tests:   0.273 seconds  ##共使用了多少时间 </span><br><span class="line">Complete requests:      1000   ##请求数 </span><br><span class="line">Failed requests:        0   ##失败请求 </span><br><span class="line">Write errors:           0   </span><br><span class="line">Total transferred:      275000 bytes  ##总共传输字节数，包含http的头信息等 </span><br><span class="line">HTML transferred:       25000 bytes  ##html字节数，实际的页面传递字节数 </span><br><span class="line">Requests per second:    3661.60 [#/sec] (mean)  ##每秒多少请求，这个是非常重要的参数数值，服务器的吞吐量 </span><br><span class="line">Time per request:       27.310 [ms] (mean)  ##用户平均请求等待时间 </span><br><span class="line">Time per request:       0.273 [ms] (mean, across all concurrent requests)  ##服务器平均处理时间，也就是服务器吞吐量的倒数 </span><br><span class="line">Transfer rate:          983.34 [Kbytes/sec] received  ##每秒获取的数据长度</span><br><span class="line"></span><br><span class="line">Connection Times (ms) </span><br><span class="line">              min  mean[+/-sd] median   max </span><br><span class="line">Connect:        0    1   2.3      0      16 </span><br><span class="line">Processing:     6   25   3.2     25      32 </span><br><span class="line">Waiting:        5   24   3.2     25      32 </span><br><span class="line">Total:          6   25   4.0     25      48</span><br><span class="line"></span><br><span class="line">Percentage of the requests served within a certain time (ms) </span><br><span class="line">  50%     25  ## 50%的请求在25ms内返回 </span><br><span class="line">  66%     26  ## 60%的请求在26ms内返回 </span><br><span class="line">  75%     26 </span><br><span class="line">  80%     26 </span><br><span class="line">  90%     27 </span><br><span class="line">  95%     31 </span><br><span class="line">  98%     38 </span><br><span class="line">  99%     43 </span><br><span class="line">100%     48 (longest request)</span><br><span class="line">--------------------- </span><br><span class="line">作者：songxiuliang </span><br><span class="line">来源：CSDN </span><br><span class="line">原文：https://blog.csdn.net/songxiuliang/article/details/68060986 </span><br><span class="line">版权声明：本文为博主原创文章，转载请附上博文链接！</span><br></pre></td></tr></table></figure></p><h1 id="网络抓包工具"><a href="#网络抓包工具" class="headerlink" title="网络抓包工具"></a>网络抓包工具</h1><p>WireShark </p>]]></content>
      
      
      <categories>
          
          <category> apache 压力测试工具 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> apache ab 压力测试 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>springjpadata</title>
      <link href="/2018/10/30/springjpadata/"/>
      <url>/2018/10/30/springjpadata/</url>
      
        <content type="html"><![CDATA[<h1 id="介绍Repository接口讲解"><a href="#介绍Repository接口讲解" class="headerlink" title="介绍Repository接口讲解"></a>介绍Repository接口讲解</h1><ul><li>Repository 接口是Spring Data的核心接口， 不提供任何方法</li><li>public interface Repository&lt;T, ID extends Serializable&gt; {}， 这个是Repository接口的定义</li><li>@RepositoryDefinition 注解的使用， 也可以在类上面使用这个注册表示实现了这个Repository接口；</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Repository</span>&lt;<span class="title">T</span>, <span class="title">ID</span> <span class="keyword">extends</span> <span class="title">Serializable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>1、 Repository是一个空接口， 也可以说是一个标记型接口；</p><p>2、 自定义的一个Repositry类时， 可以实现这个接口； 同时也可以采用注解的方式， 其对应注解是如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@RepositoryDefinition</span>(domainClass = Employee.class, idClass = Integer.class)</span><br><span class="line"></span><br><span class="line">domainClass 表示这个数据库操作对应的实例类； 这个实例类对应的主键的类型 ；</span><br></pre></td></tr></table></figure><p> 3、可以通过 alt + commond + b 查看这个接口的所有实现类； </p><p> 可以查询出， Repositry有一个实现接口， CrudRepository.class , 然而 CrudRepositry类也实现了一个接口叫做<br> PagingAndSortingRepository 的接口， 这个接口里面又有二个对象： Sort 和 Pageable ； 一个是用来排序用的， 一个是<br> 用分而的对象； </p><h1 id="Repository-中查询方法定义规则和使用"><a href="#Repository-中查询方法定义规则和使用" class="headerlink" title="Repository 中查询方法定义规则和使用"></a>Repository 中查询方法定义规则和使用</h1><p>1、 需要了解Spring Data中查询方法名和定义的规则； </p><p>2、 使用Spring Data完成复杂查询方法名称的命名； </p><p>如下规则 ：</p><table><thead><tr><th style="text-align:center">Keyword</th><th style="text-align:center">Sample</th><th style="text-align:center">JPQL Snippet</th></tr></thead><tbody><tr><td style="text-align:center">And</td><td style="text-align:center">findByLastnameAndFirstname</td><td style="text-align:center">… where x.lastname = ?1 and x.firstname = ?2</td></tr><tr><td style="text-align:center">Or</td><td style="text-align:center">findByLastnameOrFirstName</td><td style="text-align:center">… where x.lastname = ?1 or x.firstname = ?2</td></tr><tr><td style="text-align:center">Between</td><td style="text-align:center">findByStartDateBetween</td><td style="text-align:center">…where x.startDate between ?1 and ?2</td></tr><tr><td style="text-align:center">LessThan</td><td style="text-align:center">findByAgeLessThan</td><td style="text-align:center">…where x.age &lt; ?1</td></tr><tr><td style="text-align:center">GreaterThan</td><td style="text-align:center">findByAgeGreaterThen</td><td style="text-align:center">… where x.age &gt; ?1</td></tr><tr><td style="text-align:center">After</td><td style="text-align:center">findByStartDateAfter</td><td style="text-align:center">… where x.startDate &gt; ?1</td></tr><tr><td style="text-align:center">Before</td><td style="text-align:center">findByStartDateBefore</td><td style="text-align:center">…where x.startDate &lt; ?1</td></tr><tr><td style="text-align:center">IsNull</td><td style="text-align:center">findByAgeIsNull</td><td style="text-align:center">…where x.age is null</td></tr><tr><td style="text-align:center">IsNotNull, NotNull</td><td style="text-align:center">findByAge(Is)NotNull</td><td style="text-align:center">… where x.age not null</td></tr></tbody></table><h1 id="Query-查询注解的使用"><a href="#Query-查询注解的使用" class="headerlink" title="Query 查询注解的使用"></a>Query 查询注解的使用</h1><ul><li>在 Repostitory方法中使用， 不需要遵循查询方法命名规则</li><li>只需要将@Query定义在Repository中的方法这上即可</li><li>命名参数及索引参数的使用</li><li>本地查询</li></ul><p><em>特别要注意， 在@Query(“”)里面编写查询SQL时， 不是表名， 而是关联的类名</em><br><em>特别要注意， 在@Query(“”)里面编写占位符时， 需要这个写?1, 问号表示参数占位符， 1，表示参数以应的编号，?2 表示第二个参数占位符。</em></p><p>还有种占位符参数的对应写法，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">@Query(&quot;select o from Employee o where o.name = :name1 and o.age = :age1&quot;)</span><br><span class="line">public List&lt;T&gt; queryParam2(@Param(&quot;name1)String name, @Param(&quot;age1&quot;)Integer age)</span><br><span class="line">通过上面这种写法也可以将SQL上的占位符与形参一一对应起来</span><br></pre></td></tr></table></figure></p><h1 id="在Spring-Data-JPA-中如何更新及删除操作整合事务的使用"><a href="#在Spring-Data-JPA-中如何更新及删除操作整合事务的使用" class="headerlink" title="在Spring Data JPA 中如何更新及删除操作整合事务的使用"></a>在Spring Data JPA 中如何更新及删除操作整合事务的使用</h1><ul><li>@Modifying 注解使用</li><li>@Modifying 结合@Query注解执行更新操作</li><li>@Transactional 在Spring Data中的使用</li></ul><p>例子， 如果想要对库中的某个表的记录进行更新操作的话：如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Modifying</span></span><br><span class="line"><span class="meta">@Query</span>(<span class="string">"update Employee o set o.age = :age where o.id = :id"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">update</span><span class="params">(@Param(<span class="string">"id"</span>)</span>Integer id , @<span class="title">Param</span><span class="params">(<span class="string">"age"</span>)</span>Integer age)</span>;</span><br></pre></td></tr></table></figure></p><p>以上这个操作是一个更新操作， 需要要上面添加一个注解， @Modifying</p><p>不仅需要在更新操作的接口方法上添加@Modifying注解， 而且还需要把这个方法的调用放在一个service类里面， 在对应的方法上添加@Transactional ,使其对事物的支持， 如果遇到操作异常可以进行事情回滚； </p><h1 id="CrudRepository-接口使用详解"><a href="#CrudRepository-接口使用详解" class="headerlink" title="CrudRepository 接口使用详解"></a>CrudRepository 接口使用详解</h1><ul><li>save (entity)   save (entities)</li><li>findOne(id)     exists(id)</li><li>findAll()       delete(id)</li><li>delete(entify)  delete(entities)</li><li>deleteAll() </li></ul><p>注：<br>   以下异常信息：<br>   <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">actory.BeanCreationException: Error creating bean with name <span class="string">'employeeCrudRepository'</span>: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Not an managed type: <span class="class"><span class="keyword">class</span> <span class="title">java</span>.<span class="title">lang</span>.<span class="title">Object</span></span></span><br></pre></td></tr></table></figure></p><p>   原因是， 由于自定义的Repository在继承CrudRepository时没有指定对应的泛型类的主键类对象。<br>  如下所示的配置：<br>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 使用Repository时， 需要创建一个接口， ；来继承CrudRepository接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">EmployeeCrudRepository</span>  <span class="keyword">extends</span> <span class="title">CrudRepository</span>&lt;<span class="title">Employee</span>, <span class="title">Integer</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">上面的接口定义需要指定， CrudRepository&lt;Employee, Integer&gt; 的泛型，否则会报上面的异常；</span><br></pre></td></tr></table></figure></p><p>以下异常信息：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ework.orm.jpa.JpaSystemException: No <span class="keyword">default</span> constructor <span class="keyword">for</span> entity:  : com.imooc.domain.Employee; nested exception is org.hibernate.InstantiationException: No <span class="keyword">default</span> constructor <span class="keyword">for</span> entity:  : com.imooc.domain.Employee</span><br></pre></td></tr></table></figure></p><p>是因为对应的实例类中没有提供默认的构造函数； </p><p>是因为相关操作没有指定事物， 需要在相当的操作方法上添加， @Transactional  即可。 </p><h1 id="CAP-（附）"><a href="#CAP-（附）" class="headerlink" title="CAP （附）"></a>CAP （附）</h1><ul><li>Consistency   一致性</li><li>Availability  活越性， 可用性</li><li>Partition tolerance 分区容错性</li></ul><p>一致性和可用性， 为什么不能周时成立？ 可用性高于性； </p><h1 id="PagingAndSortingRepository-接口使用详解"><a href="#PagingAndSortingRepository-接口使用详解" class="headerlink" title="PagingAndSortingRepository 接口使用详解"></a>PagingAndSortingRepository 接口使用详解</h1><ul><li>该接口包含分布和排序的功能； </li><li>带排序的查询： findAll(Sort sort);</li><li>带排序的分布查询： findAll(Pageable pageable)</li></ul><p>// 以下是Spring Data Jpa 中几个Repository的继承关系；<br>JpaRepository &gt; PagingAndSortingRepository &gt; CrudRepository &gt; Repository </p><h1 id="JpaRepository接口使用详解"><a href="#JpaRepository接口使用详解" class="headerlink" title="JpaRepository接口使用详解"></a>JpaRepository接口使用详解</h1><ul><li>findAll</li><li>findAll(Sort sort)</li><li>save(entities)</li><li>flush</li><li>deleteInBatch(entities)</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> spring jpa data Repository ORM </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>springcloud03</title>
      <link href="/2018/10/28/springcloud03/"/>
      <url>/2018/10/28/springcloud03/</url>
      
        <content type="html"><![CDATA[<p>当服务的实例很多的时候， 都从配置中心读取文件， 这时可以考虑将配置中心做成一个微服务， 将其集群化， 从而达到高可用， 架构图如下：</p><ul><li>注： 在通过git进行配置时， 发现修改配置后， 不会马上生效， 需要重启config-client工程。 </li></ul><p>Spring Cloud Bus将分布式的节点用轻量的消息代理连接起来。 它可以用于广播配置文件的不更改或者服务之间的通讯，也可以用于监控.本文要讲述的是用Spring Cloud Bus实现通知微服务架构的配置文件的更改。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1>]]></content>
      
      
      
        <tags>
            
            <tag> springcloud config Zuul parallel(并发) concorrent(并行) Spring Cloud Bus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>springcloud02</title>
      <link href="/2018/10/26/springcloud02/"/>
      <url>/2018/10/26/springcloud02/</url>
      
        <content type="html"><![CDATA[<p>在上一篇文章中讲zuul时， 提过使用配置服务来保存各个服务的配置文件。 它就是Spring Cloud Config </p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在分布式系统中， 由于服务数量巨多， 为了方便配置文件统一管理， 实时更新， 所以需要分布式的配置中心组件。 在Spring Cloud中， 有分布式配置中心组件spring cloud config , 它支持配置服务放在配置服务的内存中（即本地）， 也支持放在远程Git仓库中。 在Spring cloud config组件中， 分两个解色， 一个是config server， 二是config client。 </p><p>~</p><h1 id="构建-Config-Server"><a href="#构建-Config-Server" class="headerlink" title="构建 Config Server"></a>构建 Config Server</h1><p>原码在我的gitHub中可以查看。 </p><p>注：</p><ul><li><p>在config server入口文件中添加一个注解<br><code>@EnableConfigServer</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  <span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@EnableConfigServer</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigServerApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">SpringApplication.run(ConfigServerApplication.class, args);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>需要在程序的配置文件application.properties文件配置以下：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">   spring.application.name=config-server</span><br><span class="line">server.port=8888</span><br><span class="line"></span><br><span class="line">spring.cloud.config.server.git.uri=https://github.com/forezp/SpringcloudConfig/</span><br><span class="line">spring.cloud.config.server.git.searchPaths=respo</span><br><span class="line">spring.cloud.config.label=master</span><br><span class="line">spring.cloud.config.server.git.username=</span><br><span class="line">spring.cloud.config.server.git.password=</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>spring.cloud.config.server.git.uri: 配置git仓库地址<br>spring.cloud.config.server.git.searchPaths: 配置仓库路径<br>spring.cloud.config.label:配置仓库的分支名称<br>spring.cloud.config.server.git.username: 配置访问git仓库的用户名<br>spring.cloud.config.server.git.password: 配置访问git仓库的用户密码</p><p>注： 如果仓库Git为公开仓库， 可以不填写用户名和密码， 如果是私有的仓库需要填写， 本例子是公开仓库，放心使用。 </p><h1 id="构建一个config-client"><a href="#构建一个config-client" class="headerlink" title="构建一个config client"></a>构建一个config client</h1><p>重新创建一个spring boot项目， 取名为config-client， 其pom.xml文件配置如下：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.forezp<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>config-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>config-client<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Demo project for Spring Boot<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">parent</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.forezp<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>sc-f-chapter6<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>0.0.1-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">parent</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.cloud<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-cloud-starter-config<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">其配置文件 bootstrap.properties</span><br><span class="line">(为什么时bootstrap.properties呢， 换另的名字是否可以，试一试，经过测试，没有问题， 配置文件可以是application.properties)</span><br><span class="line"></span><br><span class="line">其配置如下：</span><br><span class="line">```properties</span><br><span class="line">spring.application.name=config-client</span><br><span class="line">spring.cloud.config.label=master</span><br><span class="line">spring.cloud.config.profile=dev</span><br><span class="line">spring.cloud.config.uri= http://localhost:8888/</span><br><span class="line">server.port=8881</span><br></pre></td></tr></table></figure></p><ul><li>spring.cloud.config.label 指明远程仓库的分支</li><li>spring.cloud.config.prpfile<ul><li>dev 开发环境配置文件</li><li>test 测试环境配置文件</li><li>pro 生产环境配置文件</li></ul></li><li>spring.cloud.config.uri=<a href="http://localhost:8888/指明配置服务中心的服务地址" target="_blank" rel="noopener">http://localhost:8888/指明配置服务中心的服务地址</a></li></ul><p>程序的入口类， 写一个API接口“/hi” ，返回从配置中心读取的foo变量的值， 代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigClientApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">SpringApplication.run(ConfigClientApplication.class, args);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Value</span>(<span class="string">"$&#123;foo&#125;"</span>)</span><br><span class="line">String foo;</span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/hi"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">hi</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> foo;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>访问：<a href="http://localhost:8881/hi，" target="_blank" rel="noopener">http://localhost:8881/hi，</a> 网页显示：</p><p>在git配置文件里的的值。</p><p>这就说明， config-client从config-server获取到了foo的属性， 而config-server是从git仓库读取的：</p><p>git -&gt;  config-server -&gt;  configclient</p>]]></content>
      
      
      
        <tags>
            
            <tag> springcloud config Zuul </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SpringCloud关于Zuul模块学习</title>
      <link href="/2018/10/25/springcloud01/"/>
      <url>/2018/10/25/springcloud01/</url>
      
        <content type="html"><![CDATA[<p>在微服务架构中， 需要几个基础的服务治理组件， 包括服务注册与发现、服务消费、负载均衡、断路器、智能路由、配置管理等，由这几个基础组件相互协作， 共同组建一个简单的微服务系统。</p><p>在Spring Cloud微服务系统中， 一种常见的负载均衡方式是， 客户端的请求首先经过负载均衡（zuul、Nginx）再达到服务网关（zuul集群）， 然后再到具体的服务器， 服务统一注册到高可用的服务注册中心集群， 服务的甩有配置文件由配置服务管理，配置服务的配置文件放在git仓库， 方便开发人员随时配置。</p><h1 id="Zuul-简介"><a href="#Zuul-简介" class="headerlink" title="Zuul 简介"></a>Zuul 简介</h1><p>Zuul 的主要功能是路由转发和过滤器。 路由功能是微服务的一部分， 比如/api/user转发到user服务， /api/shop转发到shop服务。 zuul默认和Ribbon结合实现了负载均衡的功能。 </p><p>zuul有以下功能：</p><ul><li>Authentication</li><li>Insights</li><li>Stress Testing</li><li>Canary Testing</li><li>Dynamic Migration</li><li>Load Shedding</li><li>Security</li><li>Static Response Handing</li><li>Active/Active traffic management</li></ul><h1 id="开发编码"><a href="#开发编码" class="headerlink" title="开发编码"></a>开发编码</h1><p>。。。。</p><h1 id="服务过滤"><a href="#服务过滤" class="headerlink" title="服务过滤"></a>服务过滤</h1><p>zuul不仅只是路由， 并且还能过滤， 做一些安全验证。 继续改造工程：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyFilter</span> <span class="keyword">extends</span> <span class="title">ZuulFilter</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger log = LoggerFactory.getLogger(MyFilter.class);</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">filterType</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"pre"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">filterOrder</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">shouldFilter</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        RequestContext ctx = RequestContext.getCurrentContext();</span><br><span class="line">        HttpServletRequest request = ctx.getRequest();</span><br><span class="line">        log.info(String.format(<span class="string">"%s &gt;&gt;&gt; %s"</span>, request.getMethod(), request.getRequestURL().toString()));</span><br><span class="line">        Object accessToken = request.getParameter(<span class="string">"token"</span>);</span><br><span class="line">        <span class="keyword">if</span>(accessToken == <span class="keyword">null</span>) &#123;</span><br><span class="line">            log.warn(<span class="string">"token is empty"</span>);</span><br><span class="line">            ctx.setSendZuulResponse(<span class="keyword">false</span>);</span><br><span class="line">            ctx.setResponseStatusCode(<span class="number">401</span>);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                ctx.getResponse().getWriter().write(<span class="string">"token is empty"</span>);</span><br><span class="line">            &#125;<span class="keyword">catch</span> (Exception e)&#123;&#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        log.info(<span class="string">"ok"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><ul><li><p>filterType： 返回一个字符串代表过虑器的类型， 在zuul中定义了四种不同生命周期的过滤器类型， 具体如下：<br>1、 per： 路由之前<br>2、 routing: 路由之时<br>3、 post : 路由之后<br>4、 error: 发送错误调用</p></li><li><p>filterOrder : 过滤的顺序</p></li><li>shouldFilter: 这里可以写逻辑判断， 是否要过滤， 本文true, 永远需要过滤。</li><li>run： 过滤的具体逻辑。 可以很复杂， 包括查询sql, nosql去判断应该请求到底有没有相关的权限。</li></ul><h1 id="编码。"><a href="#编码。" class="headerlink" title="编码。"></a>编码。</h1><p>详情查看gitee上的spring cloud工程源码</p>]]></content>
      
      
      
        <tags>
            
            <tag> springcloud zuul 分布式模块 分布式 </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GUNS工程学习笔记</title>
      <link href="/2018/10/25/guns/"/>
      <url>/2018/10/25/guns/</url>
      
        <content type="html"><![CDATA[<h2 id="Sping-Boot的注解"><a href="#Sping-Boot的注解" class="headerlink" title="Sping Boot的注解"></a>Sping Boot的注解</h2><p>@ConditionalOnBean 配置了某个特定bean<br>@ConditionalOnMissingBean 没有配置特定bean<br>@ConditionalOnClass classpath中有指定的类<br>@ConditionalOnMissingClass classpath中没有指定的类<br>@ConditionalOnProperty 给定配置属性中包含某个值<br>@ConditionalOnResource classpath有指定资源<br>@ConditionalOnWebApplication 是一个web应用程序<br>@ConditionalOnNotWebApplication 不是一个web应用程序</p><h2 id="覆蓋自動配置"><a href="#覆蓋自動配置" class="headerlink" title="覆蓋自動配置"></a>覆蓋自動配置</h2><p>﹣ 以覆蓋DataSourceTransactionManager為例，介紹如何覆蓋默認配置</p><ul><li>没有自动配置如何创建自己需要的配置</li></ul><p>1、 扩大项目源：  北京， 上海， 天津，  重庆</p><pre><code>项目内容 （专业）：  不规范、 体验不好  体现出专业  头像是否需要换成正装  最好的拿到一手，前期项目； 价值更大； 一在都是免费的。 背靠中诚天下。   慢耕细做，稳扎稳打。  咱们现在的资源和优势是什么？</code></pre><p>2、投资者 ：    </p><p>3、 添加资讯，丰富内容 ；   新闻资讯（源），</p><p>4、 推广， 吸引更多的人来平台发布项目； 免费发布项目，对接投资者。</p><pre><code>引入中介机构， 办线下活动； 建立品牌认识； 尽职调查。</code></pre><h2 id="Swagger2的配置说明"><a href="#Swagger2的配置说明" class="headerlink" title="Swagger2的配置说明"></a>Swagger2的配置说明</h2><ul><li>@ApiOperation: 用在方法上，说明方法的作用</li><li>@ApiImplicitParams: 用在方法上包含一组参数说明</li><li>@ApiImplicitParam: 用在@ApiImplicitParams注解中， 指定一个请求参数在各个方面：</li><li>paramType: 参数放在哪个地方</li><li><ul><li>header 请求参数的获取： @RequestHeader</li></ul></li><li><ul><li>query 请求a参数的获取： @RequestParam</li></ul></li><li><ul><li>path 用于restfull接口  请求参数获取： @PathVariable</li></ul></li><li><ul><li>body @RequestBody</li></ul></li><li><ul><li>form 表单提交</li></ul></li><li>name : 参数名</li><li>dataType: 参数类型</li><li>required 参数是否必须传</li><li>value   参数的意思（中文描述）</li><li>defaultValue： 参数的默认值</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> guns study spring spring mvc shro </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>配置云服务器免密码登录（简单流程）</title>
      <link href="/2018/10/25/ssh-keygen-md/"/>
      <url>/2018/10/25/ssh-keygen-md/</url>
      
        <content type="html"><![CDATA[<p><code>在本机（这里以mac命令为例， 如果是其它的操作机请自行完成命令转换）</code></p><h4 id="在本机生成本地的私钥和公钥，命令如下："><a href="#在本机生成本地的私钥和公钥，命令如下：" class="headerlink" title="在本机生成本地的私钥和公钥，命令如下："></a>在本机生成本地的私钥和公钥，命令如下：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;xxx@xx.com&quot;</span><br></pre></td></tr></table></figure><p>命令执行完成后， 会有如下几步的交互：</p><ul><li>询问生成的私钥和公钥存放的位置，默认为~/.ssh/目录下名为：id_rsa 和 id_rsa.pub</li><li>询问是否设置密码： 输入密码，再确认输入密码</li><li>确认后， 完成；</li></ul><p>在~/.ssh/目录下就会生成二个文件，./id_rsa和id_rsa.pub ； </p><p>接下来，启动一个ssh的代理进程，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">eval &quot;(ssh-agent -s)&quot; //将ssh添加到代理当时，</span><br><span class="line">ssh-add ~/.ssh/id_rsa //将刚生成的私钥添加到ssh命令中</span><br></pre></td></tr></table></figure></p><p>再往后， 上到需要远程连接的服务器，cd 到根目录，确保在~/.ssh/上没有类假的id_rsa和id_rsa.pub文件， 如果有的话，一定要先备份（备份时id_rsa.pub文件最好不改变后缀名），命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 4096 -C &quot;aaa@bbb.com&quot;</span><br><span class="line">第一步确认生成文件保存的位置， 一般情况下默认位置即可。</span><br><span class="line">第二步确认输入密码</span><br><span class="line">完成后，生成文件</span><br></pre></td></tr></table></figure></p><p>再往后， 需要在~/.ssh目录下生成一个较验授权文件。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~/.ssh/authorized_keys</span><br><span class="line">vi authorized_keys</span><br></pre></td></tr></table></figure></p><p>完成以上的配置之后， 接下来就是对authorized_keys文件进行授权处理，命令如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 600 authorized_keys</span><br></pre></td></tr></table></figure></p><p>重启 ssh 命令<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service ssh restart</span><br></pre></td></tr></table></figure></p><p>完成， 有问题请随时批评指正！！</p><p>蚂蚁学技！！！ </p>]]></content>
      
      
      
        <tags>
            
            <tag> linux ssh-keygen git 免密 login </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hadoop</title>
      <link href="/2018/10/15/hadoop/"/>
      <url>/2018/10/15/hadoop/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop是什么？"><a href="#Hadoop是什么？" class="headerlink" title="Hadoop是什么？"></a>Hadoop是什么？</h1><ul><li>Hadoop是一个开源的大数据框架</li><li>Hadoop是一个分布式计算的解决方案</li><li>Hadoop = HDFS（分布式文件系统） + MapReduce（分布式计算）</li></ul><h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><ul><li>数据块</li><li>NameNode</li><li>DataNode</li></ul><h2 id="数据块"><a href="#数据块" class="headerlink" title="数据块"></a>数据块</h2><p>是抽象块而非整个文件作来存储单元<br>默认大小为64M， 一般设置为128M， 备份 *3 </p><h2 id="NameNode"><a href="#NameNode" class="headerlink" title="NameNode"></a>NameNode</h2><p>管理文件系统的命名空间， 存放文件元数据<br>维护着文件系统的所有文件和目录， 文件与数据块的映射<br>记录每个文件中各个块所在数据节点的信息</p><h2 id="DataNode"><a href="#DataNode" class="headerlink" title="DataNode"></a>DataNode</h2><p>存储并检索数据块<br>向NameNode更新所存储块的列表</p><h1 id="HDFS优点"><a href="#HDFS优点" class="headerlink" title="HDFS优点"></a>HDFS优点</h1><p>适合大文件存储， 支持TB、PB级的数据存储， 并有副本策略</p><p>可以构建在廉价的机器上， 并有一定的容错和恢复机制</p><p>支持流式数据访问， 一次写入， 多次读取最高效</p><h1 id="HDFS缺点"><a href="#HDFS缺点" class="headerlink" title="HDFS缺点"></a>HDFS缺点</h1><p>不适合大量小文件存储</p><p>不适合并发写入， 不支持文件随机修改</p><p>不支持随机读等低延时的访问方式</p><h2 id="问题-数据块一般设计多大合适。-一般为-128M"><a href="#问题-数据块一般设计多大合适。-一般为-128M" class="headerlink" title="问题 数据块一般设计多大合适。 一般为 128M"></a>问题 数据块一般设计多大合适。 一般为 128M</h2><h1 id="HDFS写流程"><a href="#HDFS写流程" class="headerlink" title="HDFS写流程"></a>HDFS写流程</h1><p>客户端向NameNode发起写数据请求</p><p>分块写入DataNode节点， DataNode自动完成副本备份</p><p>DataNode向NameNode汇报存储完成， NameNode通知客户端</p><h1 id="HDFS读流程"><a href="#HDFS读流程" class="headerlink" title="HDFS读流程"></a>HDFS读流程</h1><p>客户端向NameNode发起读数据请求</p><p>NameNode找出距离最近的DataNode节点信息</p><p>客户端从DataNode分块下载文件</p><h1 id="常用的HDFS-Shell命令"><a href="#常用的HDFS-Shell命令" class="headerlink" title="常用的HDFS Shell命令"></a>常用的HDFS Shell命令</h1><p>类Linux系统： ls, cat, mkdir,  rm, chmod, chown 等<br>HDFS文件交互： copyFromLocal, copyToLocal, get, put</p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>TypeScript</title>
      <link href="/2018/10/10/TypeScript/"/>
      <url>/2018/10/10/TypeScript/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
        <tags>
            
            <tag> ES TS JS </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>jdk11</title>
      <link href="/2018/09/29/jdk11/"/>
      <url>/2018/09/29/jdk11/</url>
      
        <content type="html"><![CDATA[<h2 id="JEP327-Unicode-10"><a href="#JEP327-Unicode-10" class="headerlink" title="JEP327  Unicode 10"></a>JEP327  Unicode 10</h2><p>Upgrade existing platform APIs to support version 10.0 of the Unicode Standard (<a href="http://openjdk.java.net/jeps/327" target="_blank" rel="noopener">JEP 327</a> )</p><p><strong>Description</strong><br>Java SE 10 implements Unicode 8.0, unicode 9.0 adds 7,500 characters and six new scriptes, and Unicode 10.0.0 ands 8c518 characters and fore new scripte, This upgrade will include the Unicode 9.0 chages , and thus will and a total of 16,018 characters and ten new scripts. </p><h2 id="JEP-321-HTTP-Client-Standard"><a href="#JEP-321-HTTP-Client-Standard" class="headerlink" title="JEP 321 HTTP Client (Standard)"></a>JEP 321 HTTP Client (Standard)</h2><p>The HTTP Client has been standarized in Java 11. As part of this work the previosly incubating API, located in the java.incubator.http package, has bean removed At a very minimun Code that uses types from the java. incubator.http package will need to be updated to import the HTTP types from the standard package name, java.net.http.</p><h2 id="New-Collection-toArray-IntFunction-Default-Method"><a href="#New-Collection-toArray-IntFunction-Default-Method" class="headerlink" title="New Collection.toArray(IntFunction) Default Method"></a>New Collection.toArray(IntFunction) Default Method</h2><p>A new default method toArray(IntFunction) has been added to the java.util.Collection interface. This method allows the collection’s elements to be transferred to a newly created array of a desired runtime type. The new method is an overload of the existing toArray(T[]) method that takes an array instance as an argument. The addition of the overloaded method creates a minor source incompatibility. Previously, code of the form coll.toArray(null) would always resolve to the existing toArray method. With the new overloaded method, this code is now ambiguous and will result in a compile-time error. (This is only a source incompatibility. Existing binaries are unaffected.) The ambiguous code should be changed to cast null to the desired array type, for example, toArray((Object[])null) or some other array type. Note that passing null to either toArray method is specified to throw NullPointerException.</p><h2 id="Updated-Locale-Data-to-Unicode-CLDR-v33"><a href="#Updated-Locale-Data-to-Unicode-CLDR-v33" class="headerlink" title="Updated Locale Data to Unicode CLDR v33"></a>Updated Locale Data to Unicode CLDR v33</h2><p>The locale data based on the Unicode Consortium’s CLDR (Common Locale Data Registry) has been updated for JDK 11. Localized digits that are in supplementary planes (such as, those in Indian Chakma script) are substituted with ASCII digits until JDK-8204092 is resolved. Medium and short time patterns for Burmese locale have not been upgraded. When JDK-8209175 is resolved, these patterns will be upgraded.</p><h2 id="Lazy-Allocation-of-Compiler-Threads"><a href="#Lazy-Allocation-of-Compiler-Threads" class="headerlink" title="Lazy Allocation of Compiler Threads"></a>Lazy Allocation of Compiler Threads</h2><p>A new command line flag -XX:+UseDynamicNumberOfCompilerThreads has been added to dynamically control compiler threads. In tiered compilation mode, which is on by default, the VM starts a large number of compiler threads on systems with many CPUs regardless of the available memory and the number of compilation requests. Because the threads consume memory even when they are idle (which is almost all of the time), this leads to an inefficient use of resources.</p><p>To address this issue, the implementation has been changed to start only one compiler thread of each type during startup and to handle the start and shutdown of further threads dynamically. It is controlled by a new command line flag, which is on by default:</p><p>-XX:+UseDynamicNumberOfCompilerThreads</p><p><em>hotspot/gc</em></p><h2 id="JEP-333-ZGC-A-Scalable-Low-Latency-Garbage-Collector-Experimental"><a href="#JEP-333-ZGC-A-Scalable-Low-Latency-Garbage-Collector-Experimental" class="headerlink" title="JEP 333 ZGC A Scalable Low-Latency Garbage Collector (Experimental)"></a>JEP 333 ZGC A Scalable Low-Latency Garbage Collector (Experimental)</h2><p>The Z Garbage Collector, also known as ZGC, is a scalable low latency garbage collector (JEP 333). It is designed to meet the following goals:</p><p>Pause times do not exceed 10 ms<br>Pause times do not increase with the heap or live-set size<br>Handle heaps ranging from a few hundred megabytes to multi terabytes in size<br>At its core, ZGC is a concurrent garbage collector, meaning that all heavy lifting work (marking, compaction, reference processing, string table cleaning, etc) is done while Java threads continue to execute. This greatly limits the negative impact that garbage collection has on application response times.</p><p>ZGC is included as an experimental feature. To enable it, the -XX:+UnlockExperimentalVMOptions option will therefore need to be used in combination with the -XX:+UseZGC option.</p><p>This experimental version of ZGC has the following limitations:</p><p>It is only available on Linux/x64.</p><p>Using compressed oops and/or compressed class points is not supported. The -XX:+UseCompressedOops and -XX:+UseCompressedClassPointers options are disabled by default. Enabling them will have no effect.</p><p>Class unloading is not supported. The -XX:+ClassUnloading and -XX:+ClassUnloadingWithConcurrentMark options are disabled by default. Enabling them will have no effect.</p><p>Using ZGC in combination with Graal is not supported.</p><h2 id="JEP-318-Epsilon-A-No-Op-Garbage-Collector"><a href="#JEP-318-Epsilon-A-No-Op-Garbage-Collector" class="headerlink" title="JEP 318 Epsilon, A No-Op Garbage Collector"></a>JEP 318 Epsilon, A No-Op Garbage Collector</h2><p>Epsilon GC is the new experimental no-op garbage collector. Epsilon GC only handles memory allocation, and does not implement any memory reclamation mechanism. It is useful for performance testing, to contrast costs/benefits of other GCs. It can be used to conveniently assert memory footprint and memory pressure in tests. In extreme cases, it might be useful with very short lived jobs, where memory reclamation would happen at JVM termination, or getting the last-drop latency improvements in low-garbage applications. See more discussion about its use and tradeoffs in JEP 318.</p><p><em>hotspot/jvmti</em></p><h2 id="JEP-331-Low-Overhead-heap-Profiling"><a href="#JEP-331-Low-Overhead-heap-Profiling" class="headerlink" title="JEP 331 Low-Overhead heap Profiling"></a>JEP 331 Low-Overhead heap Profiling</h2><p>Provide a low-overhead way of sampling Java heap allocations, accessible via JVMTI (JEP 331).</p><p>It is designed to meet the following goals:</p><p>Low-overhead enough to be continuously enabled by default<br>Accessible via a well-defined, programmatic interface (JVMTI)<br>Can sample all allocations (that is, not limited to allocations that are in one particular heap region or that were allocated in one particular way)<br>Can be defined in an implementation-independent way (that is, without relying on any particular GC algorithm or VM implementation)<br>Can give information about both live and dead Java objects</p><p><em>hotspot/runtime</em></p><h2 id="JEP-181-Nest-Based-Access-Control"><a href="#JEP-181-Nest-Based-Access-Control" class="headerlink" title="JEP 181 Nest-Based Access Control"></a>JEP 181 Nest-Based Access Control</h2>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>编写高质量的java代码</title>
      <link href="/2018/09/27/%E7%BC%96%E5%86%99%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84java%E4%BB%A3%E7%A0%81/"/>
      <url>/2018/09/27/%E7%BC%96%E5%86%99%E9%AB%98%E8%B4%A8%E9%87%8F%E7%9A%84java%E4%BB%A3%E7%A0%81/</url>
      
        <content type="html"><![CDATA[<h1 id="Java开发中通用的方法和准则"><a href="#Java开发中通用的方法和准则" class="headerlink" title="Java开发中通用的方法和准则"></a>Java开发中通用的方法和准则</h1><h2 id="不要在常量和变量中出现易混淆的字母"><a href="#不要在常量和变量中出现易混淆的字母" class="headerlink" title="不要在常量和变量中出现易混淆的字母"></a>不要在常量和变量中出现易混淆的字母</h2><p>包名全小写， 类名首字母全大写， 常量全部大写并用下划线分隔， 变量采用驼峰命名法（Camel Case）命名等， 这些都是最基本的Java编码规范， 是每一个Java都应熟知的规则， 但是在变量的声明中要注意不要引入容易混淆的字母。</p><h2 id="莫让常量蜕变成变量"><a href="#莫让常量蜕变成变量" class="headerlink" title="莫让常量蜕变成变量"></a>莫让常量蜕变成变量</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    System.out.println(<span class="string">"常量会变量：“  + Const。RAND_CONST);</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  /\*\*接口常量\*\*/</span></span><br><span class="line"><span class="string">  interface Const &#123;</span></span><br><span class="line"><span class="string">    public static final int RAND_CONST = new Random().nextInt();</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p>以上定义一个常量变量时，可能会成一个伪常量。</p><h2 id="三元操作类型务必一致"><a href="#三元操作类型务必一致" class="headerlink" title="三元操作类型务必一致"></a>三元操作类型务必一致</h2><p>在三元操作符时， 前后二个类型是有一个转换规划：</p><ul><li>若两个操作数不可转换则不转换， 返回值为Object类型；</li><li>。。。</li></ul><h2 id="避免带有变长参数的方法重载"><a href="#避免带有变长参数的方法重载" class="headerlink" title="避免带有变长参数的方法重载"></a>避免带有变长参数的方法重载</h2><h2 id="别让NULL值和空值威胁到变长方法"><a href="#别让NULL值和空值威胁到变长方法" class="headerlink" title="别让NULL值和空值威胁到变长方法"></a>别让NULL值和空值威胁到变长方法</h2><h2 id="覆写变长方法也循规蹈矩"><a href="#覆写变长方法也循规蹈矩" class="headerlink" title="覆写变长方法也循规蹈矩"></a>覆写变长方法也循规蹈矩</h2><h2 id="警惕自增的陷阱"><a href="#警惕自增的陷阱" class="headerlink" title="警惕自增的陷阱"></a>警惕自增的陷阱</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">count = count++ ;</span><br></pre></td></tr></table></figure><p>这句代码有陷阱， 在php,java里这个陷阱是一样的，但是在C++里面没问题。</p><h2 id="不要让旧语法困扰你"><a href="#不要让旧语法困扰你" class="headerlink" title="不要让旧语法困扰你"></a>不要让旧语法困扰你</h2><h2 id="少用静态导入"><a href="#少用静态导入" class="headerlink" title="少用静态导入"></a>少用静态导入</h2><p>如下代码段：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.Math.PI;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MathUtils</span></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">calCircleArea</span><span class="params">(<span class="keyword">double</span> r)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> PI * r * r;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">calBallArea</span><span class="params">(<span class="keyword">double</span> r )</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span>  <span class="number">4</span> * PI * r * r;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 以下导入更加不要做</span></span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.Double.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.Math.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.lang.Intger.*;</span><br><span class="line"><span class="keyword">import</span> <span class="keyword">static</span> java.text.MuberFormat.*;</span><br></pre></td></tr></table></figure></p><h2 id="不要在本类中覆盖静态导入的变量和方法"><a href="#不要在本类中覆盖静态导入的变量和方法" class="headerlink" title="不要在本类中覆盖静态导入的变量和方法"></a>不要在本类中覆盖静态导入的变量和方法</h2><p>如果要变更一个被静态导入的方法， 最好的办法是在原始类中重构， 而不是在本类中覆盖。<br>如：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String PI = <span class="string">"我是Hello World!"</span>;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">abs</span><span class="params">(<span class="keyword">int</span> args)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">       System.out.println(<span class="string">"PI = "</span> + PI);</span><br><span class="line"></span><br><span class="line">       System.out.println(<span class="string">"abs = "</span> + abs(-<span class="number">100</span>));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p><p>虚拟机在编辑时，找变量和方法时， 有一个” 最短路径原则“ 。 合情合理。</p><h2 id="养成良好习惯，-显式声明UID"><a href="#养成良好习惯，-显式声明UID" class="headerlink" title="养成良好习惯， 显式声明UID"></a>养成良好习惯， 显式声明UID</h2>]]></content>
      
      
      
        <tags>
            
            <tag> java 规范 hexo </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Egg (来自阿里的优秀框架)</title>
      <link href="/2018/09/25/Egg/"/>
      <url>/2018/09/25/Egg/</url>
      
        <content type="html"><![CDATA[<h1 id="Egg-js是什么？"><a href="#Egg-js是什么？" class="headerlink" title="Egg.js是什么？"></a>Egg.js是什么？</h1><p><em>Egg.js为企业级框架和应用而生</em>， 我们希望由Egg.js孕育出更多的上层框架，帮助开发团队和开发人员降低开发和维护成本。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注： Egg.js缩写为Egg</span><br></pre></td></tr></table></figure></p><h2 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h2><hr><p>我们深知企业级应用在追求规范和共建的同时，还需要考虑如何平衡不同团队之间的差异，求同存异。所以我们没有选择社区常见框架的大集市模式（集成如数据库、模板引擎、前端框架等功能），而是专注于提供 Web 开发的核心功能和一套灵活可扩展的插件机制。我们不会做出技术选型，因为固定的技术选型会使框架的扩展性变差，无法满足各种定制需求。通过 Egg，团队的架构师和技术负责人可以非常容易地基于自身的技术架构在 Egg 基础上扩展出适合自身业务场景的框架。</p><p>Egg 的插件机制有很高的可扩展性，一个插件只做一件事（比如 Nunjucks 模板封装成了 egg-view-nunjucks、MySQL 数据库封装成了 egg-mysql）。Egg 通过框架聚合这些插件，并根据自己的业务场景定制配置，这样应用的开发成本就变得很低。</p><p>Egg 奉行『约定优于配置』，按照一套统一的约定进行应用开发，团队内部采用这种方式可以减少开发人员的学习成本，开发人员不再是『钉子』，可以流动起来。没有约定的团队，沟通成本是非常高的，比如有人会按目录分栈而其他人按目录分功能，开发者认知不一致很容易犯错。但约定不等于扩展性差，相反 Egg 有很高的扩展性，可以按照团队的约定定制框架。使用 Loader 可以让框架根据不同环境定义默认配置，还可以覆盖 Egg 的默认约定。</p><h2 id="async-function"><a href="#async-function" class="headerlink" title="async function"></a>async function</h2><p> async function 是语言层面提供的语法糖， 在async function中， 我们可以通过await 关键字来等待一个Promise被resolve（或者reject, 此时会抛出异常）， Node.js现在的LTS版本已原生支持。</p> <figure class="highlight ts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> fn = <span class="keyword">async</span> <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">const</span> user = <span class="keyword">await</span> getUsers();</span><br><span class="line">    <span class="keyword">const</span> posts = <span class="keyword">await</span> fetchPosts(user.id);</span><br><span class="line">    <span class="keyword">return</span> &#123;user, posts&#125;;</span><br><span class="line">&#125;</span><br><span class="line">fn.then(<span class="function"><span class="params">res</span>=&gt;</span><span class="built_in">console</span>.log(res)).catch(<span class="function"><span class="params">err</span>=&gt;</span><span class="built_in">console</span>.error(err.stack));</span><br></pre></td></tr></table></figure><h2 id="Koa"><a href="#Koa" class="headerlink" title="Koa"></a>Koa</h2> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Koa is a new Web framework designed by the team behind Express, which aims to be a smaller, more expressive, and more robust foundation for Web applications and APIS.</span><br></pre></td></tr></table></figure><h3 id="Middleware"><a href="#Middleware" class="headerlink" title="Middleware"></a>Middleware</h3><p> Koa 的中间件和Express不同， Koa选择了洋葱圈模型。</p><h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p> 通过同步代码编写异步代码带来的另外一个非常大的好外就是异常处理非常自然， 使用try catch就可以将按照规范编写的代码中的所有错误都捕获到。这样我们就可很便捷的编写一个自定义的错误处理中间件。</p> <figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">function</span> <span class="title">onerror</span>(<span class="params">ctx, next</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">try</span>&#123;</span><br><span class="line">        <span class="keyword">await</span> next();</span><br><span class="line">    &#125; <span class="keyword">catch</span>(error)&#123;</span><br><span class="line">        ctx.app.emit(<span class="string">'error'</span>, error);</span><br><span class="line">        ctx.body = <span class="string">'server error'</span>;</span><br><span class="line">        ctx.status = error.status || <span class="number">500</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 只需要将这个中间件放在其他中间件之前， 就可以捕获字化所有的同步或异常代码中抛出来的异常。</p><h1 id="Egg继承于Koa"><a href="#Egg继承于Koa" class="headerlink" title="Egg继承于Koa"></a>Egg继承于Koa</h1><p> 如上述， KOA是一个非常优秀的框架， 然而对于企业应用来说， 它还比较基础。</p><p> 而Egg选择了Koa 作来其基础框架， 在它的模型基础上， 进一步进行了一些增强。</p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p> 在基于Egg的框架或者应用中， 我们可以通过定义app/extend/{application, context, request, response}.js来扩展Koa中对应的四个对象的原型， 通过这个功能， 我们可以快速的增加更多的辅助方法， 例如我们在app/extend/context.js中写入下列代码：</p> <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = &#123;</span><br><span class="line">    get isIOS () &#123;</span><br><span class="line">        <span class="keyword">const</span> iosReg = <span class="regexp">/iphone|ipad|ipod/i</span>;</span><br><span class="line">        <span class="keyword">return</span> iosReg.test(<span class="keyword">this</span>.get(<span class="string">'user-agent'</span>));</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p> 在controller中， 我们就可以使用到刚才定义的这个便捷的属性了：</p> <figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">export</span>.handler = <span class="function"><span class="params">ctx</span> =&gt;</span> &#123;</span><br><span class="line">    ctx.body = ctx.isIOS</span><br><span class="line">       ? <span class="string">'Your operation system is IOS'</span></span><br><span class="line">       : <span class="string">'Your operating system is Not IOS'</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><p> 众所周知， 在Express和Koa中， 经常会引入许许多多的中间件来提供各种各样的功能， 例如引入koa-session提供Session的支持， 引入koa-bodyparser来解析请求的body.而Egg提供了一个更加强大的插件机制， 让这些独立领域的功能模块可以更加容易编写。</p><p> 一个插件可以包含：</p><ul><li>extend : 扩展基础对象的上下文， 提供各种工具类、属性。</li><li>middleware: 增加一个或多个中间件， 提供请求的前置、后置处理逻辑。</li><li>config : 配置各个环境下插件的默认配置项。</li></ul><p> 一个独立领域下的插件实现， 可以在代码维护性非常高的情况下实现非常完善的功能， 而插件也支持配置各个环境下的默认（最佳）配置， 让我们使用插件的时候几乎不需要修改配置项。</p><ul><li><p>egg-security 插件就是一个典型的例子。 </p><p>更多关于插件的内容， 请查看插件章节学习。 </p></li></ul><h2 id="Egg-与-Koa-的版本关系"><a href="#Egg-与-Koa-的版本关系" class="headerlink" title="Egg 与 Koa 的版本关系"></a>Egg 与 Koa 的版本关系</h2><h3 id="Egg2-x"><a href="#Egg2-x" class="headerlink" title="Egg2.x"></a>Egg2.x</h3><p>Node.js 8正式进入LTS后， async function 可以在Node.js在使用并且没有任何性能问题了， Egg 2.x基于Koa 2.x 框架底层以及所有内置插件都使用async function编写， 并保持了对Egg 1.x以及 generator function 的完全兼容， 应用层只需要升级到Node.js8 即可从Egg 1.x迁移到Egg 2.x</p><ul><li>底层基于Koa 2.x ， 异步解决方案基于 async function 。</li><li>官方插件以及Egg核心应用async function 编写。</li><li>建议业务层迁移到 async function 方案。</li><li>只支持Node.js8及以上的版本。 </li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Egg Alibaba Node.js Koa </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>spring-aop</title>
      <link href="/2018/09/18/spring-aop/"/>
      <url>/2018/09/18/spring-aop/</url>
      
        <content type="html"><![CDATA[<h1 id="AOP中的基本概念"><a href="#AOP中的基本概念" class="headerlink" title="AOP中的基本概念"></a>AOP中的基本概念</h1><ul><li><p>通知 （Adivce)<br>通知有5种类型：</p><ul><li>Before 在方法被调用之前调用</li><li>After 在方法完成后调用通知，无论方法是否执行成功</li><li>After-returning 在方法成功执行之后调用通知</li><li>After-throwing 在方法抛出异常后调用通知</li><li>Around 通知了好， 包含了被通知的方法， 在被通知的方法调用之前后调用之后执行自定义的行为</li></ul></li><li><p>切点 （Pointcut)</p></li></ul><p>切点在Spring AOP中确实是对应系统中的方法。 但是这个方法是定义在切面中的方法， 一般和通知在一起使用， 一起组成了切面。</p><ul><li>连接点（Join point)</li></ul><p>比如： 方法调用、方法执行、字段设置、获取， 异常处理执行， 类初始化， 甚至是for循环中的某个点</p><p>理论上， 程序执行过程中的任何时点都可以作为织入点， 而所有的这些执行时点都是Join point.</p><p>但是Spring AOP目前仅支持方法执行（method execution)也可以这样理解， 连接点就是你准备在系统中执行切点和切入通知的地方（一般是一个方法， 一个字段）</p><ul><li>切面 （Aspect)</li></ul><p>切面是切点和通知的集合，  一般单独作为一个类。 通知和切点共同定义了关于切面的全部内容， 它是什么时候， 在何时和何处完成功能。 </p><ul><li>引入（Introduction)</li></ul><p>引用允许我们向现有的类添加新的方法或者属性</p><ul><li>织入 （Weaving)</li></ul><p>组装方面来创建一个被通知对象， 这可以在编译时完成（例如使用AspectJ编译器）， 也可以在运行时完成， spring和其它纯Java AOP框架一样， 在运行时完成织入。 </p>]]></content>
      
      
      
    </entry>
    
    <entry>
      <title>gradle</title>
      <link href="/2018/09/17/gradle/"/>
      <url>/2018/09/17/gradle/</url>
      
        <content type="html"><![CDATA[<h1 id="build-gradle文件如何配置"><a href="#build-gradle文件如何配置" class="headerlink" title="build.gradle文件如何配置"></a>build.gradle文件如何配置</h1><p>你可能很想知道我该如何对一个build.gradle进行配置， 首先你已经知道一个工程对应一个build.gradle文件， 也就是说一个build.gradle文件就对应一个Project实例， 那么Project实例具有属性你都可以使用。</p><p>在build.gradle文件中采用DSL进行配置， 下面是你可以在build.gradle文件中配置的内容：</p><ul><li>Task</li></ul><p>Task是一种任务， 任务是Gradle中的基本组件， Task的概念也是收到了Ant的启发而设计的。</p><ul><li>Dependencies</li></ul><p>依赖管理</p><ul><li>Plugins</li></ul><p>插件， 就像我们在Maven的pom.xml文件中增加插件一样， Gradle也可以添加插件， 常见的插件有java,eclipse我们可以使用apple plugin: ‘java’加载插件</p><ul><li>Properties</li></ul><p>属性配置</p><ul><li>Methods</li></ul><p>配置一个方法， 纳尼， 配置文件可以配置一个方法， 你特么在逗我！没错， 这就是DSL的魅力， DSL内置支Groovy这种脚本语言， 因此， 我们可以在build.gradle文件中编写相关符合groovy语法的代码， 因此， 换句话说， build.gradle文件已经 超出了配置文件的范畴， 看起来更像是一个脚本文件， 比配置文件更加强大。 </p><ul><li>Script Blocks</li></ul><p>脚本块是一个很强大的特性， 也是Gradle特有的。 上面说到其实build.gradle文件相当于一个脚本文件 ， 因此脚本块的出现也就不足为奇了， 常用的脚本块有以下几种：</p><pre><code>-    allprojects 在很多项目工程中对所有项目（包括子项目）的通用配置-  ant对ant提供支持- artifacts对生成构件的支持， 如生产一个jar包- buildscript执行gradle build 命令的相关配置， 主要配置构建的输出目录， 引用的仓库等信息- configurations提供对依赖管理的支持- dependencies依赖声明和配置- repositories仓库配置- subprojects在多项目中对所有子项目的通用配置</code></pre><h1 id="Gradle配置简单的多项目工程"><a href="#Gradle配置简单的多项目工程" class="headerlink" title="Gradle配置简单的多项目工程"></a>Gradle配置简单的多项目工程</h1><p>该工程为 Spring boot工程， 大家可以通过<a href="http://start.spring.io/配置下载，" target="_blank" rel="noopener">http://start.spring.io/配置下载，</a> 主工程包含三个子工程， 分别是myapp-controller, myapp-service , myapp-dao</p><h2 id="根目录下的settings-gradle"><a href="#根目录下的settings-gradle" class="headerlink" title="根目录下的settings.gradle"></a>根目录下的settings.gradle</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">rootProject.name = &apos;myapp&apos;</span><br><span class="line"></span><br><span class="line">include &apos;myapp-controller&apos;</span><br><span class="line">include &apos;myapp-service&apos;</span><br><span class="line">include &apos;myapp-dao&apos;</span><br></pre></td></tr></table></figure><h2 id="根目录下的build-gradle"><a href="#根目录下的build-gradle" class="headerlink" title="根目录下的build.gradle"></a>根目录下的build.gradle</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">// 构建脚本</span><br><span class="line">buildscript &#123;</span><br><span class="line">ext &#123;</span><br><span class="line">springBootVersion = &apos;2.0.2.RELEASE&apos;</span><br><span class="line">&#125;</span><br><span class="line">repositories &#123;</span><br><span class="line">mavenCentral()</span><br><span class="line">maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public/&apos; &#125;</span><br><span class="line">&#125;</span><br><span class="line">dependencies &#123;</span><br><span class="line">classpath(&quot;org.springframework.boot:spring-boot-gradle-plugin:$&#123;springBootVersion&#125;&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">// 所有项目共有的配置</span><br><span class="line">allprojects &#123;</span><br><span class="line">apply plugin: &apos;java&apos;</span><br><span class="line">apply plugin: &apos;eclipse&apos;</span><br><span class="line">apply plugin: &apos;org.springframework.boot&apos;</span><br><span class="line">apply plugin: &apos;io.spring.dependency-management&apos;</span><br><span class="line"></span><br><span class="line">group = &apos;com.example&apos;</span><br><span class="line">version = &apos;0.0.1-SNAPSHOT&apos;</span><br><span class="line">sourceCompatibility = 1.8</span><br><span class="line"></span><br><span class="line">repositories &#123;</span><br><span class="line">mavenCentral()</span><br><span class="line">maven &#123; url &apos;http://maven.aliyun.com/nexus/content/groups/public/&apos; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dependencies &#123;</span><br><span class="line">compile(&apos;org.springframework.boot:spring-boot-starter-web&apos;)</span><br><span class="line">testCompile(&apos;org.springframework.boot:spring-boot-starter-test&apos;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="每个子工程的build-gradle"><a href="#每个子工程的build-gradle" class="headerlink" title="每个子工程的build.gradle"></a>每个子工程的build.gradle</h2> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> description = &apos;myapp-controller&apos;</span><br><span class="line">dependencies &#123;</span><br><span class="line">    // 该子工程包含另外一个子工程</span><br><span class="line">compile project(&apos;:myapp-dao&apos;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>end</p>]]></content>
      
      
      
        <tags>
            
            <tag> gradle maven ant new publish create </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>hexo</title>
      <link href="/2018/09/17/hexo/"/>
      <url>/2018/09/17/hexo/</url>
      
        <content type="html"><![CDATA[<h2 id="学习hexo常用命令"><a href="#学习hexo常用命令" class="headerlink" title="学习hexo常用命令"></a>学习hexo常用命令</h2><ul><li>init</li><li>new</li><li>generate</li><li>publish</li><li>server</li><li>deploy</li><li>render</li><li>migrate</li><li>clean</li><li>list</li><li>version</li></ul><h2 id="命令说明"><a href="#命令说明" class="headerlink" title="命令说明"></a>命令说明</h2><h3 id="init"><a href="#init" class="headerlink" title="init"></a>init</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init [folder]</span><br></pre></td></tr></table></figure><p>新建一个网站。如果没有设置folder, Hexo默认在目前的文件夹建立网站。</p><h3 id="new"><a href="#new" class="headerlink" title="new"></a>new</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure><p>新建一篇文章。如果没有设置layout的话。 默认使用_config.yml中的 default_layout参数代替。如果标题包含空格的话， 请使用引号括起来。</p><h3 id="generate"><a href="#generate" class="headerlink" title="generate"></a>generate</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>生成静态文件。</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">-d, –deplay</td><td style="text-align:center">文件生成后立即部署网站</td></tr><tr><td style="text-align:center">-w, –watch</td><td style="text-align:center">监视文件变动</td></tr></tbody></table><p>该命令可以简写为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo g</span><br></pre></td></tr></table></figure></p><h3 id="publish"><a href="#publish" class="headerlink" title="publish"></a>publish</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo publish [layout] &lt;filename&gt;</span><br></pre></td></tr></table></figure><p>发表草稿。</p><h3 id="server"><a href="#server" class="headerlink" title="server"></a>server</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>启动服务器。 默认情况下， 访问网址为： <a href="http://localhost:4000" target="_blank" rel="noopener">http://localhost:4000</a>.</p><table><thead><tr><th style="text-align:center">选项</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">asdasdf</td><td style="text-align:center">asdfasdfads</td></tr></tbody></table>]]></content>
      
      
      
    </entry>
    
  
  
</search>
